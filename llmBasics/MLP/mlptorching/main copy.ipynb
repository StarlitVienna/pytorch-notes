{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "\n",
      "\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "with open(\"input.txt\", 'r', encoding=\"UTF-8\") as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(set(text))\n",
    "    vocab_size = len(chars)\n",
    "\n",
    "\n",
    "stoi = {char:integer for integer, char in enumerate(chars)}\n",
    "itos = {integer:char for integer, char in enumerate(chars)}\n",
    "\n",
    "encode = lambda enc: [stoi[c] for c in enc]\n",
    "decode = lambda dec: \"\".join([itos[i] for i in dec])\n",
    "\n",
    "print(encode(\"\\n\"))\n",
    "print(decode(encode(\"\\n\")))\n",
    "\n",
    "vocab_size = len(stoi)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLP/mlptorching/main copy.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m context_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m names[:]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     context \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m context_size\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m char \u001b[39min\u001b[39;00m n \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'names' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "labels = []\n",
    "context_size = 3\n",
    "for n in names[:]:\n",
    "    context = [0] * context_size\n",
    "    for char in n + \".\":\n",
    "        idx = stoi[char]\n",
    "        inputs.append(context)\n",
    "        labels.append(idx)\n",
    "        context = context[1:] + [idx]\n",
    "\n",
    "inputs = torch.tensor(inputs)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print(inputs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 2\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLP/mlptorching/main copy.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m embtest \u001b[39m=\u001b[39m C[inputs]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(vocab_size)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(inputs\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(embtest\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m embtest \u001b[39m=\u001b[39m embtest\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, context_size\u001b[39m*\u001b[39mn_embd)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "embtest = C[inputs]\n",
    "print(vocab_size)\n",
    "print(inputs.shape)\n",
    "print(embtest.shape)\n",
    "\n",
    "embtest = embtest.view(-1, context_size*n_embd)\n",
    "print(embtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd):\n",
    "        super(MLP, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_emb_table = nn.Embedding(context_size, n_embd)\n",
    "        self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size)\n",
    "\n",
    "        self.query = nn.Linear(in_features=n_embd, out_features=n_embd)\n",
    "        self.key = nn.Linear(in_features=n_embd, out_features=n_embd)\n",
    "\n",
    "    def forward(self, x, batched:bool):\n",
    "        tok_emb = self.token_embedding(x)\n",
    "        #print(f\"x.shape[1] --> {x.shape[1]}\")\n",
    "        pos_emb = self.positional_emb_table(torch.arange(x.shape[1])) # --> context_size X n_embd\n",
    "        #print(pos_emb.shape)\n",
    "        result_emb = tok_emb + pos_emb\n",
    "\n",
    "        Q = self.query(result_emb)\n",
    "        K = self.key(result_emb)\n",
    "\n",
    "        print(Q.shape)\n",
    "        print(K.shape)\n",
    "\n",
    "        #dot_simillarity = Q @ K\n",
    "        #print(dot_simillarity.shape)\n",
    "        #print(dot_simillarity)\n",
    "\n",
    "\n",
    "\n",
    "        #test = self.token_embedding(torch.tensor([0])).shape --> [2] #basically it's a 1 X 1 X 2 but squeezed\n",
    "        #test = self.token_embedding(torch.tensor([0, 2])).shape --> [2, 2]\n",
    "        #test = self.token_embedding(torch.tensor([0, 2, 2])).shape --> [3, 2] #the n_embd is always preserved so it can go into the lm_head\n",
    "        #print(test)\n",
    "        #emb = emb.view(-1, context_size*n_embd)\n",
    "        #OR --> B, T, C = emb.shape #batch --> how many inputs in the batch #Time --> context size #Channels --> n_embd\n",
    "        logits = self.lm_head(result_emb)\n",
    "        if batched:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) #96 X 2 #assuming batch_size = 32 and n_embd = 2\n",
    "\n",
    "        #The explanation below is for a batch size of 32 and vocab size of 27\n",
    "        #logits = self.lm_head(emb) # turns this into --> 96 X 27 #so there must be 96 labels in total to be compared those 96 inputs #because of B * T in the view above it's not 32 inputs of 3 characters anymore, it's now 96 characters with 27 probabilities each\n",
    "        #if the input is not bached, then there is no batch input dimension nor time, the only output plucked out of the emb table are 2 channels, the shape of it being [2] ex --> [-2.243, 0.763]\n",
    "\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def generator(self, starting_idx, max_new_tokens):\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            #max_new_tokens is needed since there is no special character to stop the generation\n",
    "            logits = self(starting_idx, False) #plucks out the 0th row of the token embedding table\n",
    "            #logits are of shape --> B*T X vocab_size or just batch_size * n_context_character X vocab_size\n",
    "\n",
    "            #then based on the last character, predict the next one\n",
    "\n",
    "            #print(logits.shape) #since it's being passed as batched, there is no batch_dimension in the logits\n",
    "            #but if it's passed as unbatched, there will be an extra dimension at the beggining of logits\n",
    "            #print(logits[:, -1, :]) # --> no need for the last : but just in case it can be useful\n",
    "            #if it's passed as unbatched, there will be an extra dimension at the beggining, thus the need to do it like this --> [:, -1, :]\n",
    "            probs = torch.softmax(logits[:, -1, :], dim=1) #no dim passed because is unbatched, if batched, pass dim as 1\n",
    "            new_idx = torch.multinomial(probs, num_samples=1)\n",
    "            starting_idx = torch.cat((starting_idx, new_idx), dim=1)\n",
    "            #print(starting_idx)\n",
    "        return starting_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(data, batch_size, context_size):\n",
    "    batch_idx = torch.randint(0, data.shape[0]-context_size, (batch_size,))\n",
    "    x = torch.stack([data[idx:idx+context_size] for idx in batch_idx])\n",
    "    y = torch.stack([data[idx+1:idx+1+context_size] for idx in batch_idx])\n",
    "\n",
    "    #decode x to view what it is\n",
    "    #print(x[0].tolist())\n",
    "    #print(decode(x[0].tolist()))\n",
    "    #print(decode(y[0].tolist()))\n",
    "\n",
    "    return (x, y)\n",
    "\n",
    "data = torch.tensor(encode(text))\n",
    "x, y = get_batch(data, 32, 3)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embd = 32\n",
    "context_size = 256 #also max context for predictions\n",
    "batch_size = 64\n",
    "\n",
    "model = MLP(vocab_size=vocab_size, n_embd=n_embd)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 32])\n",
      "torch.Size([64, 256, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [64, 32] but got: [64, 256].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLP/mlptorching/main copy.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m x, y \u001b[39m=\u001b[39m get_batch(data, batch_size, context_size)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#print(x.shape)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m logits \u001b[39m=\u001b[39m model(x, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#print(y.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#print(logits.shape)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#print(y)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(logits, y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/torching/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/torching/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLP/mlptorching/main copy.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(Q\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(K\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m dot_simillarity \u001b[39m=\u001b[39m Q \u001b[39m@\u001b[39;49m K\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(dot_simillarity\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/mlptorching/main%20copy.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(dot_simillarity)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [64, 32] but got: [64, 256]."
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    x, y = get_batch(data, batch_size, context_size)\n",
    "    #print(x.shape)\n",
    "    logits = model(x, True)\n",
    "    #print(y.shape)\n",
    "    #print(logits.shape)\n",
    "    #print(y)\n",
    "    loss = loss_fn(logits, y.view(-1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I peringnthe, pees.\n",
      "KEETHeshen te pracours msthe be t ndlos bur manoulle his:\n",
      "\n",
      "MENowisecht. l'ds u r gin, om.\n",
      "dicowireabret, u geake llof Ano Vodsowhes thestourday Tofuto, f s oounghiackn.\n",
      "Whe d ous NTh ING s'd wed t s I:\n",
      "TE:\n",
      "Yonat:\n",
      "Ansid\n",
      "Buropainth wey ic\n"
     ]
    }
   ],
   "source": [
    "#starts with a new line\n",
    "with torch.inference_mode():\n",
    "    sample = model.generator(torch.tensor([[0]]), 256)\n",
    "    sample_tolist = sample[0].tolist()\n",
    "    decoded = decode(sample_tolist)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
