{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#Hyper parameter --> a designer's choice parameter, can be as small or as big as you like\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"names.txt\", 'r', encoding=\"UTF-8\") as f:\n",
    "    text = f.read()\n",
    "    words = text.splitlines()\n",
    "    chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "stoi = {char:integer+1 for integer,char in enumerate(chars)}\n",
    "itos = {integer+1:char for integer,char in enumerate(chars)}\n",
    "\n",
    "stoi[\".\"] = 0\n",
    "itos[0] = \".\"\n",
    "\n",
    "vocab_size = len(stoi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1]]\n",
      "torch.Size([5, 3])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "#Generating data\n",
    "inputs, labels = [], []\n",
    "context_size = 3\n",
    "\n",
    "for w in words[:1]:\n",
    "    context = [0] * context_size\n",
    "    for char in w + \".\":\n",
    "        ix = stoi[char]\n",
    "        inputs.append(context)\n",
    "        labels.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "inputs = torch.tensor(inputs)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "#print(inputs)\n",
    "print(inputs.shape) #number of total characters in the words X block size (context size) --> there is a 1 new character for each dimension added, thus why it's n_c X b_s\n",
    "print(labels.shape) #number of total characters in the words X 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27, 2])\n",
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1]], device='cuda:0')\n",
      "tensor([[[-0.4136,  0.0690],\n",
      "         [-0.4136,  0.0690],\n",
      "         [-0.4136,  0.0690]]], device='cuda:0')\n",
      "torch.Size([1, 3, 2])\n",
      "tensor([[-0.4136,  0.0690],\n",
      "        [-0.4136,  0.0690],\n",
      "        [-0.4136,  0.0690]], device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      " Visualizing\n",
      "tensor([[[-0.4136,  0.0690],\n",
      "         [-0.4136,  0.0690],\n",
      "         [-0.4136,  0.0690]],\n",
      "\n",
      "        [[-0.4136,  0.0690],\n",
      "         [-0.4136,  0.0690],\n",
      "         [ 1.3629,  0.3710]],\n",
      "\n",
      "        [[-0.4136,  0.0690],\n",
      "         [ 1.3629,  0.3710],\n",
      "         [ 0.1636,  0.1639]],\n",
      "\n",
      "        [[ 1.3629,  0.3710],\n",
      "         [ 0.1636,  0.1639],\n",
      "         [ 0.1636,  0.1639]],\n",
      "\n",
      "        [[ 0.1636,  0.1639],\n",
      "         [ 0.1636,  0.1639],\n",
      "         [ 0.9522,  0.2234]]], device='cuda:0')\n",
      "torch.Size([5, 3, 2])\n",
      "tensor([[[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]],\n",
      "\n",
      "        [[True, True],\n",
      "         [True, True],\n",
      "         [True, True]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#The embedding is pretty handy because it can generalize to new scenarios never seen by the model\n",
    "g = torch.Generator(device=device).manual_seed(2718472123)\n",
    "emb = torch.randn((vocab_size, 2), generator=g)\n",
    "print(emb.shape) #each character basically have 2 values, the neural network can prioritize one of the values depending on the context so to give a different answer as the next character\n",
    "\n",
    "\n",
    "print(inputs[:5]) #grab the first word\n",
    "print(emb[torch.tensor([[0, 0, 0]])]) #indexing at [0, 0, 0] is the same as taking the value emb[0, :] three times and stacking those tensors\n",
    "print(emb[torch.tensor([[0, 0, 0]])].shape)\n",
    "print(torch.stack((emb[0, :], emb[0, :], emb[0, :])))\n",
    "print(\"\")\n",
    "\n",
    "visualization = emb[torch.tensor(\n",
    "    [\n",
    "        [0, 0, 0],\n",
    "        [0, 0, 5],\n",
    "        [0, 5, 13],\n",
    "        [5, 13, 13],\n",
    "        [13, 13, 1]\n",
    "    ]\n",
    ")]\n",
    "\n",
    "print(\"\\n\\n Visualizing\")\n",
    "print(visualization)\n",
    "print(visualization.shape) # 5 X 3 X 2 (5 inputs, 3 context characters (block size), 2 values per character) total of 5*3*2=30 values\n",
    "print(torch.eq(visualization, emb[inputs[:5]]))\n",
    "#they are the same\n",
    "\n",
    "embedded = emb[inputs]\n",
    "#print(embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLP/second.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/second.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#print(embedded.shape)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/second.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m embedded_for_forwardpass \u001b[39m=\u001b[39m embedded\u001b[39m.\u001b[39mview(embedded\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], context_size\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/second.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(embedded_for_forwardpass\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLP/second.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(embedded_for_forwardpass[\u001b[39m0\u001b[39m]) \u001b[39m#This is the same as emb[[0, 0 ,0]] crammed together to form a single vector\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedded' is not defined"
     ]
    }
   ],
   "source": [
    "#print(embedded.shape)\n",
    "embedded_for_forwardpass = embedded.view(embedded.shape[0], context_size*2)\n",
    "print(embedded_for_forwardpass.shape)\n",
    "print(embedded_for_forwardpass[0]) #This is the same as emb[[0, 0 ,0]] crammed together to form a single vector\n",
    "print(emb[[0,0,0]])\n",
    "print()\n",
    "#Or can think of it as embedded[0, :] crammed together for form a single vector of 1 X 3*2 (3 context characters in total with 2 values each)\n",
    "print(embedded[0, :])\n",
    "#This way it can be passed to the hidden layer for the forward pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228146, 6])\n",
      "tensor([[ 0.9726,  0.4431, -0.0864,  ...,  0.0149, -0.7072,  0.1730],\n",
      "        [ 0.6922, -0.8180,  0.9886,  ..., -0.0238,  0.2132,  0.9690],\n",
      "        [ 0.7751,  0.7703,  0.8652,  ..., -0.8317, -0.9067, -0.3992],\n",
      "        ...,\n",
      "        [ 0.7867, -0.6697,  0.9998,  ..., -0.6898, -0.5859,  0.9968],\n",
      "        [ 0.9975,  0.9968,  0.3273,  ..., -0.9427, -0.8403, -0.7195],\n",
      "        [ 0.9586, -0.9914,  0.9985,  ..., -0.9999,  0.9998,  0.9991]],\n",
      "       device='cuda:0')\n",
      "torch.Size([228146, 2000])\n",
      "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0')\n",
      "PROBS SHAPE --> torch.Size([228146, 27])\n",
      "tensor([25, 17, 19,  ...,  5,  0,  5], device='cuda:0')\n",
      "PREDS SHAPE --> torch.Size([228146])\n",
      "LABELS SHAPE --> torch.Size([228146])\n"
     ]
    }
   ],
   "source": [
    "#DOING THE FORWARD PASS\n",
    "\n",
    "\n",
    "#Hidden layer\n",
    "print(embedded_for_forwardpass.shape)\n",
    "w1_n_neurons = 2000\n",
    "W1 = torch.randn((embedded_for_forwardpass.shape[1], w1_n_neurons), generator=g)\n",
    "b1 = torch.randn((w1_n_neurons), generator=g) #One bias per neuron\n",
    "\n",
    "hidden_layer_output = torch.tanh(embedded_for_forwardpass @ W1 + b1) #torch.tanh is the activation function, very similar to sigmoid but quite different\n",
    "\n",
    "print(hidden_layer_output)\n",
    "print(hidden_layer_output.shape)\n",
    "\n",
    "#Output layer\n",
    "W2 = torch.randn((w1_n_neurons, vocab_size), generator=g)\n",
    "#Number of features X vocab size (it will pull which character from the vocab size is expected)\n",
    "b2 = torch.randn((vocab_size), generator=g) #One bias per neuron in the output layer\n",
    "\n",
    "logits = hidden_layer_output @ W2 + b2\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "print(probs.sum(dim=1)) #Every row sums to 1\n",
    "print(f\"PROBS SHAPE --> {probs.shape}\") #228146 character predictions using a vocab of 27 characters\n",
    "\n",
    "preds = torch.argmax(probs, dim=1)\n",
    "print(preds)\n",
    "print(f\"PREDS SHAPE --> {preds.shape}\")\n",
    "print(f\"LABELS SHAPE --> {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  5.5468,  14.0438,   4.0803,  ...,  21.6168,  64.5432,  25.1775],\n",
      "        [-43.1634,  -8.5669,   1.7233,  ...,  52.6536, -25.9140,   8.2162],\n",
      "        [ 14.4222,   0.4754, -48.1010,  ..., -41.6979, -19.8595,  -3.8052],\n",
      "        ...,\n",
      "        [-11.2490,  -2.4094, -48.5172,  ...,  26.2349,  19.9011,  26.8131],\n",
      "        [ 95.0431,  27.8424, -34.6679,  ..., -67.1100,  22.7324, -64.7000],\n",
      "        [ 26.4629, -38.3026,  31.6897,  ...,  40.6187, -70.5282,  -5.8369]],\n",
      "       device='cuda:0')\n",
      "tensor(71.9009, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss = F.cross_entropy(logits, labels)\n",
    "print(logits)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.3359, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "lr = -0.001\n",
    "parameters = [emb, W1, b1, W2, b2]\n",
    "embedded_for_forwardpass = emb[inputs].view(embedded.shape[0], context_size*2)\n",
    "h = torch.tanh(embedded_for_forwardpass @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, labels)\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "    p.grad = None\n",
    "\n",
    "loss.backward()\n",
    "for p in parameters:\n",
    "    p.data += lr*p.grad\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
