{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device --> cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"gpu\"\n",
    "torch.set_default_device(device)\n",
    "print(f\"current device --> {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"names.txt\", 'r', encoding=\"UTF-8\") as f:\n",
    "    text = f.read()\n",
    "    words = text.splitlines()\n",
    "    chars = sorted(set(\"\".join(words)))\n",
    "\n",
    "stoi = {char:integer+1 for integer, char in enumerate(chars)}\n",
    "itos = {integer+1:char for integer, char in enumerate(chars)}\n",
    "\n",
    "stoi[\".\"] = 0\n",
    "itos[0] = \".\"\n",
    "\n",
    "vocab_size = len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(words)\n",
    "\n",
    "train_percent = 0.8\n",
    "eval_percent = 0.1\n",
    "test_percent = 0.1\n",
    "\n",
    "inputs, labels = [], []\n",
    "\n",
    "\n",
    "context_size = 3\n",
    "\n",
    "for w in words[:]:\n",
    "    context = [0] * context_size\n",
    "    for char in w + \".\":\n",
    "        ix = stoi[char]\n",
    "        inputs.append(context)\n",
    "        labels.append(ix)\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "train_split = int(len(inputs)*train_percent)\n",
    "eval_split = int(len(inputs)*eval_percent)\n",
    "test_split = int(len(inputs)*test_percent)\n",
    "\n",
    "Xtrain = torch.tensor(inputs[:train_split])\n",
    "Ytrain = torch.tensor(labels[:train_split])\n",
    "\n",
    "Xeval = torch.tensor(inputs[train_split:train_split+eval_split])\n",
    "Yeval = torch.tensor(labels[train_split:train_split+eval_split])\n",
    "\n",
    "Xtest = torch.tensor(inputs[train_split+eval_split:])\n",
    "Ytest = torch.tensor(labels[train_split+eval_split:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_crammed_dimensions = 10\n",
    "\n",
    "C = torch.randn((vocab_size, n_crammed_dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, in_features, out_features, bias):\n",
    "        self.weights = torch.randn((in_features, out_features)) / in_features**0.5 #Kaiming initialization\n",
    "        self.biases = torch.zeros((out_features)) if bias else None\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        self.output = inputs @ self.weights\n",
    "        if self.biases is not None:\n",
    "            self.output += self.biases\n",
    "        return self.output\n",
    "    \n",
    "    def params(self):\n",
    "        if self.biases is not None:\n",
    "            return [self.weights, self.biases]\n",
    "        else:\n",
    "            return [self.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182516, 3, 10])\n",
      "tensor([[ 3.0407e+00, -9.4090e-01, -7.7606e+00, -4.4884e-01,  1.2144e+00,\n",
      "          2.0335e+00,  2.3982e-01, -3.1188e-01, -4.6000e+00, -1.2278e+00],\n",
      "        [ 3.8857e+00, -2.1588e-01, -8.0756e+00,  1.7754e+00, -1.6461e+00,\n",
      "          2.5144e+00, -1.5102e+00, -3.9295e-01, -5.1568e+00,  2.5783e-01],\n",
      "        [ 2.4733e+00,  5.2570e-01, -3.2230e+00, -2.4308e-01, -4.6965e-01,\n",
      "          3.3051e-01, -1.0441e+00,  4.7854e-01,  2.2393e-01,  8.5947e-01],\n",
      "        [ 3.1372e+00, -2.8095e-01, -3.4550e+00,  1.4800e+00, -4.3365e-01,\n",
      "         -8.5897e-01, -2.1755e-01, -6.9670e-01, -4.9960e-01, -1.3064e+00],\n",
      "        [ 1.8108e+00,  5.0826e-01, -2.3793e+00,  5.5754e-01, -2.6300e-01,\n",
      "          9.5574e-01, -2.8494e-02, -1.9921e+00, -4.1166e+00, -7.6748e-01],\n",
      "        [ 4.5352e+00,  7.6271e-01, -7.0911e+00,  3.0721e+00,  1.7022e-01,\n",
      "         -2.3601e-01, -1.6577e+00, -1.6835e+00, -3.3861e+00,  9.7677e-01],\n",
      "        [ 2.7822e+00, -1.0838e+00, -2.0333e+00, -5.6300e-01, -6.1111e-01,\n",
      "         -7.9136e-01,  3.3473e-01, -9.2837e-01, -6.3978e-01,  3.6266e-01],\n",
      "        [ 1.5389e+00, -1.1496e+00, -2.1743e+00,  1.4907e+00,  2.2408e-01,\n",
      "         -4.4046e-01, -3.4692e-01, -3.7592e-01, -1.8490e+00,  7.1709e-01],\n",
      "        [ 3.4036e+00,  9.8664e-01, -4.5518e+00, -5.8680e-01,  1.0003e-01,\n",
      "         -7.6377e-01, -2.1013e+00, -1.1921e+00, -2.2975e+00, -2.2352e+00],\n",
      "        [ 3.6728e+00, -4.2652e-01, -6.5083e+00,  1.5799e+00,  6.3734e-01,\n",
      "         -1.3893e+00, -1.1023e+00, -1.5576e+00, -4.9650e+00,  6.5274e-01],\n",
      "        [ 5.7071e-01,  1.0746e+00, -2.2639e+00,  8.9716e-01, -2.6530e-01,\n",
      "         -4.9046e-03, -4.9504e-01,  1.0284e+00, -2.0339e+00, -1.0908e+00],\n",
      "        [ 2.0466e+00, -1.1161e+00, -2.3265e+00,  2.5477e+00, -1.7166e+00,\n",
      "          1.2430e-01, -1.7520e-01, -1.3696e-01, -2.8661e+00, -1.3842e+00],\n",
      "        [ 2.0648e+00,  6.6585e-02, -5.2403e+00,  2.1434e+00, -8.4789e-01,\n",
      "         -8.1214e-01, -1.4532e+00,  5.7650e-01, -2.6310e+00, -1.1758e+00],\n",
      "        [ 9.7969e-01, -6.2180e-01, -3.8730e+00,  9.2957e-01, -9.5333e-01,\n",
      "         -2.6738e-01, -3.4843e-01, -2.0256e+00, -2.4915e+00, -1.2185e-01],\n",
      "        [ 1.1555e+00,  1.2105e+00, -5.1751e+00,  1.5216e+00,  3.1949e-01,\n",
      "          1.6006e-01, -1.8238e-01, -1.2702e+00, -5.1064e+00,  8.7443e-01],\n",
      "        [ 4.5683e+00,  7.4856e-01, -6.4245e+00, -5.9099e-01, -1.3669e+00,\n",
      "          2.2332e-01, -2.3216e+00, -1.7040e+00, -2.9215e+00,  5.1424e-01],\n",
      "        [ 8.5891e-01, -8.6285e-02, -2.1547e+00,  6.1263e-01, -1.8740e+00,\n",
      "         -1.2687e-02, -4.2477e-01, -3.5797e-01, -1.3674e+00,  8.3443e-01],\n",
      "        [ 1.0563e+00,  6.7175e-01, -1.3122e+00, -1.5327e+00, -2.0022e+00,\n",
      "          1.2437e+00, -3.2287e-01, -8.5957e-01,  9.6246e-02, -7.5103e-01],\n",
      "        [ 3.2805e+00,  1.0287e+00, -4.6877e+00,  1.4479e+00, -7.1537e-01,\n",
      "         -4.5533e-01, -1.6661e+00, -1.4263e+00, -2.4918e+00, -1.9965e+00],\n",
      "        [ 2.9689e+00,  5.3449e-01, -4.4202e+00,  1.4345e+00,  3.3461e-02,\n",
      "          6.0276e-03, -3.1334e+00, -3.5927e-01, -1.6060e+00, -5.0799e-01],\n",
      "        [ 2.8963e+00, -1.9389e+00, -2.7332e+00,  2.1655e+00, -3.4648e-01,\n",
      "         -5.7840e-01, -2.2705e+00, -9.9033e-01, -3.4582e+00, -5.8871e-01],\n",
      "        [ 4.6244e+00, -8.7691e-02, -5.8880e+00,  2.9971e-03, -1.1177e+00,\n",
      "          4.4539e-01,  1.9680e+00, -8.0464e-01, -1.9059e+00,  8.6118e-01],\n",
      "        [ 1.8974e-02,  9.8392e-01, -1.9960e+00, -5.6778e-01, -1.8185e+00,\n",
      "          1.3859e+00, -1.7587e+00, -1.7132e+00, -2.4272e+00,  8.1143e-01],\n",
      "        [ 1.1541e+00,  9.2288e-01, -2.5059e+00,  2.7276e-01, -2.2028e+00,\n",
      "          6.8515e-01,  2.5344e+00,  6.1784e-01, -2.1907e+00,  2.5139e-01],\n",
      "        [ 8.8863e-01, -1.3628e+00, -3.1617e+00, -1.2554e+00, -8.3035e-01,\n",
      "         -5.6490e-01,  1.2833e-01, -2.4420e-01, -2.5820e-01,  8.1066e-01],\n",
      "        [ 3.6907e+00, -2.3467e-02, -4.1077e+00,  1.4152e+00, -4.8655e-01,\n",
      "          2.6291e-02, -1.4362e+00,  5.1400e-01, -5.3548e+00, -1.0267e-01],\n",
      "        [ 5.1979e-01,  3.6157e-01, -3.9418e+00, -5.8280e-01, -7.4988e-01,\n",
      "          5.7813e-01, -2.1588e+00, -5.7772e-02, -9.8089e-01, -7.0667e-01]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3.0407e+00, -9.4090e-01, -7.7606e+00, -4.4884e-01,  1.2144e+00,\n",
      "          2.0335e+00,  2.3982e-01, -3.1188e-01, -4.6000e+00, -1.2278e+00],\n",
      "        [ 3.8857e+00, -2.1588e-01, -8.0756e+00,  1.7754e+00, -1.6461e+00,\n",
      "          2.5144e+00, -1.5102e+00, -3.9295e-01, -5.1568e+00,  2.5783e-01],\n",
      "        [ 2.4733e+00,  5.2570e-01, -3.2230e+00, -2.4308e-01, -4.6965e-01,\n",
      "          3.3051e-01, -1.0441e+00,  4.7854e-01,  2.2393e-01,  8.5947e-01],\n",
      "        [ 3.1372e+00, -2.8095e-01, -3.4550e+00,  1.4800e+00, -4.3365e-01,\n",
      "         -8.5897e-01, -2.1755e-01, -6.9670e-01, -4.9960e-01, -1.3064e+00],\n",
      "        [ 1.8108e+00,  5.0826e-01, -2.3793e+00,  5.5754e-01, -2.6300e-01,\n",
      "          9.5574e-01, -2.8494e-02, -1.9921e+00, -4.1166e+00, -7.6748e-01],\n",
      "        [ 4.5352e+00,  7.6271e-01, -7.0911e+00,  3.0721e+00,  1.7022e-01,\n",
      "         -2.3601e-01, -1.6577e+00, -1.6835e+00, -3.3861e+00,  9.7677e-01],\n",
      "        [ 2.7822e+00, -1.0838e+00, -2.0333e+00, -5.6300e-01, -6.1111e-01,\n",
      "         -7.9136e-01,  3.3473e-01, -9.2837e-01, -6.3978e-01,  3.6266e-01],\n",
      "        [ 1.5389e+00, -1.1496e+00, -2.1743e+00,  1.4907e+00,  2.2408e-01,\n",
      "         -4.4046e-01, -3.4692e-01, -3.7592e-01, -1.8490e+00,  7.1709e-01],\n",
      "        [ 3.4036e+00,  9.8664e-01, -4.5518e+00, -5.8680e-01,  1.0003e-01,\n",
      "         -7.6377e-01, -2.1013e+00, -1.1921e+00, -2.2975e+00, -2.2352e+00],\n",
      "        [ 3.6728e+00, -4.2652e-01, -6.5083e+00,  1.5799e+00,  6.3734e-01,\n",
      "         -1.3893e+00, -1.1023e+00, -1.5576e+00, -4.9650e+00,  6.5274e-01],\n",
      "        [ 5.7071e-01,  1.0746e+00, -2.2639e+00,  8.9716e-01, -2.6530e-01,\n",
      "         -4.9046e-03, -4.9504e-01,  1.0284e+00, -2.0339e+00, -1.0908e+00],\n",
      "        [ 2.0466e+00, -1.1161e+00, -2.3265e+00,  2.5477e+00, -1.7166e+00,\n",
      "          1.2430e-01, -1.7520e-01, -1.3696e-01, -2.8661e+00, -1.3842e+00],\n",
      "        [ 2.0648e+00,  6.6585e-02, -5.2403e+00,  2.1434e+00, -8.4789e-01,\n",
      "         -8.1214e-01, -1.4532e+00,  5.7650e-01, -2.6310e+00, -1.1758e+00],\n",
      "        [ 9.7969e-01, -6.2180e-01, -3.8730e+00,  9.2957e-01, -9.5333e-01,\n",
      "         -2.6738e-01, -3.4843e-01, -2.0256e+00, -2.4915e+00, -1.2185e-01],\n",
      "        [ 1.1555e+00,  1.2105e+00, -5.1751e+00,  1.5216e+00,  3.1949e-01,\n",
      "          1.6006e-01, -1.8238e-01, -1.2702e+00, -5.1064e+00,  8.7443e-01],\n",
      "        [ 4.5683e+00,  7.4856e-01, -6.4245e+00, -5.9099e-01, -1.3669e+00,\n",
      "          2.2332e-01, -2.3216e+00, -1.7040e+00, -2.9215e+00,  5.1424e-01],\n",
      "        [ 8.5891e-01, -8.6285e-02, -2.1547e+00,  6.1263e-01, -1.8740e+00,\n",
      "         -1.2687e-02, -4.2477e-01, -3.5797e-01, -1.3674e+00,  8.3443e-01],\n",
      "        [ 1.0563e+00,  6.7175e-01, -1.3122e+00, -1.5327e+00, -2.0022e+00,\n",
      "          1.2437e+00, -3.2287e-01, -8.5957e-01,  9.6246e-02, -7.5103e-01],\n",
      "        [ 3.2805e+00,  1.0287e+00, -4.6877e+00,  1.4479e+00, -7.1537e-01,\n",
      "         -4.5533e-01, -1.6661e+00, -1.4263e+00, -2.4918e+00, -1.9965e+00],\n",
      "        [ 2.9689e+00,  5.3449e-01, -4.4202e+00,  1.4345e+00,  3.3461e-02,\n",
      "          6.0276e-03, -3.1334e+00, -3.5927e-01, -1.6060e+00, -5.0799e-01],\n",
      "        [ 2.8963e+00, -1.9389e+00, -2.7332e+00,  2.1655e+00, -3.4648e-01,\n",
      "         -5.7840e-01, -2.2705e+00, -9.9033e-01, -3.4582e+00, -5.8871e-01],\n",
      "        [ 4.6244e+00, -8.7691e-02, -5.8880e+00,  2.9971e-03, -1.1177e+00,\n",
      "          4.4539e-01,  1.9680e+00, -8.0464e-01, -1.9059e+00,  8.6118e-01],\n",
      "        [ 1.8974e-02,  9.8392e-01, -1.9960e+00, -5.6778e-01, -1.8185e+00,\n",
      "          1.3859e+00, -1.7587e+00, -1.7132e+00, -2.4272e+00,  8.1143e-01],\n",
      "        [ 1.1541e+00,  9.2288e-01, -2.5059e+00,  2.7276e-01, -2.2028e+00,\n",
      "          6.8515e-01,  2.5344e+00,  6.1784e-01, -2.1907e+00,  2.5139e-01],\n",
      "        [ 8.8863e-01, -1.3628e+00, -3.1617e+00, -1.2554e+00, -8.3035e-01,\n",
      "         -5.6490e-01,  1.2833e-01, -2.4420e-01, -2.5820e-01,  8.1066e-01],\n",
      "        [ 3.6907e+00, -2.3467e-02, -4.1077e+00,  1.4152e+00, -4.8655e-01,\n",
      "          2.6291e-02, -1.4362e+00,  5.1400e-01, -5.3548e+00, -1.0267e-01],\n",
      "        [ 5.1979e-01,  3.6157e-01, -3.9418e+00, -5.8280e-01, -7.4988e-01,\n",
      "          5.7813e-01, -2.1588e+00, -5.7772e-02, -9.8089e-01, -7.0667e-01]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 3.0407e+00, -9.4090e-01, -7.7606e+00, -4.4884e-01,  1.2144e+00,\n",
      "          2.0335e+00,  2.3982e-01, -3.1188e-01, -4.6000e+00, -1.2278e+00],\n",
      "        [ 3.8857e+00, -2.1588e-01, -8.0756e+00,  1.7754e+00, -1.6461e+00,\n",
      "          2.5144e+00, -1.5102e+00, -3.9295e-01, -5.1568e+00,  2.5783e-01],\n",
      "        [ 2.4733e+00,  5.2570e-01, -3.2230e+00, -2.4308e-01, -4.6965e-01,\n",
      "          3.3051e-01, -1.0441e+00,  4.7854e-01,  2.2393e-01,  8.5947e-01],\n",
      "        [ 3.1372e+00, -2.8095e-01, -3.4550e+00,  1.4800e+00, -4.3365e-01,\n",
      "         -8.5897e-01, -2.1755e-01, -6.9670e-01, -4.9960e-01, -1.3064e+00],\n",
      "        [ 1.8108e+00,  5.0826e-01, -2.3793e+00,  5.5754e-01, -2.6300e-01,\n",
      "          9.5574e-01, -2.8494e-02, -1.9921e+00, -4.1166e+00, -7.6748e-01],\n",
      "        [ 4.5352e+00,  7.6271e-01, -7.0911e+00,  3.0721e+00,  1.7022e-01,\n",
      "         -2.3601e-01, -1.6577e+00, -1.6835e+00, -3.3861e+00,  9.7677e-01],\n",
      "        [ 2.7822e+00, -1.0838e+00, -2.0333e+00, -5.6300e-01, -6.1111e-01,\n",
      "         -7.9136e-01,  3.3473e-01, -9.2837e-01, -6.3978e-01,  3.6266e-01],\n",
      "        [ 1.5389e+00, -1.1496e+00, -2.1743e+00,  1.4907e+00,  2.2408e-01,\n",
      "         -4.4046e-01, -3.4692e-01, -3.7592e-01, -1.8490e+00,  7.1709e-01],\n",
      "        [ 3.4036e+00,  9.8664e-01, -4.5518e+00, -5.8680e-01,  1.0003e-01,\n",
      "         -7.6377e-01, -2.1013e+00, -1.1921e+00, -2.2975e+00, -2.2352e+00],\n",
      "        [ 3.6728e+00, -4.2652e-01, -6.5083e+00,  1.5799e+00,  6.3734e-01,\n",
      "         -1.3893e+00, -1.1023e+00, -1.5576e+00, -4.9650e+00,  6.5274e-01],\n",
      "        [ 5.7071e-01,  1.0746e+00, -2.2639e+00,  8.9716e-01, -2.6530e-01,\n",
      "         -4.9046e-03, -4.9504e-01,  1.0284e+00, -2.0339e+00, -1.0908e+00],\n",
      "        [ 2.0466e+00, -1.1161e+00, -2.3265e+00,  2.5477e+00, -1.7166e+00,\n",
      "          1.2430e-01, -1.7520e-01, -1.3696e-01, -2.8661e+00, -1.3842e+00],\n",
      "        [ 2.0648e+00,  6.6585e-02, -5.2403e+00,  2.1434e+00, -8.4789e-01,\n",
      "         -8.1214e-01, -1.4532e+00,  5.7650e-01, -2.6310e+00, -1.1758e+00],\n",
      "        [ 9.7969e-01, -6.2180e-01, -3.8730e+00,  9.2957e-01, -9.5333e-01,\n",
      "         -2.6738e-01, -3.4843e-01, -2.0256e+00, -2.4915e+00, -1.2185e-01],\n",
      "        [ 1.1555e+00,  1.2105e+00, -5.1751e+00,  1.5216e+00,  3.1949e-01,\n",
      "          1.6006e-01, -1.8238e-01, -1.2702e+00, -5.1064e+00,  8.7443e-01],\n",
      "        [ 4.5683e+00,  7.4856e-01, -6.4245e+00, -5.9099e-01, -1.3669e+00,\n",
      "          2.2332e-01, -2.3216e+00, -1.7040e+00, -2.9215e+00,  5.1424e-01],\n",
      "        [ 8.5891e-01, -8.6285e-02, -2.1547e+00,  6.1263e-01, -1.8740e+00,\n",
      "         -1.2687e-02, -4.2477e-01, -3.5797e-01, -1.3674e+00,  8.3443e-01],\n",
      "        [ 1.0563e+00,  6.7175e-01, -1.3122e+00, -1.5327e+00, -2.0022e+00,\n",
      "          1.2437e+00, -3.2287e-01, -8.5957e-01,  9.6246e-02, -7.5103e-01],\n",
      "        [ 3.2805e+00,  1.0287e+00, -4.6877e+00,  1.4479e+00, -7.1537e-01,\n",
      "         -4.5533e-01, -1.6661e+00, -1.4263e+00, -2.4918e+00, -1.9965e+00],\n",
      "        [ 2.9689e+00,  5.3449e-01, -4.4202e+00,  1.4345e+00,  3.3461e-02,\n",
      "          6.0276e-03, -3.1334e+00, -3.5927e-01, -1.6060e+00, -5.0799e-01],\n",
      "        [ 2.8963e+00, -1.9389e+00, -2.7332e+00,  2.1655e+00, -3.4648e-01,\n",
      "         -5.7840e-01, -2.2705e+00, -9.9033e-01, -3.4582e+00, -5.8871e-01],\n",
      "        [ 4.6244e+00, -8.7691e-02, -5.8880e+00,  2.9971e-03, -1.1177e+00,\n",
      "          4.4539e-01,  1.9680e+00, -8.0464e-01, -1.9059e+00,  8.6118e-01],\n",
      "        [ 1.8974e-02,  9.8392e-01, -1.9960e+00, -5.6778e-01, -1.8185e+00,\n",
      "          1.3859e+00, -1.7587e+00, -1.7132e+00, -2.4272e+00,  8.1143e-01],\n",
      "        [ 1.1541e+00,  9.2288e-01, -2.5059e+00,  2.7276e-01, -2.2028e+00,\n",
      "          6.8515e-01,  2.5344e+00,  6.1784e-01, -2.1907e+00,  2.5139e-01],\n",
      "        [ 8.8863e-01, -1.3628e+00, -3.1617e+00, -1.2554e+00, -8.3035e-01,\n",
      "         -5.6490e-01,  1.2833e-01, -2.4420e-01, -2.5820e-01,  8.1066e-01],\n",
      "        [ 3.6907e+00, -2.3467e-02, -4.1077e+00,  1.4152e+00, -4.8655e-01,\n",
      "          2.6291e-02, -1.4362e+00,  5.1400e-01, -5.3548e+00, -1.0267e-01],\n",
      "        [ 5.1979e-01,  3.6157e-01, -3.9418e+00, -5.8280e-01, -7.4988e-01,\n",
      "          5.7813e-01, -2.1588e+00, -5.7772e-02, -9.8089e-01, -7.0667e-01]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(C[Xtrain].shape)\n",
    "\n",
    "#  Emb   X   W1\n",
    "# m x n     n x p\n",
    "\n",
    "w1_n_neurons = 2000\n",
    "\n",
    "#W1 = torch.randn((context_size*n_crammed_dimensions, w1_n_neurons)) * ((5/3) / (vocab_size*n_crammed_dimensions**0.5))\n",
    "linear1 = nn.Linear(in_features=context_size*n_crammed_dimensions, out_features=w1_n_neurons, bias=True, device=device)\n",
    "#b1 = torch.randn((w1_n_neurons)) * 0.01\n",
    "# #No need for b1 because of batch normalization\n",
    "\n",
    "#W2 = torch.randn((w1_n_neurons, vocab_size)) * 0.01\n",
    "#b2 = torch.randn((vocab_size)) * 0\n",
    "linear2 = nn.Linear(in_features=w1_n_neurons, out_features=vocab_size, bias=True)\n",
    "\n",
    "params = [C, linear1, linear2]\n",
    "for param in params:\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/evie/torching/llmBasics/MLPpt2/torchingMPL.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLPpt2/torchingMPL.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLPpt2/torchingMPL.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/evie/torching/llmBasics/MLPpt2/torchingMPL.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     param\u001b[39m.\u001b[39;49mdata \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m lr \u001b[39m*\u001b[39m param\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 1000\n",
    "\n",
    "lr = -0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for param in params:\n",
    "        param.grad = None\n",
    "\n",
    "    batch = torch.randint(0, Xtrain.shape[0], (batch_size,))\n",
    "    emb = C[Xtrain[batch]].view(-1, context_size*n_crammed_dimensions)\n",
    "    #hpreact = emb @ W1 + b1\n",
    "    hpreact = linear1(emb)\n",
    "    h = torch.tanh(hpreact)\n",
    "    #logits = h @ W2 + b2\n",
    "    logits = linear2(h)\n",
    "    loss = F.cross_entropy(logits, Ytrain[batch])\n",
    "    loss.backward()\n",
    "\n",
    "    #for param in params:\n",
    "        #param.data += lr * param.grad\n",
    "    C.data += lr * C.grad\n",
    "    linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4326, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#Eval loss\n",
    "with torch.no_grad():\n",
    "    emb = C[Xeval].view(-1, context_size*n_crammed_dimensions)\n",
    "    hpreact = emb @ W1 + b1\n",
    "    h = torch.tanh(hpreact)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Yeval)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
