{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9bf803",
   "metadata": {
    "papermill": {
     "duration": 0.016081,
     "end_time": "2024-07-09T20:09:35.560229",
     "exception": false,
     "start_time": "2024-07-09T20:09:35.544148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction (WIP)\n",
    "- This notebook is based on the \"Let's build GPT: from scratch, in code, spelled out\" tutorial by Andrej Karpathy. You can find the tutorial here --> https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7\n",
    "- There are several different approaches in this notebook that do not strictly follow the original video. Some implementations are my own.\n",
    "- I am using the same shakespeare text as in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e391c3",
   "metadata": {
    "papermill": {
     "duration": 0.015366,
     "end_time": "2024-07-09T20:09:35.592152",
     "exception": false,
     "start_time": "2024-07-09T20:09:35.576786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fb54c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:35.625386Z",
     "iopub.status.busy": "2024-07-09T20:09:35.624963Z",
     "iopub.status.idle": "2024-07-09T20:09:39.537763Z",
     "shell.execute_reply": "2024-07-09T20:09:39.536664Z"
    },
    "papermill": {
     "duration": 3.932755,
     "end_time": "2024-07-09T20:09:39.540512",
     "exception": false,
     "start_time": "2024-07-09T20:09:35.607757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea34174",
   "metadata": {
    "papermill": {
     "duration": 0.015628,
     "end_time": "2024-07-09T20:09:39.572590",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.556962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fdb089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.607512Z",
     "iopub.status.busy": "2024-07-09T20:09:39.606799Z",
     "iopub.status.idle": "2024-07-09T20:09:39.616828Z",
     "shell.execute_reply": "2024-07-09T20:09:39.615425Z"
    },
    "papermill": {
     "duration": 0.029609,
     "end_time": "2024-07-09T20:09:39.619329",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.589720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "generator = torch.Generator(device=device)\n",
    "print(f\"default device set to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590bf6f",
   "metadata": {
    "papermill": {
     "duration": 0.016024,
     "end_time": "2024-07-09T20:09:39.651494",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.635470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dce447d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.685976Z",
     "iopub.status.busy": "2024-07-09T20:09:39.685544Z",
     "iopub.status.idle": "2024-07-09T20:09:39.736235Z",
     "shell.execute_reply": "2024-07-09T20:09:39.734724Z"
    },
    "papermill": {
     "duration": 0.070821,
     "end_time": "2024-07-09T20:09:39.738945",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.668124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "with open(\"/kaggle/input/shakespeare/input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324da3ce",
   "metadata": {
    "papermill": {
     "duration": 0.016531,
     "end_time": "2024-07-09T20:09:39.772574",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.756043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582abd83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.809519Z",
     "iopub.status.busy": "2024-07-09T20:09:39.809059Z",
     "iopub.status.idle": "2024-07-09T20:09:39.816192Z",
     "shell.execute_reply": "2024-07-09T20:09:39.815136Z"
    },
    "papermill": {
     "duration": 0.029094,
     "end_time": "2024-07-09T20:09:39.819231",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.790137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: v for v, c in enumerate(vocab)}\n",
    "itos = {v: c for c, v in stoi.items()}\n",
    "print(stoi[\"h\"])\n",
    "print(itos[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "779d757e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.854247Z",
     "iopub.status.busy": "2024-07-09T20:09:39.853223Z",
     "iopub.status.idle": "2024-07-09T20:09:39.860539Z",
     "shell.execute_reply": "2024-07-09T20:09:39.859366Z"
    },
    "papermill": {
     "duration": 0.027927,
     "end_time": "2024-07-09T20:09:39.863441",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.835514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 6, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12, 2]\n",
      "hello, how are you?!\n"
     ]
    }
   ],
   "source": [
    "encode = lambda d: [stoi[idx] for idx in d]\n",
    "decode = lambda e: \"\".join([itos[idx] for idx in e])\n",
    "\n",
    "encoded = encode(\"hello, how are you?!\")\n",
    "decoded = decode(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8561e2",
   "metadata": {
    "papermill": {
     "duration": 0.016356,
     "end_time": "2024-07-09T20:09:39.897077",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.880721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562058f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.932370Z",
     "iopub.status.busy": "2024-07-09T20:09:39.931942Z",
     "iopub.status.idle": "2024-07-09T20:09:39.937713Z",
     "shell.execute_reply": "2024-07-09T20:09:39.936602Z"
    },
    "papermill": {
     "duration": 0.026591,
     "end_time": "2024-07-09T20:09:39.940250",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.913659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_size = 8\n",
    "n_embd = 5\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66978960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:39.975161Z",
     "iopub.status.busy": "2024-07-09T20:09:39.974774Z",
     "iopub.status.idle": "2024-07-09T20:09:39.982478Z",
     "shell.execute_reply": "2024-07-09T20:09:39.981123Z"
    },
    "papermill": {
     "duration": 0.028335,
     "end_time": "2024-07-09T20:09:39.985052",
     "exception": false,
     "start_time": "2024-07-09T20:09:39.956717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(text, context_size):\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "    #random_idx = torch.randint(0, len(data)-context_size, (int(len(data)/context_size),))\n",
    "    random_idx = torch.randperm(len(data)-context_size)\n",
    "    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx])\n",
    "    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx])\n",
    "\n",
    "    return TensorDataset(inputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4002377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:40.020183Z",
     "iopub.status.busy": "2024-07-09T20:09:40.019795Z",
     "iopub.status.idle": "2024-07-09T20:09:40.085893Z",
     "shell.execute_reply": "2024-07-09T20:09:40.084728Z"
    },
    "papermill": {
     "duration": 0.086865,
     "end_time": "2024-07-09T20:09:40.088598",
     "exception": false,
     "start_time": "2024-07-09T20:09:40.001733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 9, 0, 3, 4, 9, 2, 8, 3, 9])\n",
      "tensor([5, 0, 8, 3, 6, 9, 1, 4, 2, 7])\n"
     ]
    }
   ],
   "source": [
    "# sicne randint might give the same random_idx, randperm is going to be preffered\n",
    "print(torch.randint(0, 10, (10,)))\n",
    "print(torch.randperm(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9a2db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:40.125029Z",
     "iopub.status.busy": "2024-07-09T20:09:40.123950Z",
     "iopub.status.idle": "2024-07-09T20:09:47.447520Z",
     "shell.execute_reply": "2024-07-09T20:09:47.446162Z"
    },
    "papermill": {
     "duration": 7.344787,
     "end_time": "2024-07-09T20:09:47.450609",
     "exception": false,
     "start_time": "2024-07-09T20:09:40.105822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(text=text[:100000], context_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2640a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:47.487905Z",
     "iopub.status.busy": "2024-07-09T20:09:47.487287Z",
     "iopub.status.idle": "2024-07-09T20:09:47.501796Z",
     "shell.execute_reply": "2024-07-09T20:09:47.500459Z"
    },
    "papermill": {
     "duration": 0.036136,
     "end_time": "2024-07-09T20:09:47.504902",
     "exception": false,
     "start_time": "2024-07-09T20:09:47.468766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.8)\n",
    "test_split = int(len(dataset)-train_split)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fc0ee00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:47.542574Z",
     "iopub.status.busy": "2024-07-09T20:09:47.542134Z",
     "iopub.status.idle": "2024-07-09T20:09:47.548727Z",
     "shell.execute_reply": "2024-07-09T20:09:47.547588Z"
    },
    "papermill": {
     "duration": 0.028033,
     "end_time": "2024-07-09T20:09:47.551197",
     "exception": false,
     "start_time": "2024-07-09T20:09:47.523164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, generator=generator)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a19207",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:47.587487Z",
     "iopub.status.busy": "2024-07-09T20:09:47.586376Z",
     "iopub.status.idle": "2024-07-09T20:09:47.592591Z",
     "shell.execute_reply": "2024-07-09T20:09:47.591202Z"
    },
    "papermill": {
     "duration": 0.027608,
     "end_time": "2024-07-09T20:09:47.595726",
     "exception": false,
     "start_time": "2024-07-09T20:09:47.568118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_from_data(dataloader):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #print(f\"batch {batch}, input {X}, label {y}\")\n",
    "        #print(batch)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb80a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:47.632350Z",
     "iopub.status.busy": "2024-07-09T20:09:47.631901Z",
     "iopub.status.idle": "2024-07-09T20:09:48.389769Z",
     "shell.execute_reply": "2024-07-09T20:09:48.388642Z"
    },
    "papermill": {
     "duration": 0.779555,
     "end_time": "2024-07-09T20:09:48.392714",
     "exception": false,
     "start_time": "2024-07-09T20:09:47.613159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_from_data(dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca309b",
   "metadata": {
    "papermill": {
     "duration": 0.01679,
     "end_time": "2024-07-09T20:09:48.427236",
     "exception": false,
     "start_time": "2024-07-09T20:09:48.410446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95e44b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:48.464040Z",
     "iopub.status.busy": "2024-07-09T20:09:48.463007Z",
     "iopub.status.idle": "2024-07-09T20:09:48.479685Z",
     "shell.execute_reply": "2024-07-09T20:09:48.478438Z"
    },
    "papermill": {
     "duration": 0.037939,
     "end_time": "2024-07-09T20:09:48.482394",
     "exception": false,
     "start_time": "2024-07-09T20:09:48.444455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, context_size, n_embd, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # B x T x C; B --> batches, T --> time (context_size), C --> n_embd\n",
    "        self.pos_embedding_table = nn.Embedding(context_size, n_embd) # T x C; this is from the posisitional encoding part of the video\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=context_size*n_embd, out_features=8*8) # B x T*C @ T*C x H; H --> number of hidden_units\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = idx.shape\n",
    "        C = self.n_embd\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        x = self.token_embedding_table(idx) + self.pos_embedding_table(positions)\n",
    "        x = x.view(B, T*C)\n",
    "\n",
    "        x = self.act_fn(self.linear1(x))\n",
    "        x = self.act_fn(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, idx: torch.Tensor, randomize: bool, max_length: int, num_samples: int) -> torch.Tensor:\n",
    "        outputs = []\n",
    "        for sample in range(num_samples):\n",
    "            full_text = \"\" \n",
    "            for i in range(max_length):\n",
    "                logits = self(idx)\n",
    "                percents = torch.softmax(logits, dim=1)\n",
    "\n",
    "                if randomize:\n",
    "                    pred = torch.multinomial(percents, num_samples=1)\n",
    "                    full_text += decode(pred.tolist()[0])\n",
    "                    idx = torch.cat([idx[:, 1:], pred], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                else:\n",
    "                    pred = torch.argmax(percents)\n",
    "                    full_text += decode([pred.item()])\n",
    "                    idx = torch.cat([idx[:, 1:], pred.view(1, 1)], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                    # in the argmax the output is a single element, pred.view(1, 1) turns it into a batch of dim 1, so it can be concatenated to the previous context\n",
    "\n",
    "            outputs.append(full_text)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc8357",
   "metadata": {
    "papermill": {
     "duration": 0.016828,
     "end_time": "2024-07-09T20:09:48.517322",
     "exception": false,
     "start_time": "2024-07-09T20:09:48.500494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the base model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2489e1fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:48.615364Z",
     "iopub.status.busy": "2024-07-09T20:09:48.614929Z",
     "iopub.status.idle": "2024-07-09T20:09:50.294868Z",
     "shell.execute_reply": "2024-07-09T20:09:50.293394Z"
    },
    "papermill": {
     "duration": 1.763833,
     "end_time": "2024-07-09T20:09:50.298360",
     "exception": false,
     "start_time": "2024-07-09T20:09:48.534527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLP(context_size=context_size, n_embd=n_embd, vocab_size=vocab_size)\n",
    "optimizer = torch.optim.Adam(params=mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304182c",
   "metadata": {
    "papermill": {
     "duration": 0.017471,
     "end_time": "2024-07-09T20:09:50.333747",
     "exception": false,
     "start_time": "2024-07-09T20:09:50.316276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Take samples from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eceb990c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:50.370967Z",
     "iopub.status.busy": "2024-07-09T20:09:50.370463Z",
     "iopub.status.idle": "2024-07-09T20:09:50.458970Z",
     "shell.execute_reply": "2024-07-09T20:09:50.457570Z"
    },
    "papermill": {
     "duration": 0.110734,
     "end_time": "2024-07-09T20:09:50.461792",
     "exception": false,
     "start_time": "2024-07-09T20:09:50.351058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:v'h.KN&K \n",
      "\n",
      "\n",
      "OU$Ad;k?'A \n",
      "\n",
      "\n",
      "cK$lvGfjb: \n",
      "\n",
      "\n",
      "-xI3bDZKL  \n",
      "\n",
      "\n",
      ":Y!:uoCJEx \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def model_sampler(model, context, randomize, max_length, num_samples):\n",
    "    #print(len(context))\n",
    "    #print(context_size)\n",
    "    test = torch.tensor([[20, 53, 61,  1, 39, 56, 58, 39]])\n",
    "    #print(test[:, 1:])\n",
    "    result = torch.cat((test[:, 1:], torch.tensor([[99]])), dim=1)\n",
    "    #print(result)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    mlp.eval()\n",
    "    idx = torch.tensor(encode(context), dtype=torch.long).view(1, len(encode(context))) # inputs must be batched\n",
    "    outputs = mlp.generate(idx=idx, randomize=randomize, max_length=max_length, num_samples=num_samples)\n",
    "    for output in outputs:\n",
    "        print(f\"{output} \\n\\n\")\n",
    "\n",
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=10, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597a259",
   "metadata": {
    "papermill": {
     "duration": 0.017954,
     "end_time": "2024-07-09T20:09:50.497758",
     "exception": false,
     "start_time": "2024-07-09T20:09:50.479804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5cf9371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:50.535646Z",
     "iopub.status.busy": "2024-07-09T20:09:50.535202Z",
     "iopub.status.idle": "2024-07-09T20:09:50.543227Z",
     "shell.execute_reply": "2024-07-09T20:09:50.541883Z"
    },
    "papermill": {
     "duration": 0.029745,
     "end_time": "2024-07-09T20:09:50.545693",
     "exception": false,
     "start_time": "2024-07-09T20:09:50.515948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in tqdm(enumerate(dataloader)):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y[:, -1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e8d5f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:50.582683Z",
     "iopub.status.busy": "2024-07-09T20:09:50.582238Z",
     "iopub.status.idle": "2024-07-09T20:09:59.726937Z",
     "shell.execute_reply": "2024-07-09T20:09:59.725811Z"
    },
    "papermill": {
     "duration": 9.167522,
     "end_time": "2024-07-09T20:09:59.730703",
     "exception": false,
     "start_time": "2024-07-09T20:09:50.563181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.146660804748535 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [00:01, 268.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 200 --> 3.1106534004211426 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "447it [00:01, 268.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 400 --> 2.642275810241699 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "646it [00:02, 272.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 600 --> 2.6673550605773926 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "847it [00:03, 283.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 800 --> 2.695472002029419 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1050it [00:03, 280.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1000 --> 2.1004154682159424 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1255it [00:04, 282.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1200 --> 2.489316463470459 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1457it [00:05, 280.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1400 --> 1.9982508420944214 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1631it [00:06, 283.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1600 --> 2.2123279571533203 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1833it [00:06, 274.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1800 --> 2.3320584297180176 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2031it [00:07, 278.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2000 --> 2.4104225635528564 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2234it [00:08, 284.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2200 --> 2.572524309158325 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2436it [00:08, 279.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2400 --> 2.1622660160064697 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [00:09, 273.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the very last batch --> 1.9016098976135254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.train()\n",
    "train_model(model=mlp, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad28043",
   "metadata": {
    "papermill": {
     "duration": 0.027576,
     "end_time": "2024-07-09T20:09:59.785567",
     "exception": false,
     "start_time": "2024-07-09T20:09:59.757991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0caaba6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:59.842857Z",
     "iopub.status.busy": "2024-07-09T20:09:59.842436Z",
     "iopub.status.idle": "2024-07-09T20:09:59.850083Z",
     "shell.execute_reply": "2024-07-09T20:09:59.848948Z"
    },
    "papermill": {
     "duration": 0.039721,
     "end_time": "2024-07-09T20:09:59.852780",
     "exception": false,
     "start_time": "2024-07-09T20:09:59.813059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def model_inference(model, dataloader):\n",
    "    mlp.eval()\n",
    "    X, y = next(iter(dataloader))\n",
    "    logits = model(X)\n",
    "    percents = torch.softmax(logits, dim=1) # dim=1 since the input was batched\n",
    "    preds = torch.argmax(percents, dim=1) # dim=1 since the input was batched\n",
    "    print(f\"for {X} \\n model predicted {preds}\")\n",
    "    print(f\"expected --> {y[:, -1]}\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9792319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:59.911228Z",
     "iopub.status.busy": "2024-07-09T20:09:59.910835Z",
     "iopub.status.idle": "2024-07-09T20:09:59.925016Z",
     "shell.execute_reply": "2024-07-09T20:09:59.923146Z"
    },
    "papermill": {
     "duration": 0.046063,
     "end_time": "2024-07-09T20:09:59.927718",
     "exception": false,
     "start_time": "2024-07-09T20:09:59.881655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for tensor([[58, 46, 39, 52,  1, 47, 42, 50],\n",
      "        [57, 39, 60, 43, 42,  0, 37, 53],\n",
      "        [47, 41, 46,  1, 46, 43,  0, 42],\n",
      "        [ 0, 13, 57,  1, 39, 52, 63,  1],\n",
      "        [43, 52,  1, 54, 53, 59, 52, 42],\n",
      "        [51, 47, 50, 50, 47, 53, 52, 57],\n",
      "        [43,  5, 57,  1, 57, 58, 39, 58],\n",
      "        [ 1, 63, 53, 59, 56,  1, 41, 53],\n",
      "        [53, 50, 42,  7, 47, 52,  1, 58],\n",
      "        [51, 63,  1, 42, 43, 57, 47, 56],\n",
      "        [47, 58, 58, 50, 43,  1, 55, 59],\n",
      "        [41, 43, 57, 57, 53, 56, 57,  1],\n",
      "        [ 1, 44, 47, 52, 43,  1, 57, 54],\n",
      "        [61, 53, 59, 50, 42,  1, 44, 53],\n",
      "        [10,  0, 37, 53, 59,  1, 39, 56],\n",
      "        [57,  6,  0, 13, 57,  1,  5, 58],\n",
      "        [ 0, 40, 43, 52, 41, 46, 43, 56],\n",
      "        [13, 10,  0, 31, 61, 43, 43, 58],\n",
      "        [52, 42, 47, 52, 45,  1, 46, 43],\n",
      "        [33, 31, 10,  0, 35, 43, 50, 50],\n",
      "        [63, 53, 59,  1, 58, 46, 47, 57],\n",
      "        [41, 43,  1, 58, 53,  1, 57, 43],\n",
      "        [63, 43, 58, 12,  0, 27,  1, 51],\n",
      "        [45, 46, 58, 47, 52, 45, 10,  0],\n",
      "        [47, 57,  1, 39, 44, 58, 43, 56],\n",
      "        [60, 43,  1, 40, 43, 43, 52,  1],\n",
      "        [ 1, 46, 39, 42,  1, 46, 43,  1],\n",
      "        [32, 46, 43,  1, 41, 59, 57, 58],\n",
      "        [53,  1, 40, 43,  1, 54, 56, 53],\n",
      "        [39, 41, 46, 43, 57,  0, 32, 53],\n",
      "        [43,  0, 35, 47, 58, 46,  1, 54],\n",
      "        [58, 46, 43,  1, 41, 53, 52, 58]]) \n",
      " model predicted tensor([58, 59, 53, 58,  1,  1,  1, 59, 46, 43, 58, 58, 57, 59,  1,  1, 43,  1,\n",
      "        58, 50,  1, 57, 43, 13, 57, 58, 58,  1, 59, 50, 53,  1])\n",
      "expected --> tensor([63, 59, 47, 43, 57,  6, 59, 52, 46, 43, 43, 46, 53, 56, 43, 47,  1,  1,\n",
      "        56,  6, 12, 52, 63, 15, 52, 58, 42, 53, 59,  1, 56, 39])\n",
      "tensor([[46, 39, 52,  1, 47, 42, 50, 63],\n",
      "        [39, 60, 43, 42,  0, 37, 53, 59],\n",
      "        [41, 46,  1, 46, 43,  0, 42, 47],\n",
      "        [13, 57,  1, 39, 52, 63,  1, 43],\n",
      "        [52,  1, 54, 53, 59, 52, 42, 57],\n",
      "        [47, 50, 50, 47, 53, 52, 57,  6],\n",
      "        [ 5, 57,  1, 57, 58, 39, 58, 59],\n",
      "        [63, 53, 59, 56,  1, 41, 53, 52],\n",
      "        [50, 42,  7, 47, 52,  1, 58, 46],\n",
      "        [63,  1, 42, 43, 57, 47, 56, 43],\n",
      "        [58, 58, 50, 43,  1, 55, 59, 43],\n",
      "        [43, 57, 57, 53, 56, 57,  1, 46],\n",
      "        [44, 47, 52, 43,  1, 57, 54, 53],\n",
      "        [53, 59, 50, 42,  1, 44, 53, 56],\n",
      "        [ 0, 37, 53, 59,  1, 39, 56, 43],\n",
      "        [ 6,  0, 13, 57,  1,  5, 58, 47],\n",
      "        [40, 43, 52, 41, 46, 43, 56,  1],\n",
      "        [10,  0, 31, 61, 43, 43, 58,  1],\n",
      "        [42, 47, 52, 45,  1, 46, 43, 56],\n",
      "        [31, 10,  0, 35, 43, 50, 50,  6],\n",
      "        [53, 59,  1, 58, 46, 47, 57, 12],\n",
      "        [43,  1, 58, 53,  1, 57, 43, 52],\n",
      "        [43, 58, 12,  0, 27,  1, 51, 63],\n",
      "        [46, 58, 47, 52, 45, 10,  0, 15],\n",
      "        [57,  1, 39, 44, 58, 43, 56, 52],\n",
      "        [43,  1, 40, 43, 43, 52,  1, 58],\n",
      "        [46, 39, 42,  1, 46, 43,  1, 42],\n",
      "        [46, 43,  1, 41, 59, 57, 58, 53],\n",
      "        [ 1, 40, 43,  1, 54, 56, 53, 59],\n",
      "        [41, 46, 43, 57,  0, 32, 53,  1],\n",
      "        [ 0, 35, 47, 58, 46,  1, 54, 56],\n",
      "        [46, 43,  1, 41, 53, 52, 58, 39]])\n"
     ]
    }
   ],
   "source": [
    "model_inference(model=mlp, dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31693c7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:09:59.985882Z",
     "iopub.status.busy": "2024-07-09T20:09:59.985496Z",
     "iopub.status.idle": "2024-07-09T20:10:00.195127Z",
     "shell.execute_reply": "2024-07-09T20:10:00.193916Z"
    },
    "papermill": {
     "duration": 0.242549,
     "end_time": "2024-07-09T20:10:00.198466",
     "exception": false,
     "start_time": "2024-07-09T20:09:59.955917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faks. ive ancen he, he sat yacagou;d, fou, bes honl:\n",
      "Bf\n",
      "MS.RAeI,ar fones\n",
      "AAn bust be coucou',\n",
      "Hat st lo,\n",
      " have\n",
      "iouled, voup stselt, boce iut,\n",
      "Aars, tounw, pseceetoud? trsintt, nt itotds-and tombland\n",
      "Yuld;oot\n",
      "\n",
      "Sen, srdedls, ofped\n",
      "Mulf at torim.\n",
      "\n",
      "MTUENENWpps pine dolledet!'e nements,, pe kithit s bo sha inud lou fo't bt furaes\n",
      "Loat\n",
      "Aad oms ppouedst. amkt ham;;d.\n",
      "\n",
      "MANENIUIChon, oru poik cou heu.\n",
      "\n",
      "BlUIM:NE'rUestep; po ton. wamkml.\n",
      "WhMLO,:\n",
      "LEOICNIUS:\n",
      "Hertill, hes sa'te tous.,ar nrhard in sou.\n",
      "\n",
      "Forl:, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=500, num_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a62f6",
   "metadata": {
    "papermill": {
     "duration": 0.028531,
     "end_time": "2024-07-09T20:10:00.255362",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.226831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ade4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.313166Z",
     "iopub.status.busy": "2024-07-09T20:10:00.312787Z",
     "iopub.status.idle": "2024-07-09T20:10:00.322693Z",
     "shell.execute_reply": "2024-07-09T20:10:00.321355Z"
    },
    "papermill": {
     "duration": 0.042104,
     "end_time": "2024-07-09T20:10:00.325192",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.283088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 8\n",
      "torch.Size([32, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "print(B, T)\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "638302dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.384985Z",
     "iopub.status.busy": "2024-07-09T20:10:00.384562Z",
     "iopub.status.idle": "2024-07-09T20:10:00.419268Z",
     "shell.execute_reply": "2024-07-09T20:10:00.417780Z"
    },
    "papermill": {
     "duration": 0.068297,
     "end_time": "2024-07-09T20:10:00.422100",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.353803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.7152, -1.6628,  1.9220, -0.5699],\n",
      "         [-1.8801, -1.7981, -0.3845, -0.4875],\n",
      "         [-0.8771, -1.0641, -0.4788,  0.0515],\n",
      "         ...,\n",
      "         [-0.1167, -0.4897, -0.4951, -0.1277],\n",
      "         [-0.0074, -0.4484, -0.5282, -0.2701],\n",
      "         [ 0.0087, -0.3526, -0.4009, -0.1639]],\n",
      "\n",
      "        [[ 1.4021, -0.3635, -1.8786,  0.0854],\n",
      "         [ 1.0147, -0.3344, -0.3362, -0.1383],\n",
      "         [ 1.1161, -0.1369, -0.3775, -0.2427],\n",
      "         ...,\n",
      "         [ 0.4374, -0.1645, -0.0404,  0.1385],\n",
      "         [ 0.0827, -0.4172, -0.4191,  0.0608],\n",
      "         [ 0.0466, -0.4464, -0.6699,  0.2086]],\n",
      "\n",
      "        [[ 1.1288,  0.4040, -0.6674,  1.1294],\n",
      "         [ 0.4700, -0.6070, -0.4009,  0.8013],\n",
      "         [ 0.5224, -0.5065,  0.1348,  0.4135],\n",
      "         ...,\n",
      "         [ 0.7478, -0.3227, -0.3659,  0.7559],\n",
      "         [ 0.5560, -0.1962, -0.1366,  0.6243],\n",
      "         [ 0.3498, -0.2706,  0.0725,  0.5135]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3887, -0.4573, -0.0542,  2.0803],\n",
      "         [-0.8473, -0.7564, -0.1124,  1.1075],\n",
      "         [-0.6278, -1.0436, -0.1197,  0.8960],\n",
      "         ...,\n",
      "         [-0.0721, -0.5802, -0.3254, -0.0811],\n",
      "         [ 0.0711, -0.6233, -0.5262, -0.0167],\n",
      "         [ 0.0218, -0.7245, -0.4842,  0.0480]],\n",
      "\n",
      "        [[-1.0933, -0.7916,  1.5362, -0.2617],\n",
      "         [-0.2330, -0.5485,  1.3712, -0.3119],\n",
      "         [-0.0560, -0.7668,  1.2593, -0.6907],\n",
      "         ...,\n",
      "         [-0.2050, -0.6787,  0.3307, -0.4330],\n",
      "         [-0.3319, -0.6948,  0.5029, -0.4085],\n",
      "         [-0.2120, -0.6461,  0.5908, -0.4027]],\n",
      "\n",
      "        [[-0.8056,  1.6414,  0.6032, -1.2154],\n",
      "         [ 0.1616,  1.0227, -0.0321, -0.0430],\n",
      "         [ 0.3168,  0.5800,  0.3807, -0.1494],\n",
      "         ...,\n",
      "         [-0.3702, -0.2139,  0.6833, -0.2076],\n",
      "         [-0.5623, -0.4209,  0.8603, -0.2593],\n",
      "         [-0.3509, -0.3178,  0.6693, -0.0857]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = torch.zeros(size=(B, T, C)) # each of the values has a unique value\n",
    "\n",
    "for batch_idx in range(B):\n",
    "    for context_idx in range(T):\n",
    "        xprev = embedded[batch_idx, :context_idx+1]\n",
    "        bag_of_words[batch_idx, context_idx] = torch.mean(xprev, dim=0)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c104c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.481495Z",
     "iopub.status.busy": "2024-07-09T20:10:00.481048Z",
     "iopub.status.idle": "2024-07-09T20:10:00.495728Z",
     "shell.execute_reply": "2024-07-09T20:10:00.493722Z"
    },
    "papermill": {
     "duration": 0.047716,
     "end_time": "2024-07-09T20:10:00.498554",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.450838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[ 56.,  75.,  73.],\n",
      "        [  7.,   6.,   8.],\n",
      "        [ 42., 117.,  75.]])\n",
      "tensor([[ 56.,  48.,  64.],\n",
      "        [  7.,   6.,   8.],\n",
      "        [ 42., 117.,  75.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 3))\n",
    "tril = torch.tril(ones) # lower triangular part of a matrix\n",
    "print(tril)\n",
    "a = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (2, 3), dtype=torch.float32)\n",
    "matmul_output = a @ b\n",
    "matmul_tril_output = torch.tril(a) @ b\n",
    "print(matmul_output)\n",
    "print(matmul_tril_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "597136d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.559081Z",
     "iopub.status.busy": "2024-07-09T20:10:00.558675Z",
     "iopub.status.idle": "2024-07-09T20:10:00.570476Z",
     "shell.execute_reply": "2024-07-09T20:10:00.569115Z"
    },
    "papermill": {
     "duration": 0.045567,
     "end_time": "2024-07-09T20:10:00.573439",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.527872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[6.0000, 8.0000],\n",
      "        [3.0000, 4.0000],\n",
      "        [4.6667, 3.6667]])\n"
     ]
    }
   ],
   "source": [
    "# do the same as bag of words but with matrix multiplication (dot product)\n",
    "a = torch.ones(size=(3, 3), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "\n",
    "a = torch.tril(a)\n",
    "\"\"\"\n",
    "b = torch.tensor(\n",
    "    [\n",
    "        [2, 7],\n",
    "        [6, 4],\n",
    "        [6, 5]\n",
    "    ], dtype=torch.float32\n",
    ")\n",
    "\"\"\"\n",
    "print(a)\n",
    "a = a/a.sum(dim=1, keepdim=True)\n",
    "print(a)\n",
    "\n",
    "output = a @ b\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74eac718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.633768Z",
     "iopub.status.busy": "2024-07-09T20:10:00.633288Z",
     "iopub.status.idle": "2024-07-09T20:10:00.649608Z",
     "shell.execute_reply": "2024-07-09T20:10:00.648177Z"
    },
    "papermill": {
     "duration": 0.05007,
     "end_time": "2024-07-09T20:10:00.652644",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.602574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 4])\n",
      "torch.Size([8, 8])\n",
      "tensor([[[-0.3020,  0.8613,  0.8509,  1.0694],\n",
      "         [-0.1474,  0.8005, -0.0386,  0.7087],\n",
      "         [ 0.2306,  0.8734,  0.1007,  0.5407],\n",
      "         ...,\n",
      "         [-0.0237,  0.9753,  0.2149,  0.6148],\n",
      "         [-0.1876,  1.1710,  0.3889,  0.6553],\n",
      "         [ 0.1801,  1.2350,  0.3246,  0.6314]],\n",
      "\n",
      "        [[-2.0734,  0.3787, -0.4855, -1.4053],\n",
      "         [-0.6292,  0.5835, -0.7629, -0.4855],\n",
      "         [ 0.0906,  0.8567, -1.0150, -0.4248],\n",
      "         ...,\n",
      "         [-0.2257, -0.0535, -0.1501, -0.4011],\n",
      "         [-0.1924,  0.0598, -0.2613, -0.2940],\n",
      "         [-0.1832,  0.0983, -0.1115, -0.1161]],\n",
      "\n",
      "        [[ 0.9866,  1.0192,  0.3793,  0.2046],\n",
      "         [ 0.0192,  0.2940, -0.0295,  0.1856],\n",
      "         [ 0.2845,  0.4588, -0.3664,  0.2685],\n",
      "         ...,\n",
      "         [ 0.1857,  0.4227, -0.4971,  0.1486],\n",
      "         [ 0.2495,  0.3161, -0.3195, -0.0099],\n",
      "         [ 0.1306,  0.3211, -0.3383, -0.0613]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3477, -0.2381, -1.7774,  1.2868],\n",
      "         [ 0.3046, -0.7503,  0.1485,  0.2455],\n",
      "         [-0.1130, -0.6439, -0.0471,  0.2191],\n",
      "         ...,\n",
      "         [-0.5550,  0.4377,  0.3166,  0.5696],\n",
      "         [-0.5856,  0.0859,  0.2070,  0.2640],\n",
      "         [-0.3479,  0.0628,  0.2890,  0.4481]],\n",
      "\n",
      "        [[-0.7020,  0.3559, -0.4694, -0.4211],\n",
      "         [ 0.0565,  0.5721, -0.7548,  0.0067],\n",
      "         [ 0.5262,  0.2653, -0.6036,  0.0466],\n",
      "         ...,\n",
      "         [ 0.3155, -0.0395,  0.2550, -0.1934],\n",
      "         [ 0.1701,  0.0170,  0.1515, -0.2260],\n",
      "         [ 0.2507,  0.1134,  0.0026, -0.1434]],\n",
      "\n",
      "        [[-0.2504,  0.7736,  0.3942,  0.3925],\n",
      "         [ 0.3681,  0.8964,  0.3867,  0.2985],\n",
      "         [ 0.5171,  0.8604, -0.0890,  0.3438],\n",
      "         ...,\n",
      "         [ 0.2210,  0.4947,  0.2697,  0.2899],\n",
      "         [ 0.1463,  0.5471,  0.3527,  0.4012],\n",
      "         [ 0.2513,  0.6061,  0.3560,  0.3767]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "#print(embedded.shape)\n",
    "\n",
    "wei = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "print(embedded.shape) # B x T x C\n",
    "print(wei.shape) # T x T\n",
    "#  1xTxT @ BxTxC\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1822c",
   "metadata": {
    "papermill": {
     "duration": 0.029114,
     "end_time": "2024-07-09T20:10:00.710969",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.681855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bag of words type aggregation with a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59049a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.775241Z",
     "iopub.status.busy": "2024-07-09T20:10:00.774837Z",
     "iopub.status.idle": "2024-07-09T20:10:00.789201Z",
     "shell.execute_reply": "2024-07-09T20:10:00.786935Z"
    },
    "papermill": {
     "duration": 0.0509,
     "end_time": "2024-07-09T20:10:00.791896",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.740996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[-0.3020,  0.8613,  0.8509,  1.0694],\n",
      "         [-0.1474,  0.8005, -0.0386,  0.7087],\n",
      "         [ 0.2306,  0.8734,  0.1007,  0.5407],\n",
      "         ...,\n",
      "         [-0.0237,  0.9753,  0.2149,  0.6148],\n",
      "         [-0.1876,  1.1710,  0.3889,  0.6553],\n",
      "         [ 0.1801,  1.2350,  0.3246,  0.6314]],\n",
      "\n",
      "        [[-2.0734,  0.3787, -0.4855, -1.4053],\n",
      "         [-0.6292,  0.5835, -0.7629, -0.4855],\n",
      "         [ 0.0906,  0.8567, -1.0150, -0.4248],\n",
      "         ...,\n",
      "         [-0.2257, -0.0535, -0.1501, -0.4011],\n",
      "         [-0.1924,  0.0598, -0.2613, -0.2940],\n",
      "         [-0.1832,  0.0983, -0.1115, -0.1161]],\n",
      "\n",
      "        [[ 0.9866,  1.0192,  0.3793,  0.2046],\n",
      "         [ 0.0192,  0.2940, -0.0295,  0.1856],\n",
      "         [ 0.2845,  0.4588, -0.3664,  0.2685],\n",
      "         ...,\n",
      "         [ 0.1857,  0.4227, -0.4971,  0.1486],\n",
      "         [ 0.2495,  0.3161, -0.3195, -0.0099],\n",
      "         [ 0.1306,  0.3211, -0.3383, -0.0613]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.3477, -0.2381, -1.7774,  1.2868],\n",
      "         [ 0.3046, -0.7503,  0.1485,  0.2455],\n",
      "         [-0.1130, -0.6439, -0.0471,  0.2191],\n",
      "         ...,\n",
      "         [-0.5550,  0.4377,  0.3166,  0.5696],\n",
      "         [-0.5856,  0.0859,  0.2070,  0.2640],\n",
      "         [-0.3479,  0.0628,  0.2890,  0.4481]],\n",
      "\n",
      "        [[-0.7020,  0.3559, -0.4694, -0.4211],\n",
      "         [ 0.0565,  0.5721, -0.7548,  0.0067],\n",
      "         [ 0.5262,  0.2653, -0.6036,  0.0466],\n",
      "         ...,\n",
      "         [ 0.3155, -0.0395,  0.2550, -0.1934],\n",
      "         [ 0.1701,  0.0170,  0.1515, -0.2260],\n",
      "         [ 0.2507,  0.1134,  0.0026, -0.1434]],\n",
      "\n",
      "        [[-0.2504,  0.7736,  0.3942,  0.3925],\n",
      "         [ 0.3681,  0.8964,  0.3867,  0.2985],\n",
      "         [ 0.5171,  0.8604, -0.0890,  0.3438],\n",
      "         ...,\n",
      "         [ 0.2210,  0.4947,  0.2697,  0.2899],\n",
      "         [ 0.1463,  0.5471,  0.3527,  0.4012],\n",
      "         [ 0.2513,  0.6061,  0.3560,  0.3767]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = torch.zeros(size=(T, T)) # zeros just so there's a plaaceholder for masked_fill\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\")) # whenever the value in tril is 0, it will get replaced with -inf; this allows softmax to come into place, since -inf will get a percent of 0\n",
    "wei = torch.softmax(wei, dim=1)\n",
    "print(wei)\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b135a1",
   "metadata": {
    "papermill": {
     "duration": 0.028782,
     "end_time": "2024-07-09T20:10:00.850084",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.821302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLP model with agreggation\n",
    "- a problem that needs to be addressed with the previous model is that it needs to always receive a input of B x T (batch_size by context_size), whereas it would be best if the model could adapt to inputs of different context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b5ad7ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:00.916388Z",
     "iopub.status.busy": "2024-07-09T20:10:00.915431Z",
     "iopub.status.idle": "2024-07-09T20:10:00.930305Z",
     "shell.execute_reply": "2024-07-09T20:10:00.929327Z"
    },
    "papermill": {
     "duration": 0.052937,
     "end_time": "2024-07-09T20:10:00.933827",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.880890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1772, -0.8563, -0.8250,  0.7784,  0.3994],\n",
      "         [-1.4278, -0.2129, -0.9921,  0.2713,  0.2778],\n",
      "         [-0.6630, -0.1838, -0.6789,  0.2007,  0.2597],\n",
      "         ...,\n",
      "         [-0.1470, -0.4072, -0.3895, -0.1202, -0.3026],\n",
      "         [-0.0819, -0.2754, -0.4424,  0.0961, -0.4651],\n",
      "         [-0.1635, -0.0382, -0.5058,  0.0578, -0.3659]],\n",
      "\n",
      "        [[-0.1855,  0.0972,  0.8307, -1.3274, -0.5651],\n",
      "         [-0.4229, -0.4281,  0.3734, -0.5946, -0.3629],\n",
      "         [-0.1432, -0.3768, -0.1316, -0.6000, -0.5317],\n",
      "         ...,\n",
      "         [ 0.0350, -0.6950, -0.6717,  0.3662, -0.1211],\n",
      "         [-0.0757, -0.5785, -0.4903, -0.1183, -0.2821],\n",
      "         [-0.1859, -0.5367, -0.4898, -0.1930, -0.2658]],\n",
      "\n",
      "        [[ 1.2801, -0.5447,  0.9786, -0.2297, -0.3808],\n",
      "         [ 0.5822, -0.5246,  0.6279, -0.3887,  0.4966],\n",
      "         [ 0.4285,  0.0777,  0.2231, -0.3176,  0.0764],\n",
      "         ...,\n",
      "         [ 0.4156,  0.0136, -0.2311, -0.1844, -0.2442],\n",
      "         [ 0.6149, -0.0090, -0.1830, -0.0991,  0.0663],\n",
      "         [ 0.5862, -0.0821, -0.1918,  0.0153, -0.0458]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.4937,  0.7564, -1.2700, -2.7893, -0.3179],\n",
      "         [ 0.0512,  0.0482, -0.6954, -1.0435, -0.0149],\n",
      "         [ 0.2167, -0.5166, -0.9998, -0.7716,  0.2303],\n",
      "         ...,\n",
      "         [ 0.3022, -0.0859, -0.2180, -0.1997, -0.0366],\n",
      "         [ 0.1817, -0.0868, -0.2511, -0.1137, -0.0986],\n",
      "         [ 0.2573, -0.1907, -0.2245, -0.0062, -0.2356]],\n",
      "\n",
      "        [[ 0.9405, -1.2926,  0.0082,  0.4816,  0.5488],\n",
      "         [ 1.1747, -1.3393, -0.2194, -0.8746,  0.1682],\n",
      "         [ 0.5008, -0.9304, -0.4068, -0.6632,  0.3187],\n",
      "         ...,\n",
      "         [ 0.4147, -0.7796, -0.2287, -0.6085,  0.4749],\n",
      "         [ 0.2323, -0.4785, -0.3796, -0.6560,  0.3752],\n",
      "         [ 0.1351, -0.3843, -0.3334, -0.6585,  0.4456]],\n",
      "\n",
      "        [[ 0.2642,  1.0378, -1.6233,  0.4883,  0.5922],\n",
      "         [ 0.3165,  0.7824, -0.9977,  0.0046, -1.0297],\n",
      "         [ 0.6392,  0.5393, -0.7709,  0.1524, -0.8399],\n",
      "         ...,\n",
      "         [-0.1205,  0.2962, -0.1153,  0.5383,  0.0452],\n",
      "         [-0.0219,  0.1707, -0.2983,  0.3360,  0.1979],\n",
      "         [-0.2184,  0.2292, -0.2301,  0.2488,  0.0430]]])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "C = n_embd\n",
    "T = context_size\n",
    "B = batch_size\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "print(xbow @ test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a51060b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.013266Z",
     "iopub.status.busy": "2024-07-09T20:10:01.012866Z",
     "iopub.status.idle": "2024-07-09T20:10:01.021242Z",
     "shell.execute_reply": "2024-07-09T20:10:01.019824Z"
    },
    "papermill": {
     "duration": 0.045858,
     "end_time": "2024-07-09T20:10:01.023792",
     "exception": false,
     "start_time": "2024-07-09T20:10:00.977934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "# a problem that needs to be addressed with the previous model is that it needs to always receive a \n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "print(batch_sample_inputs.shape)\n",
    "print(batch_sample_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c670269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.085044Z",
     "iopub.status.busy": "2024-07-09T20:10:01.084670Z",
     "iopub.status.idle": "2024-07-09T20:10:01.100536Z",
     "shell.execute_reply": "2024-07-09T20:10:01.099195Z"
    },
    "papermill": {
     "duration": 0.049928,
     "end_time": "2024-07-09T20:10:01.103432",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.053504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        #logits = self.lm_head(token_emb.view(B*T, C)) # output of shape B*T x hidden_units1; this might be a problem for the labels since they are of shape B x T, thus they need to be reshaped aswell\n",
    "        x = self.act_fn(self.linear1(token_emb.view(B*T, C))) # hidden_units1 x hidden_units2\n",
    "        x = self.act_fn(self.linear2(x)) # hidden_units2 x hidden_units3\n",
    "        x = self.linear3(x) # hidden_units3 x vocab_size\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "176d6e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.165112Z",
     "iopub.status.busy": "2024-07-09T20:10:01.164687Z",
     "iopub.status.idle": "2024-07-09T20:10:01.172936Z",
     "shell.execute_reply": "2024-07-09T20:10:01.171731Z"
    },
    "papermill": {
     "duration": 0.041844,
     "end_time": "2024-07-09T20:10:01.175571",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.133727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2 = MLPv2(vocab_size=vocab_size, n_embd=32, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "248348b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.239024Z",
     "iopub.status.busy": "2024-07-09T20:10:01.237411Z",
     "iopub.status.idle": "2024-07-09T20:10:01.247313Z",
     "shell.execute_reply": "2024-07-09T20:10:01.246055Z"
    },
    "papermill": {
     "duration": 0.044322,
     "end_time": "2024-07-09T20:10:01.250143",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.205821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpv2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32ac92fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.313822Z",
     "iopub.status.busy": "2024-07-09T20:10:01.313140Z",
     "iopub.status.idle": "2024-07-09T20:10:01.327582Z",
     "shell.execute_reply": "2024-07-09T20:10:01.326181Z"
    },
    "papermill": {
     "duration": 0.049572,
     "end_time": "2024-07-09T20:10:01.330138",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.280566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([58, 46, 39, 52,  1, 47, 42, 50])\n",
      "tensor([[46, 39, 52,  1, 47, 42, 50, 63]])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8])\n",
      "tensor(4.1575)\n"
     ]
    }
   ],
   "source": [
    "mlpv2_loss_fn = nn.CrossEntropyLoss()\n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "sample_input = batch_sample_inputs[0]\n",
    "sample_label = batch_sample_labels[0]\n",
    "print(sample_input) # 1 x T (B x T)\n",
    "print(sample_label.view(1, -1)) # 1 x T (B x T)\n",
    "mlpv2.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = mlpv2(sample_input.view(1, -1))\n",
    "    labels = sample_label.view(-1) # from B x T to B*T to match the shape of the logits\n",
    "    print(logits.shape) # B*T x vocab_size\n",
    "    print(labels.shape)\n",
    "\n",
    "    loss = mlpv2_loss_fn(logits, labels)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d2df55f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.394494Z",
     "iopub.status.busy": "2024-07-09T20:10:01.394052Z",
     "iopub.status.idle": "2024-07-09T20:10:01.401284Z",
     "shell.execute_reply": "2024-07-09T20:10:01.400177Z"
    },
    "papermill": {
     "duration": 0.041054,
     "end_time": "2024-07-09T20:10:01.403799",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.362745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def generate_from_model(model, num_outputs, starting_char, max_length):\n",
    "    mlpv2.eval()\n",
    "    outputs = []\n",
    "    starting_idx = torch.tensor([stoi[starting_char]], dtype=torch.long).view(1, -1)\n",
    "    for i in range(num_outputs):\n",
    "        output = mlpv2.generate(starting_idx=starting_idx, max_length=max_length) # must be batched\n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8db3661b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.465843Z",
     "iopub.status.busy": "2024-07-09T20:10:01.465250Z",
     "iopub.status.idle": "2024-07-09T20:10:01.475822Z",
     "shell.execute_reply": "2024-07-09T20:10:01.474392Z"
    },
    "papermill": {
     "duration": 0.044561,
     "end_time": "2024-07-09T20:10:01.478531",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.433970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ah $\n",
      "S\n"
     ]
    }
   ],
   "source": [
    "test_output = generate_from_model(model=mlpv2, num_outputs=1, starting_char=\"a\", max_length=5)\n",
    "print(test_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41bc8726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.540949Z",
     "iopub.status.busy": "2024-07-09T20:10:01.540529Z",
     "iopub.status.idle": "2024-07-09T20:10:01.548618Z",
     "shell.execute_reply": "2024-07-09T20:10:01.547437Z"
    },
    "papermill": {
     "duration": 0.042147,
     "end_time": "2024-07-09T20:10:01.550909",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.508762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            if batch % 1200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d83aacd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.613808Z",
     "iopub.status.busy": "2024-07-09T20:10:01.613401Z",
     "iopub.status.idle": "2024-07-09T20:10:01.619604Z",
     "shell.execute_reply": "2024-07-09T20:10:01.618219Z"
    },
    "papermill": {
     "duration": 0.040651,
     "end_time": "2024-07-09T20:10:01.622426",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.581775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2_optimizer = torch.optim.Adam(params=mlpv2.parameters(), lr=1e-3)\n",
    "mlpv2_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c65e0c59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:01.688604Z",
     "iopub.status.busy": "2024-07-09T20:10:01.688070Z",
     "iopub.status.idle": "2024-07-09T20:10:50.778763Z",
     "shell.execute_reply": "2024-07-09T20:10:50.777566Z"
    },
    "papermill": {
     "duration": 49.126949,
     "end_time": "2024-07-09T20:10:50.781585",
     "exception": false,
     "start_time": "2024-07-09T20:10:01.654636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.192663669586182 at epoch 0\n",
      "loss for batch 1200 --> 2.4094653129577637 at epoch 0\n",
      "loss for batch 2400 --> 2.5396831035614014 at epoch 0\n",
      "loss for batch 0 --> 2.3995587825775146 at epoch 1\n",
      "loss for batch 1200 --> 2.358095645904541 at epoch 1\n",
      "loss for batch 2400 --> 2.5309691429138184 at epoch 1\n",
      "loss for batch 0 --> 2.393231153488159 at epoch 2\n",
      "loss for batch 1200 --> 2.344420909881592 at epoch 2\n",
      "loss for batch 2400 --> 2.526885986328125 at epoch 2\n",
      "loss for batch 0 --> 2.3893609046936035 at epoch 3\n",
      "loss for batch 1200 --> 2.3379037380218506 at epoch 3\n",
      "loss for batch 2400 --> 2.523819923400879 at epoch 3\n",
      "loss for the very last batch --> 2.4213552474975586\n"
     ]
    }
   ],
   "source": [
    "train_model(model=mlpv2, dataloader=train_dataloader, loss_fn=mlpv2_loss_fn, optimizer=mlpv2_optimizer, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de291445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:50.849239Z",
     "iopub.status.busy": "2024-07-09T20:10:50.848317Z",
     "iopub.status.idle": "2024-07-09T20:10:50.950843Z",
     "shell.execute_reply": "2024-07-09T20:10:50.949094Z"
    },
    "papermill": {
     "duration": 0.144855,
     "end_time": "2024-07-09T20:10:50.959362",
     "exception": false,
     "start_time": "2024-07-09T20:10:50.814507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bus gom hesse'lo tof pintr howowan tigo pupr yor\n",
      "pl,\n",
      "Fonce, nt on nd neeit,\n",
      "Tot nile gem hiticrm\n",
      "S:\n",
      "S\n",
      "\n",
      "\n",
      "bart d\n",
      "Arel; yond\n",
      "The yor w o ateathe g, tthealle;\n",
      "OLe pl hengiredof RCitr;\n",
      "fo INUSIAncondis\n",
      "Yot,\n",
      "Who\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_outputs = generate_from_model(model=mlpv2, max_length=100, num_outputs=2, starting_char=\"b\")\n",
    "for output in test_outputs:\n",
    "    print(f\"{output}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe6ee262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.033481Z",
     "iopub.status.busy": "2024-07-09T20:10:51.033057Z",
     "iopub.status.idle": "2024-07-09T20:10:51.041971Z",
     "shell.execute_reply": "2024-07-09T20:10:51.040780Z"
    },
    "papermill": {
     "duration": 0.04484,
     "end_time": "2024-07-09T20:10:51.044459",
     "exception": false,
     "start_time": "2024-07-09T20:10:50.999619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=T, step=1) # from 0 to T-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73191b25",
   "metadata": {
    "papermill": {
     "duration": 0.033495,
     "end_time": "2024-07-09T20:10:51.110469",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.076974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention\n",
    "- with xbow you can add information about the tokens, but the model itself does not attribute any weight to them. This is what self attention solves by using Keys, Queries and Values\n",
    "- every token will have a specific Query (Q) and Key (K) attatched to it\n",
    "    - Query --> what the model is looking for\n",
    "    - Key --> the weight the model is giving to this certain token\n",
    "    - Value --> Q @ K to get the affinities between themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e20c2674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.178077Z",
     "iopub.status.busy": "2024-07-09T20:10:51.176926Z",
     "iopub.status.idle": "2024-07-09T20:10:51.186907Z",
     "shell.execute_reply": "2024-07-09T20:10:51.185393Z"
    },
    "papermill": {
     "duration": 0.046433,
     "end_time": "2024-07-09T20:10:51.189673",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.143240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "\n",
    "B, T, C = 2, 4, 8\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "output = xbow @ test_tensor\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45cef98c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.257965Z",
     "iopub.status.busy": "2024-07-09T20:10:51.257567Z",
     "iopub.status.idle": "2024-07-09T20:10:51.266751Z",
     "shell.execute_reply": "2024-07-09T20:10:51.265325Z"
    },
    "papermill": {
     "duration": 0.046714,
     "end_time": "2024-07-09T20:10:51.269303",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.222589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32])\n",
      "torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "head_size = 32\n",
    "key = nn.Linear(in_features=C, out_features=head_size, bias=False) # bias = False so that it's just a multiplication\n",
    "query = nn.Linear(in_features=C, out_features=head_size, bias=False) \n",
    "\n",
    "#print(test_tensor.shape)\n",
    "k = key(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a key value\n",
    "q = query(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a query value\n",
    "print(k.shape)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43cf5c68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.337805Z",
     "iopub.status.busy": "2024-07-09T20:10:51.337390Z",
     "iopub.status.idle": "2024-07-09T20:10:51.348808Z",
     "shell.execute_reply": "2024-07-09T20:10:51.347348Z"
    },
    "papermill": {
     "duration": 0.049505,
     "end_time": "2024-07-09T20:10:51.351422",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.301917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(k.transpose(-2, -1).shape) # same as k.permute(0, 2, 1)\n",
    "print(k.permute(0, 2, 1).shape)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "print(wei.shape) #  B x T x T\n",
    "\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1) # dim=-1 in this case, since wei is of shape\n",
    "\n",
    "output = wei @ test_tensor\n",
    "\n",
    "print(output.shape) # B x T x C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bb1d1",
   "metadata": {
    "papermill": {
     "duration": 0.032128,
     "end_time": "2024-07-09T20:10:51.417776",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.385648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Update the model with a self attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ad9b476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.484397Z",
     "iopub.status.busy": "2024-07-09T20:10:51.483951Z",
     "iopub.status.idle": "2024-07-09T20:10:51.494858Z",
     "shell.execute_reply": "2024-07-09T20:10:51.493623Z"
    },
    "papermill": {
     "duration": 0.047461,
     "end_time": "2024-07-09T20:10:51.497496",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.450035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.Q = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "        #mask = torch.tril(torch.ones(size=(T, T)))\n",
    "\n",
    "        q = self.Q(x) # B x T x head_size\n",
    "        k = self.K(x) # B x T x head_size\n",
    "        v = self.V(x) # B x T x head_size\n",
    "\n",
    "        k = k.transpose(-2, -1) # B x head_size x T\n",
    "\n",
    "        wei = q @ k # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "\n",
    "        wei = wei.masked_fill(mask==0, float('-inf'))\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "\n",
    "        #x = wei @ v # BxTxT @ BxTxhead_size --> BxTxhead_size\n",
    "        x = wei @ x\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "854758a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.565093Z",
     "iopub.status.busy": "2024-07-09T20:10:51.564692Z",
     "iopub.status.idle": "2024-07-09T20:10:51.580134Z",
     "shell.execute_reply": "2024-07-09T20:10:51.578826Z"
    },
    "papermill": {
     "duration": 0.051947,
     "end_time": "2024-07-09T20:10:51.582645",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.530698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv3(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super(MLPv3, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        self.head = Head(head_size=32, n_embd=n_embd)\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "        self.mask = torch.tril(torch.ones(size=(context_size, context_size)))\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.head(x, self.mask)\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53b8b7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.650008Z",
     "iopub.status.busy": "2024-07-09T20:10:51.649603Z",
     "iopub.status.idle": "2024-07-09T20:10:51.662553Z",
     "shell.execute_reply": "2024-07-09T20:10:51.661388Z"
    },
    "papermill": {
     "duration": 0.049816,
     "end_time": "2024-07-09T20:10:51.665081",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.615265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 32\n",
    "mlpv3 = MLPv3(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size)\n",
    "mlpv3.optimizer = torch.optim.Adam(params=mlpv3.parameters(), lr=1e-2)\n",
    "mlpv3_loss_fn = nn.CrossEntropyLoss()\n",
    "mlpv3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed5a96b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.734269Z",
     "iopub.status.busy": "2024-07-09T20:10:51.733298Z",
     "iopub.status.idle": "2024-07-09T20:10:51.891067Z",
     "shell.execute_reply": "2024-07-09T20:10:51.889800Z"
    },
    "papermill": {
     "duration": 0.194747,
     "end_time": "2024-07-09T20:10:51.893771",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.699024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a w'dinforaso s?\n",
      "MENINat m navo cive tasu,\n",
      "Thed beey gug.\n",
      "\n",
      "Ans bases wesulotingre tyoowoulorde\n",
      "Wir igorieethhonong\n",
      "Fimuy holy antin,, mo f o, t d teiothaipoulebowasllealid\n",
      "aleoraminls trallert n s me u \n",
      "\n",
      "\n",
      "an he y terasere ise,\n",
      "Or s; sum ukenaik:\n",
      "Frat s.\n",
      "VOn ano thowiuth aldrs\n",
      "ORI coofein.\n",
      "Bu d brony tuollearilithue tithen;\n",
      "Troncendse w\n",
      "Thirs ccotee d powavot upe t spr.\n",
      "S:\n",
      "Thod,\n",
      "MIUS:\n",
      "\n",
      "And ck-bendowathat \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27802c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:51.962031Z",
     "iopub.status.busy": "2024-07-09T20:10:51.961625Z",
     "iopub.status.idle": "2024-07-09T20:10:51.966513Z",
     "shell.execute_reply": "2024-07-09T20:10:51.965402Z"
    },
    "papermill": {
     "duration": 0.04227,
     "end_time": "2024-07-09T20:10:51.968956",
     "exception": false,
     "start_time": "2024-07-09T20:10:51.926686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_model(model=mlpv3, dataloader=train_dataloader, loss_fn=mlpv3_loss_fn, optimizer=mlpv2_optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47449761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:10:52.038388Z",
     "iopub.status.busy": "2024-07-09T20:10:52.037932Z",
     "iopub.status.idle": "2024-07-09T20:10:52.203049Z",
     "shell.execute_reply": "2024-07-09T20:10:52.201899Z"
    },
    "papermill": {
     "duration": 0.203037,
     "end_time": "2024-07-09T20:10:52.205800",
     "exception": false,
     "start_time": "2024-07-09T20:10:52.002763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anves yoofaty hous,\n",
      "\n",
      "Foucet mer us ss br,\n",
      "TUMENERUSil,\n",
      "Soilldy iouptstcorein s she hear sond y y ntesy bloron n t athis celo cr h,\n",
      "Vondy sppr\n",
      "n ine te f tt s miroreerushat plllon:\n",
      "shear\n",
      "Gou st;\n",
      "\n",
      "At f t \n",
      "\n",
      "\n",
      "af t sce;\n",
      "Frid as\n",
      "ARUS:\n",
      "Totous thandrdecraber t s ind beleativersteal ched r uvilendizend hendst d m toizel, brd,\n",
      "Buede feres d hakldencean:\n",
      "Coun.\n",
      "Th bu aitor bur. st.\n",
      "NI tinshoneespas l grothyord as.\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99183e81",
   "metadata": {
    "papermill": {
     "duration": 0.033875,
     "end_time": "2024-07-09T20:10:52.273925",
     "exception": false,
     "start_time": "2024-07-09T20:10:52.240050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self-attetion x cross-attention\n",
    "- in self-attention the values for queries (Q), keys (K) and values (V) all come from x itself, thus self-attention\n",
    "- in cross-attention those values can come from somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dbbd9",
   "metadata": {
    "papermill": {
     "duration": 0.033253,
     "end_time": "2024-07-09T20:10:52.340913",
     "exception": false,
     "start_time": "2024-07-09T20:10:52.307660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5339176,
     "sourceId": 8871363,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 80.981851,
   "end_time": "2024-07-09T20:10:53.397994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T20:09:32.416143",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
