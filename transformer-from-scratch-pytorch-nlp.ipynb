{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/evelynartoria/transformer-from-scratch-pytorch-nlp?scriptVersionId=187722660\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"1a6294e4","metadata":{"papermill":{"duration":0.01964,"end_time":"2024-07-10T21:19:11.203028","exception":false,"start_time":"2024-07-10T21:19:11.183388","status":"completed"},"tags":[]},"source":["# Introduction (WIP)\n","- This notebook is based on the \"Let's build GPT: from scratch, in code, spelled out\" tutorial by Andrej Karpathy. You can find the tutorial here --> https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7\n","- There are several different approaches in this notebook that do not strictly follow the original video. Some implementations are my own.\n","- I am using the same shakespeare text as in the video."]},{"cell_type":"markdown","id":"7b8cb917","metadata":{"papermill":{"duration":0.019363,"end_time":"2024-07-10T21:19:11.241702","exception":false,"start_time":"2024-07-10T21:19:11.222339","status":"completed"},"tags":[]},"source":["# Import needed libraries"]},{"cell_type":"code","execution_count":1,"id":"b5c59872","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:11.280899Z","iopub.status.busy":"2024-07-10T21:19:11.280098Z","iopub.status.idle":"2024-07-10T21:19:15.95315Z","shell.execute_reply":"2024-07-10T21:19:15.952213Z"},"papermill":{"duration":4.695304,"end_time":"2024-07-10T21:19:15.955653","exception":false,"start_time":"2024-07-10T21:19:11.260349","status":"completed"},"tags":[]},"outputs":[],"source":["from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split"]},{"cell_type":"markdown","id":"017d1946","metadata":{"papermill":{"duration":0.018348,"end_time":"2024-07-10T21:19:15.992933","exception":false,"start_time":"2024-07-10T21:19:15.974585","status":"completed"},"tags":[]},"source":["# Device agnostic code"]},{"cell_type":"code","execution_count":2,"id":"574c5f1a","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.031192Z","iopub.status.busy":"2024-07-10T21:19:16.030354Z","iopub.status.idle":"2024-07-10T21:19:16.125227Z","shell.execute_reply":"2024-07-10T21:19:16.124148Z"},"papermill":{"duration":0.116251,"end_time":"2024-07-10T21:19:16.127396","exception":false,"start_time":"2024-07-10T21:19:16.011145","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["default device set to cuda\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.set_default_device(device)\n","generator = torch.Generator(device=device)\n","print(f\"default device set to {device}\")"]},{"cell_type":"markdown","id":"7d38d6e9","metadata":{"papermill":{"duration":0.018468,"end_time":"2024-07-10T21:19:16.164633","exception":false,"start_time":"2024-07-10T21:19:16.146165","status":"completed"},"tags":[]},"source":["# Prepare the data"]},{"cell_type":"code","execution_count":3,"id":"72088b65","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.20321Z","iopub.status.busy":"2024-07-10T21:19:16.202906Z","iopub.status.idle":"2024-07-10T21:19:16.24156Z","shell.execute_reply":"2024-07-10T21:19:16.240482Z"},"papermill":{"duration":0.060393,"end_time":"2024-07-10T21:19:16.243385","exception":false,"start_time":"2024-07-10T21:19:16.182992","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","65\n"]}],"source":["with open(\"/kaggle/input/shakespeare/input.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","\n","vocab = sorted(set(text))\n","vocab_size = len(vocab)\n","\n","print(vocab)\n","print(vocab_size)"]},{"cell_type":"markdown","id":"eaaf3163","metadata":{"papermill":{"duration":0.01816,"end_time":"2024-07-10T21:19:16.279861","exception":false,"start_time":"2024-07-10T21:19:16.261701","status":"completed"},"tags":[]},"source":["### Tokenizer"]},{"cell_type":"code","execution_count":4,"id":"0e6254e4","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.317381Z","iopub.status.busy":"2024-07-10T21:19:16.317072Z","iopub.status.idle":"2024-07-10T21:19:16.322219Z","shell.execute_reply":"2024-07-10T21:19:16.321408Z"},"papermill":{"duration":0.026371,"end_time":"2024-07-10T21:19:16.324492","exception":false,"start_time":"2024-07-10T21:19:16.298121","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["46\n","h\n"]}],"source":["stoi = {c: v for v, c in enumerate(vocab)}\n","itos = {v: c for c, v in stoi.items()}\n","print(stoi[\"h\"])\n","print(itos[46])"]},{"cell_type":"code","execution_count":5,"id":"78c2d56d","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.362664Z","iopub.status.busy":"2024-07-10T21:19:16.362402Z","iopub.status.idle":"2024-07-10T21:19:16.368036Z","shell.execute_reply":"2024-07-10T21:19:16.36709Z"},"papermill":{"duration":0.027216,"end_time":"2024-07-10T21:19:16.370127","exception":false,"start_time":"2024-07-10T21:19:16.342911","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["[46, 43, 50, 50, 53, 6, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12, 2]\n","hello, how are you?!\n"]}],"source":["encode = lambda d: [stoi[idx] for idx in d]\n","decode = lambda e: \"\".join([itos[idx] for idx in e])\n","\n","encoded = encode(\"hello, how are you?!\")\n","decoded = decode(encoded)\n","print(encoded)\n","print(decoded)"]},{"cell_type":"markdown","id":"a5f1716f","metadata":{"papermill":{"duration":0.018552,"end_time":"2024-07-10T21:19:16.407535","exception":false,"start_time":"2024-07-10T21:19:16.388983","status":"completed"},"tags":[]},"source":["# Prepare the dataset"]},{"cell_type":"code","execution_count":6,"id":"830fa3d0","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.447354Z","iopub.status.busy":"2024-07-10T21:19:16.447031Z","iopub.status.idle":"2024-07-10T21:19:16.450947Z","shell.execute_reply":"2024-07-10T21:19:16.450226Z"},"papermill":{"duration":0.025497,"end_time":"2024-07-10T21:19:16.452769","exception":false,"start_time":"2024-07-10T21:19:16.427272","status":"completed"},"tags":[]},"outputs":[],"source":["context_size = 128\n","vocab_size = len(vocab)"]},{"cell_type":"code","execution_count":7,"id":"9f976dca","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.491591Z","iopub.status.busy":"2024-07-10T21:19:16.4913Z","iopub.status.idle":"2024-07-10T21:19:16.49688Z","shell.execute_reply":"2024-07-10T21:19:16.496082Z"},"papermill":{"duration":0.027461,"end_time":"2024-07-10T21:19:16.49878","exception":false,"start_time":"2024-07-10T21:19:16.471319","status":"completed"},"tags":[]},"outputs":[],"source":["def make_dataset(data, context_size):\n","    random_idx_tensor = torch.randperm((len(data)-context_size)//context_size) * context_size\n","    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx_tensor])\n","    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx_tensor])\n","    \n","    return TensorDataset(inputs.to(torch.long), labels.to(torch.long))\n","\n"]},{"cell_type":"code","execution_count":8,"id":"18d0679c","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.536724Z","iopub.status.busy":"2024-07-10T21:19:16.536219Z","iopub.status.idle":"2024-07-10T21:19:16.914689Z","shell.execute_reply":"2024-07-10T21:19:16.913272Z"},"papermill":{"duration":0.399836,"end_time":"2024-07-10T21:19:16.916958","exception":false,"start_time":"2024-07-10T21:19:16.517122","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([8, 5, 5, 5, 0, 6, 3, 8, 1, 9], device='cuda:0')\n","tensor([1, 4, 9, 5, 3, 2, 7, 8, 6, 0], device='cuda:0')\n"]}],"source":["# sicne randint might give the same random_idx, randperm is going to be preffered\n","print(torch.randint(0, 10, (10,)))\n","print(torch.randperm(10))"]},{"cell_type":"code","execution_count":9,"id":"305efe75","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:16.958244Z","iopub.status.busy":"2024-07-10T21:19:16.957967Z","iopub.status.idle":"2024-07-10T21:19:18.939507Z","shell.execute_reply":"2024-07-10T21:19:18.938682Z"},"papermill":{"duration":2.004568,"end_time":"2024-07-10T21:19:18.941804","exception":false,"start_time":"2024-07-10T21:19:16.937236","status":"completed"},"tags":[]},"outputs":[],"source":["data = torch.tensor(encode(text))\n","dataset = make_dataset(data=data, context_size=context_size)"]},{"cell_type":"code","execution_count":10,"id":"708c97d3","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:18.98237Z","iopub.status.busy":"2024-07-10T21:19:18.982051Z","iopub.status.idle":"2024-07-10T21:19:18.988595Z","shell.execute_reply":"2024-07-10T21:19:18.987795Z"},"papermill":{"duration":0.028705,"end_time":"2024-07-10T21:19:18.990592","exception":false,"start_time":"2024-07-10T21:19:18.961887","status":"completed"},"tags":[]},"outputs":[],"source":["train_split = int(len(dataset)*0.75)\n","test_split = int(len(dataset)-train_split)\n","\n","train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"]},{"cell_type":"code","execution_count":11,"id":"ff9af0f3","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:19.029304Z","iopub.status.busy":"2024-07-10T21:19:19.029024Z","iopub.status.idle":"2024-07-10T21:19:19.033606Z","shell.execute_reply":"2024-07-10T21:19:19.03279Z"},"papermill":{"duration":0.026077,"end_time":"2024-07-10T21:19:19.03545","exception":false,"start_time":"2024-07-10T21:19:19.009373","status":"completed"},"tags":[]},"outputs":[],"source":["batch_size = 32\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, generator=generator)\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, generator=generator)"]},{"cell_type":"code","execution_count":12,"id":"f6b3817d","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:19.074499Z","iopub.status.busy":"2024-07-10T21:19:19.074225Z","iopub.status.idle":"2024-07-10T21:19:19.085247Z","shell.execute_reply":"2024-07-10T21:19:19.084189Z"},"papermill":{"duration":0.033002,"end_time":"2024-07-10T21:19:19.087253","exception":false,"start_time":"2024-07-10T21:19:19.054251","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0, 52, 53, 40, 50, 43,  1, 25, 39, 56, 41, 47, 59, 57,  8,  0,  0, 14,\n","        30, 33, 32, 33, 31, 10,  0, 20, 43,  5, 57,  1, 39,  1, 50, 39, 51, 40,\n","         1, 47, 52, 42, 43, 43, 42,  6,  1, 58, 46, 39, 58,  1, 40, 39, 43, 57,\n","         1, 50, 47, 49, 43,  1, 39,  1, 40, 43, 39, 56,  8,  0,  0, 25, 17, 26,\n","        17, 26, 21, 33, 31, 10,  0, 20, 43,  5, 57,  1, 39,  1, 40, 43, 39, 56,\n","         1, 47, 52, 42, 43, 43, 42,  6,  1, 58, 46, 39, 58,  1, 50, 47, 60, 43,\n","        57,  1, 50, 47, 49, 43,  1, 39,  1, 50, 39, 51, 40,  8,  1, 37, 53, 59,\n","         1, 58], device='cuda:0')\n","tensor([52, 53, 40, 50, 43,  1, 25, 39, 56, 41, 47, 59, 57,  8,  0,  0, 14, 30,\n","        33, 32, 33, 31, 10,  0, 20, 43,  5, 57,  1, 39,  1, 50, 39, 51, 40,  1,\n","        47, 52, 42, 43, 43, 42,  6,  1, 58, 46, 39, 58,  1, 40, 39, 43, 57,  1,\n","        50, 47, 49, 43,  1, 39,  1, 40, 43, 39, 56,  8,  0,  0, 25, 17, 26, 17,\n","        26, 21, 33, 31, 10,  0, 20, 43,  5, 57,  1, 39,  1, 40, 43, 39, 56,  1,\n","        47, 52, 42, 43, 43, 42,  6,  1, 58, 46, 39, 58,  1, 50, 47, 60, 43, 57,\n","         1, 50, 47, 49, 43,  1, 39,  1, 50, 39, 51, 40,  8,  1, 37, 53, 59,  1,\n","        58, 61], device='cuda:0')\n","dataset length --> 8713 (1115264 characters), that is, about the length of text 1115394 - context_size --> 1115266\n"]}],"source":["sample_input = dataset[0][0]\n","sample_label = dataset[0][1]\n","\n","print(sample_input)\n","print(sample_label)\n","\n","print(f\"dataset length --> {len(dataset)} ({len(dataset) * context_size} characters), that is, about the length of text {len(text)} - context_size --> {len(text)-context_size}\")"]},{"cell_type":"markdown","id":"e88a72bc","metadata":{"papermill":{"duration":0.05797,"end_time":"2024-07-10T21:19:19.164164","exception":false,"start_time":"2024-07-10T21:19:19.106194","status":"completed"},"tags":[]},"source":["# Base model (MLP)"]},{"cell_type":"code","execution_count":13,"id":"4d0dd1b7","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:19.208145Z","iopub.status.busy":"2024-07-10T21:19:19.20736Z","iopub.status.idle":"2024-07-10T21:19:19.221802Z","shell.execute_reply":"2024-07-10T21:19:19.22087Z"},"papermill":{"duration":0.038584,"end_time":"2024-07-10T21:19:19.223863","exception":false,"start_time":"2024-07-10T21:19:19.185279","status":"completed"},"tags":[]},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self, context_size, n_embd, vocab_size):\n","        super().__init__()\n","\n","\n","        self.context_size = context_size\n","        self.vocab_size = vocab_size\n","        self.n_embd = n_embd\n","        \n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # B x T x C; B --> batches, T --> time (context_size), C --> n_embd\n","        self.pos_embedding_table = nn.Embedding(context_size, n_embd) # T x C; this is from the posisitional encoding part of the video\n","        \n","        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8) # B x T*C @ T*C x H; H --> number of hidden_units\n","        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n","        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n","        self.act_fn = nn.Tanh()\n","\n","    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n","        B, T = idx.shape\n","        C = self.n_embd\n","        positions = torch.arange(start=0, end=T, step=1) # 1 x B x T\n","        x = self.token_embedding_table(idx) + self.pos_embedding_table(positions)\n","        x = x.view(B*T, C) # B*T x C so it does not need the full context size at the beggining to generate predictions\n","        #print(f\"x shape is {x.shape}, T is {T}, C is {C}\")\n","\n","        x = self.act_fn(self.linear1(x)) # B x T*C \n","        x = self.act_fn(self.linear2(x))\n","        x = self.linear3(x)\n","\n","        return x\n","\n","    def generate(self, starting_idx: torch.Tensor, max_length: int, debug: bool) -> torch.Tensor:\n","        full_text = decode(starting_idx.tolist()[0])\n","\n","        \n","        context = starting_idx\n","        \n","        for _ in range(max_length):\n","            context = context[:, -self.context_size:] # make sure the context is of size context_size\n","            \n","            if debug:\n","                print(f\"predicting on context: {decode(context[0].tolist())}\")\n","            \n","            logits = self(context) # B*T x vocab_size --> 1*2 x vocab_size\n","            logits = logits[-1, :].view(1, self.vocab_size) # only take the prediction for the last character\n","            percents = torch.softmax(logits, dim=1) # 1*2xvocab_size\n","            pred = torch.multinomial(percents, num_samples=1) \n","            full_text += decode(pred.tolist()[0])\n","            \n","            #print(len(padded[0]))\n","            context = torch.cat([context, pred], dim=1) # add to the context dimension instead of the batch dim\n","            \n","        return full_text\n","\n","            \n"]},{"cell_type":"markdown","id":"e1781163","metadata":{"papermill":{"duration":0.018602,"end_time":"2024-07-10T21:19:19.262034","exception":false,"start_time":"2024-07-10T21:19:19.243432","status":"completed"},"tags":[]},"source":["# Define the base model, optimizer and loss function"]},{"cell_type":"code","execution_count":14,"id":"7d0c078a","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:19.300965Z","iopub.status.busy":"2024-07-10T21:19:19.300703Z","iopub.status.idle":"2024-07-10T21:19:20.764887Z","shell.execute_reply":"2024-07-10T21:19:20.764058Z"},"papermill":{"duration":1.486195,"end_time":"2024-07-10T21:19:20.767196","exception":false,"start_time":"2024-07-10T21:19:19.281001","status":"completed"},"tags":[]},"outputs":[],"source":["mlp = MLP(context_size=context_size, n_embd=32, vocab_size=vocab_size)\n","optimizer = torch.optim.Adam(params=mlp.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"5b2e4a20","metadata":{"papermill":{"duration":0.018906,"end_time":"2024-07-10T21:19:20.805536","exception":false,"start_time":"2024-07-10T21:19:20.78663","status":"completed"},"tags":[]},"source":["# Take samples from the base model"]},{"cell_type":"code","execution_count":15,"id":"a39f0a7f","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:20.845012Z","iopub.status.busy":"2024-07-10T21:19:20.844653Z","iopub.status.idle":"2024-07-10T21:19:21.366351Z","shell.execute_reply":"2024-07-10T21:19:21.365197Z"},"papermill":{"duration":0.544353,"end_time":"2024-07-10T21:19:21.368969","exception":false,"start_time":"2024-07-10T21:19:20.824616","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["How are E;BFV;mpkZ \n","\n","\n"]}],"source":["@torch.no_grad\n","def model_sampler(model, context, randomize, max_length, num_samples):\n","    #print(len(context))\n","    #print(context_size)\n","    test = torch.tensor([[20, 53, 61,  1, 39, 56, 58, 39]])\n","    #print(test[:, 1:])\n","    result = torch.cat((test[:, 1:], torch.tensor([[99]])), dim=1)\n","    #print(result)\n","    #print(\"\\n\")\n","\n","    mlp.eval()\n","    idx = torch.tensor(encode(context), dtype=torch.long).view(1, len(encode(context))) # inputs must be batched\n","    outputs = mlp.generate(starting_idx=idx, max_length=max_length, debug=False)\n","    print(f\"{outputs} \\n\\n\")\n","\n","model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=10, num_samples=5)"]},{"cell_type":"markdown","id":"afdbf4cd","metadata":{"papermill":{"duration":0.019237,"end_time":"2024-07-10T21:19:21.407745","exception":false,"start_time":"2024-07-10T21:19:21.388508","status":"completed"},"tags":[]},"source":["# Training loop"]},{"cell_type":"code","execution_count":16,"id":"6b20453f","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:21.448456Z","iopub.status.busy":"2024-07-10T21:19:21.448098Z","iopub.status.idle":"2024-07-10T21:19:21.454504Z","shell.execute_reply":"2024-07-10T21:19:21.453637Z"},"papermill":{"duration":0.029837,"end_time":"2024-07-10T21:19:21.456519","exception":false,"start_time":"2024-07-10T21:19:21.426682","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            logits = model(X)\n","            loss = loss_fn(logits, y.view(-1)) # y.view(-1) turn y of shape BxT into B*T to mathc the logits shape\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch % 20 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n","\n","    print(f\"loss for the very last batch --> {loss}\")"]},{"cell_type":"code","execution_count":17,"id":"0b4dc4dc","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:21.496022Z","iopub.status.busy":"2024-07-10T21:19:21.495739Z","iopub.status.idle":"2024-07-10T21:19:22.393673Z","shell.execute_reply":"2024-07-10T21:19:22.39252Z"},"papermill":{"duration":0.920679,"end_time":"2024-07-10T21:19:22.395993","exception":false,"start_time":"2024-07-10T21:19:21.475314","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["30it [00:00, 107.33it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.1840667724609375 at epoch 0\n","loss for batch 20 --> 3.1744179725646973 at epoch 0\n","loss for batch 40 --> 2.970180034637451 at epoch 0\n","loss for batch 60 --> 2.954010009765625 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["128it [00:00, 258.22it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 80 --> 2.8322715759277344 at epoch 0\n","loss for batch 100 --> 2.759148597717285 at epoch 0\n","loss for batch 120 --> 2.7204084396362305 at epoch 0\n","loss for batch 140 --> 2.7117512226104736 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["205it [00:00, 231.56it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 160 --> 2.6893413066864014 at epoch 0\n","loss for batch 180 --> 2.708850622177124 at epoch 0\n","loss for batch 200 --> 2.6500089168548584 at epoch 0\n","loss for the very last batch --> 2.540949821472168\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["mlp.train()\n","train_model(model=mlp, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"]},{"cell_type":"markdown","id":"4eb6ca3e","metadata":{"papermill":{"duration":0.019953,"end_time":"2024-07-10T21:19:22.43644","exception":false,"start_time":"2024-07-10T21:19:22.416487","status":"completed"},"tags":[]},"source":["# Base model inference"]},{"cell_type":"code","execution_count":18,"id":"6282d434","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:22.479333Z","iopub.status.busy":"2024-07-10T21:19:22.479047Z","iopub.status.idle":"2024-07-10T21:19:22.48479Z","shell.execute_reply":"2024-07-10T21:19:22.483929Z"},"papermill":{"duration":0.028888,"end_time":"2024-07-10T21:19:22.486608","exception":false,"start_time":"2024-07-10T21:19:22.45772","status":"completed"},"tags":[]},"outputs":[],"source":["@torch.no_grad\n","def model_inference(model, dataloader):\n","    mlp.eval()\n","    X, y = next(iter(dataloader))\n","    logits = model(X)\n","    percents = torch.softmax(logits, dim=1) # dim=1 since the input was batched\n","    preds = torch.argmax(percents, dim=1) # dim=1 since the input was batched\n","    print(f\"for {X} \\n model predicted {preds}\")\n","    print(f\"expected --> {y[:, -1]}\")\n","    print(y)"]},{"cell_type":"code","execution_count":19,"id":"d4810353","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:22.528095Z","iopub.status.busy":"2024-07-10T21:19:22.527791Z","iopub.status.idle":"2024-07-10T21:19:22.539763Z","shell.execute_reply":"2024-07-10T21:19:22.538406Z"},"papermill":{"duration":0.034473,"end_time":"2024-07-10T21:19:22.541631","exception":false,"start_time":"2024-07-10T21:19:22.507158","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["for tensor([[44,  1, 57,  ..., 59,  1, 61],\n","        [ 6,  1, 58,  ..., 52, 45, 57],\n","        [53,  1, 39,  ..., 53, 53, 42],\n","        ...,\n","        [ 1, 61, 53,  ..., 53, 56,  1],\n","        [ 0, 13, 57,  ..., 57, 58, 43],\n","        [53,  1, 51,  ..., 39, 56, 45]], device='cuda:0') \n"," model predicted tensor([ 1, 58,  1,  ..., 52,  1,  1], device='cuda:0')\n","expected --> tensor([43,  8, 10, 42, 53, 52,  0, 53, 46, 61, 59, 15, 50,  0, 42, 61, 43, 47,\n","        46, 17, 61, 58, 52, 58, 57, 43, 61,  5, 56, 51, 56, 53],\n","       device='cuda:0')\n","tensor([[ 1, 57, 53,  ...,  1, 61, 43],\n","        [ 1, 58, 46,  ..., 45, 57,  8],\n","        [ 1, 39, 57,  ..., 53, 42, 10],\n","        ...,\n","        [61, 53, 56,  ..., 56,  1, 51],\n","        [13, 57,  1,  ..., 58, 43, 56],\n","        [ 1, 51, 59,  ..., 56, 45, 53]], device='cuda:0')\n"]}],"source":["model_inference(model=mlp, dataloader=train_dataloader)"]},{"cell_type":"code","execution_count":20,"id":"1b67927c","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:22.583621Z","iopub.status.busy":"2024-07-10T21:19:22.583334Z","iopub.status.idle":"2024-07-10T21:19:23.041751Z","shell.execute_reply":"2024-07-10T21:19:23.040876Z"},"papermill":{"duration":0.482276,"end_time":"2024-07-10T21:19:23.044158","exception":false,"start_time":"2024-07-10T21:19:22.561882","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["How are we\n","arenotheeinselu ndlh saatisheeinRYEO:\n","Mkoy edd ueamagofrim,nt re g aralin ionher then my ng wour han.l albyo thewan se en tir,oou t f the whoft mekixfre we cen\n","Dlipe,\n","\n","Pu\n","Daswe\n","T:\n","Scur inddowecd y fte pe mot don?rthize n manp,\n","o Be.\n","T:\n","Thasind g\n","Tikhelo atofrie Iindlo t:\n","Whepar pr uimlit hiig:\n","Pc n sg t sngesh hae\n","\n","\n","HCN gondtearcund f come gKce ce-m,or mhomin t bed inug sounthacindheene uy my minso rouh.\n","Ad;\n","\n","M ce e r fouthan.eome te hgor dOMorto p thing ng\n","IENU:\n","'t.\n","ATi i utow:\n","Wh bu\n","S:\n","M wo \n","\n","\n"]}],"source":["model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=500, num_samples=1)"]},{"cell_type":"markdown","id":"935aa734","metadata":{"papermill":{"duration":0.01993,"end_time":"2024-07-10T21:19:23.084841","exception":false,"start_time":"2024-07-10T21:19:23.064911","status":"completed"},"tags":[]},"source":["# Self attention math"]},{"cell_type":"code","execution_count":21,"id":"31a9aafd","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.127469Z","iopub.status.busy":"2024-07-10T21:19:23.126824Z","iopub.status.idle":"2024-07-10T21:19:23.134352Z","shell.execute_reply":"2024-07-10T21:19:23.13343Z"},"papermill":{"duration":0.030585,"end_time":"2024-07-10T21:19:23.136239","exception":false,"start_time":"2024-07-10T21:19:23.105654","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["32 128\n","torch.Size([32, 128, 4])\n"]}],"source":["sample_batch = next(iter(test_dataloader))[0]\n","B, T = sample_batch.shape # batch of B by T\n","print(B, T)\n","example_emb = nn.Embedding(vocab_size, 4)\n","embedded = example_emb(sample_batch)\n","B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n","print(embedded.shape)"]},{"cell_type":"code","execution_count":22,"id":"e01c843a","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.179152Z","iopub.status.busy":"2024-07-10T21:19:23.178907Z","iopub.status.idle":"2024-07-10T21:19:23.609963Z","shell.execute_reply":"2024-07-10T21:19:23.609013Z"},"papermill":{"duration":0.455538,"end_time":"2024-07-10T21:19:23.612605","exception":false,"start_time":"2024-07-10T21:19:23.157067","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-0.8609,  0.3323,  0.6140, -0.5782],\n","         [ 0.2443, -0.1584,  0.6773, -0.1373],\n","         [ 0.5538, -0.3726,  0.0825, -0.3324],\n","         ...,\n","         [-0.0662, -0.1874, -0.2624, -0.1384],\n","         [-0.0626, -0.1848, -0.2633, -0.1336],\n","         [-0.0645, -0.1840, -0.2653, -0.1321]],\n","\n","        [[ 0.4916, -2.7525,  0.3134, -0.7418],\n","         [-0.6967, -1.5363, -0.3940, -0.2345],\n","         [-0.0146, -1.2406, -0.0158, -0.0552],\n","         ...,\n","         [-0.0847, -0.3982,  0.0414, -0.0404],\n","         [-0.0739, -0.3929,  0.0300, -0.0455],\n","         [-0.0757, -0.3904,  0.0258, -0.0446]],\n","\n","        [[-0.5031,  1.4130,  1.4337, -1.6267],\n","         [ 0.4232,  0.3819,  1.0871, -0.6616],\n","         [-0.2549, -0.0508,  0.2470, -0.4332],\n","         ...,\n","         [-0.3068, -0.3564,  0.0160, -0.0483],\n","         [-0.3005, -0.3753,  0.0184, -0.0538],\n","         [-0.3129, -0.3748,  0.0096, -0.0512]],\n","\n","        ...,\n","\n","        [[-1.4424, -1.2755,  2.5444,  0.0591],\n","         [-0.4754, -2.0140,  1.4289, -0.3414],\n","         [ 0.1329, -1.5591,  1.1995, -0.1264],\n","         ...,\n","         [-0.0399, -0.3658,  0.0717, -0.2263],\n","         [-0.0304, -0.3692,  0.0625, -0.2302],\n","         [-0.0210, -0.3726,  0.0533, -0.2340]],\n","\n","        [[ 0.1619,  0.6934, -0.4823, -0.2641],\n","         [-0.2192, -0.0840, -0.2693, -0.1689],\n","         [ 0.3037, -0.2724,  0.0673, -0.0114],\n","         ...,\n","         [ 0.0253, -0.4561, -0.1974, -0.2530],\n","         [ 0.0336, -0.4564, -0.2020, -0.2788],\n","         [ 0.0187, -0.4553, -0.2090, -0.2745]],\n","\n","        [[ 0.1619,  0.6934, -0.4823, -0.2641],\n","         [ 0.7253,  0.4860, -0.9455, -0.4738],\n","         [ 0.9333,  0.1076, -0.3835, -0.2147],\n","         ...,\n","         [-0.0386, -0.1862, -0.2189, -0.1082],\n","         [-0.0532, -0.1872, -0.2259, -0.1052],\n","         [-0.0523, -0.1850, -0.2217, -0.0960]]], device='cuda:0',\n","       grad_fn=<CopySlices>)\n"]}],"source":["bag_of_words = torch.zeros(size=(B, T, C)) # each of the values has a unique value\n","\n","for batch_idx in range(B):\n","    for context_idx in range(T):\n","        xprev = embedded[batch_idx, :context_idx+1]\n","        bag_of_words[batch_idx, context_idx] = torch.mean(xprev, dim=0)\n","print(bag_of_words)"]},{"cell_type":"code","execution_count":23,"id":"2f00e0a3","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.659166Z","iopub.status.busy":"2024-07-10T21:19:23.658844Z","iopub.status.idle":"2024-07-10T21:19:23.682489Z","shell.execute_reply":"2024-07-10T21:19:23.681488Z"},"papermill":{"duration":0.04958,"end_time":"2024-07-10T21:19:23.684537","exception":false,"start_time":"2024-07-10T21:19:23.634957","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 1., 1.]], device='cuda:0')\n","tensor([[61., 41., 17.],\n","        [ 6.,  4.,  1.],\n","        [20., 14., 17.]], device='cuda:0')\n","tensor([[54., 36.,  9.],\n","        [ 6.,  4.,  1.],\n","        [20., 14., 17.]], device='cuda:0')\n"]}],"source":["ones = torch.ones(size=(3, 3))\n","tril = torch.tril(ones) # lower triangular part of a matrix\n","print(tril)\n","a = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n","b = torch.randint(0, 10, (2, 3), dtype=torch.float32)\n","matmul_output = a @ b\n","matmul_tril_output = torch.tril(a) @ b\n","print(matmul_output)\n","print(matmul_tril_output)"]},{"cell_type":"code","execution_count":24,"id":"a851d2af","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.728207Z","iopub.status.busy":"2024-07-10T21:19:23.727872Z","iopub.status.idle":"2024-07-10T21:19:23.739804Z","shell.execute_reply":"2024-07-10T21:19:23.73854Z"},"papermill":{"duration":0.036714,"end_time":"2024-07-10T21:19:23.741925","exception":false,"start_time":"2024-07-10T21:19:23.705211","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 1., 1.]], device='cuda:0')\n","tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]], device='cuda:0')\n","tensor([[5.0000, 5.0000],\n","        [5.5000, 6.5000],\n","        [5.3333, 5.3333]], device='cuda:0')\n"]}],"source":["# do the same as bag of words but with matrix multiplication (dot product)\n","a = torch.ones(size=(3, 3), dtype=torch.float32)\n","b = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n","\n","a = torch.tril(a)\n","\"\"\"\n","b = torch.tensor(\n","    [\n","        [2, 7],\n","        [6, 4],\n","        [6, 5]\n","    ], dtype=torch.float32\n",")\n","\"\"\"\n","print(a)\n","a = a/a.sum(dim=1, keepdim=True)\n","print(a)\n","\n","output = a @ b\n","print(output)"]},{"cell_type":"code","execution_count":25,"id":"b5588adb","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.78794Z","iopub.status.busy":"2024-07-10T21:19:23.787613Z","iopub.status.idle":"2024-07-10T21:19:23.828006Z","shell.execute_reply":"2024-07-10T21:19:23.826908Z"},"papermill":{"duration":0.06562,"end_time":"2024-07-10T21:19:23.830195","exception":false,"start_time":"2024-07-10T21:19:23.764575","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 128, 4])\n","torch.Size([128, 128])\n","tensor([[[ 7.6019e-01,  2.8860e-02,  4.0811e-01, -3.6478e-02],\n","         [ 7.8799e-01,  4.5868e-01,  8.3820e-01,  5.6509e-01],\n","         [ 6.4575e-01,  7.8612e-01,  4.6441e-01,  4.9295e-01],\n","         ...,\n","         [-3.1060e-02,  6.0723e-03,  4.4947e-01,  4.1681e-01],\n","         [-4.2786e-02,  8.8795e-03,  4.5361e-01,  4.1451e-01],\n","         [-4.8643e-02,  1.1964e-02,  4.5928e-01,  4.1661e-01]],\n","\n","        [[-1.0767e+00, -4.7999e-01,  9.7094e-01,  3.1590e-01],\n","         [-6.6464e-01, -9.1798e-01,  6.1554e-01,  2.2937e-01],\n","         [-1.7116e-01, -3.1582e-01,  8.3312e-01,  5.4180e-01],\n","         ...,\n","         [-6.7564e-02, -1.5873e-03,  4.4038e-01,  5.5480e-01],\n","         [-6.6833e-02, -1.4725e-04,  4.3821e-01,  5.5713e-01],\n","         [-7.2502e-02,  3.0082e-03,  4.4400e-01,  5.5812e-01]],\n","\n","        [[ 5.2257e-01, -3.2790e-01,  8.4859e-01,  1.0093e+00],\n","         [ 6.6918e-01,  2.8030e-01,  1.0584e+00,  1.0880e+00],\n","         [-1.2662e-01, -2.0178e-01,  9.6252e-01,  7.2840e-01],\n","         ...,\n","         [ 5.8396e-03, -1.1395e-02,  3.5582e-01,  4.5771e-01],\n","         [-2.6846e-03, -1.5084e-02,  3.6066e-01,  4.5660e-01],\n","         [-4.6366e-03, -2.5560e-02,  3.5988e-01,  4.5415e-01]],\n","\n","        ...,\n","\n","        [[ 9.7587e-01, -9.5077e-01, -2.8585e-01, -4.9257e-01],\n","         [-5.0433e-02, -7.1538e-01,  3.4255e-01, -8.8334e-02],\n","         [ 2.3831e-01, -1.8075e-01,  6.5113e-01,  3.2999e-01],\n","         ...,\n","         [ 8.4573e-02,  1.0680e-01,  3.6361e-01,  4.8421e-01],\n","         [ 8.6752e-02,  1.1731e-01,  3.5851e-01,  4.8314e-01],\n","         [ 8.8896e-02,  1.2765e-01,  3.5350e-01,  4.8209e-01]],\n","\n","        [[-2.3367e-01, -3.2699e-01,  1.1626e+00,  1.2597e-01],\n","         [-1.6247e-01, -4.2443e-01, -5.5624e-01,  7.5974e-01],\n","         [ 1.6361e-01,  1.3218e-02,  5.1937e-02,  8.9537e-01],\n","         ...,\n","         [-1.1686e-01, -7.6495e-02,  4.9333e-01,  5.0433e-01],\n","         [-1.2068e-01, -8.1185e-02,  4.9754e-01,  5.2040e-01],\n","         [-1.2171e-01, -9.1144e-02,  4.9569e-01,  5.1745e-01]],\n","\n","        [[-2.3367e-01, -3.2699e-01,  1.1626e+00,  1.2597e-01],\n","         [-1.0417e-01, -7.2843e-02,  6.6391e-01,  4.8879e-01],\n","         [ 2.0248e-01,  2.4761e-01,  8.6537e-01,  7.1474e-01],\n","         ...,\n","         [-1.1258e-01,  7.0406e-02,  4.3667e-01,  4.5697e-01],\n","         [-1.1369e-01,  5.9175e-02,  4.3528e-01,  4.5450e-01],\n","         [-1.1487e-01,  4.7420e-02,  4.3840e-01,  4.5967e-01]]],\n","       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n"]}],"source":["sample_batch = next(iter(test_dataloader))[0]\n","B, T = sample_batch.shape # batch of B by T\n","example_emb = nn.Embedding(vocab_size, 4)\n","embedded = example_emb(sample_batch)\n","B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n","#print(embedded.shape)\n","\n","wei = torch.tril(torch.ones(size=(T, T)))\n","wei = wei / wei.sum(dim=1, keepdim=True)\n","print(embedded.shape) # B x T x C\n","print(wei.shape) # T x T\n","#  1xTxT @ BxTxC\n","bag_of_words = wei @ embedded\n","print(bag_of_words)"]},{"cell_type":"markdown","id":"9f5dd484","metadata":{"papermill":{"duration":0.020638,"end_time":"2024-07-10T21:19:23.871959","exception":false,"start_time":"2024-07-10T21:19:23.851321","status":"completed"},"tags":[]},"source":["# Bag of words type aggregation with a mask"]},{"cell_type":"code","execution_count":26,"id":"4534a746","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:23.915028Z","iopub.status.busy":"2024-07-10T21:19:23.914729Z","iopub.status.idle":"2024-07-10T21:19:23.93252Z","shell.execute_reply":"2024-07-10T21:19:23.931237Z"},"papermill":{"duration":0.041318,"end_time":"2024-07-10T21:19:23.934492","exception":false,"start_time":"2024-07-10T21:19:23.893174","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n","        [0.3333, 0.3333, 0.3333,  ..., 0.0000, 0.0000, 0.0000],\n","        ...,\n","        [0.0079, 0.0079, 0.0079,  ..., 0.0079, 0.0000, 0.0000],\n","        [0.0079, 0.0079, 0.0079,  ..., 0.0079, 0.0079, 0.0000],\n","        [0.0078, 0.0078, 0.0078,  ..., 0.0078, 0.0078, 0.0078]],\n","       device='cuda:0')\n","tensor([[[ 7.6019e-01,  2.8860e-02,  4.0811e-01, -3.6478e-02],\n","         [ 7.8799e-01,  4.5868e-01,  8.3820e-01,  5.6509e-01],\n","         [ 6.4575e-01,  7.8612e-01,  4.6441e-01,  4.9295e-01],\n","         ...,\n","         [-3.1060e-02,  6.0723e-03,  4.4947e-01,  4.1681e-01],\n","         [-4.2786e-02,  8.8795e-03,  4.5361e-01,  4.1451e-01],\n","         [-4.8643e-02,  1.1964e-02,  4.5928e-01,  4.1661e-01]],\n","\n","        [[-1.0767e+00, -4.7999e-01,  9.7094e-01,  3.1590e-01],\n","         [-6.6464e-01, -9.1798e-01,  6.1554e-01,  2.2937e-01],\n","         [-1.7116e-01, -3.1582e-01,  8.3312e-01,  5.4180e-01],\n","         ...,\n","         [-6.7564e-02, -1.5873e-03,  4.4038e-01,  5.5480e-01],\n","         [-6.6833e-02, -1.4725e-04,  4.3821e-01,  5.5713e-01],\n","         [-7.2502e-02,  3.0082e-03,  4.4400e-01,  5.5812e-01]],\n","\n","        [[ 5.2257e-01, -3.2790e-01,  8.4859e-01,  1.0093e+00],\n","         [ 6.6918e-01,  2.8030e-01,  1.0584e+00,  1.0880e+00],\n","         [-1.2662e-01, -2.0178e-01,  9.6252e-01,  7.2840e-01],\n","         ...,\n","         [ 5.8396e-03, -1.1395e-02,  3.5582e-01,  4.5771e-01],\n","         [-2.6846e-03, -1.5084e-02,  3.6066e-01,  4.5660e-01],\n","         [-4.6366e-03, -2.5560e-02,  3.5988e-01,  4.5415e-01]],\n","\n","        ...,\n","\n","        [[ 9.7587e-01, -9.5077e-01, -2.8585e-01, -4.9257e-01],\n","         [-5.0433e-02, -7.1538e-01,  3.4255e-01, -8.8334e-02],\n","         [ 2.3831e-01, -1.8075e-01,  6.5113e-01,  3.2999e-01],\n","         ...,\n","         [ 8.4573e-02,  1.0680e-01,  3.6361e-01,  4.8421e-01],\n","         [ 8.6752e-02,  1.1731e-01,  3.5851e-01,  4.8314e-01],\n","         [ 8.8896e-02,  1.2765e-01,  3.5350e-01,  4.8209e-01]],\n","\n","        [[-2.3367e-01, -3.2699e-01,  1.1626e+00,  1.2597e-01],\n","         [-1.6247e-01, -4.2443e-01, -5.5624e-01,  7.5974e-01],\n","         [ 1.6361e-01,  1.3218e-02,  5.1937e-02,  8.9537e-01],\n","         ...,\n","         [-1.1686e-01, -7.6495e-02,  4.9333e-01,  5.0433e-01],\n","         [-1.2068e-01, -8.1185e-02,  4.9754e-01,  5.2040e-01],\n","         [-1.2171e-01, -9.1144e-02,  4.9569e-01,  5.1745e-01]],\n","\n","        [[-2.3367e-01, -3.2699e-01,  1.1626e+00,  1.2597e-01],\n","         [-1.0417e-01, -7.2843e-02,  6.6391e-01,  4.8879e-01],\n","         [ 2.0248e-01,  2.4761e-01,  8.6537e-01,  7.1474e-01],\n","         ...,\n","         [-1.1258e-01,  7.0406e-02,  4.3667e-01,  4.5697e-01],\n","         [-1.1369e-01,  5.9175e-02,  4.3528e-01,  4.5450e-01],\n","         [-1.1487e-01,  4.7420e-02,  4.3840e-01,  4.5967e-01]]],\n","       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n"]}],"source":["tril = torch.tril(torch.ones(size=(T, T)))\n","wei = torch.zeros(size=(T, T)) # zeros just so there's a plaaceholder for masked_fill\n","wei = wei.masked_fill(tril==0, float(\"-inf\")) # whenever the value in tril is 0, it will get replaced with -inf; this allows softmax to come into place, since -inf will get a percent of 0\n","wei = torch.softmax(wei, dim=1)\n","print(wei)\n","bag_of_words = wei @ embedded\n","print(bag_of_words)"]},{"cell_type":"markdown","id":"c4478e7f","metadata":{"papermill":{"duration":0.020574,"end_time":"2024-07-10T21:19:23.975914","exception":false,"start_time":"2024-07-10T21:19:23.95534","status":"completed"},"tags":[]},"source":["# MLP model with agreggation\n","- a problem that needs to be addressed with the previous model is that it needs to always receive a input of B x T (batch_size by context_size), whereas it would be best if the model could adapt to inputs of different context_size"]},{"cell_type":"code","execution_count":27,"id":"5da83471","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.019439Z","iopub.status.busy":"2024-07-10T21:19:24.019186Z","iopub.status.idle":"2024-07-10T21:19:24.032339Z","shell.execute_reply":"2024-07-10T21:19:24.030909Z"},"papermill":{"duration":0.037729,"end_time":"2024-07-10T21:19:24.034305","exception":false,"start_time":"2024-07-10T21:19:23.996576","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[-2.9187e-01,  9.7878e-01, -1.1457e+00,  7.6321e-01],\n","         [ 2.7074e-01,  3.2424e-01,  1.4588e-01,  2.1881e-01],\n","         [ 6.8003e-01, -5.8981e-02,  4.3124e-02, -9.4029e-02],\n","         ...,\n","         [ 6.6365e-02,  4.5040e-02,  7.2592e-02, -1.0932e-01],\n","         [ 7.4244e-02,  4.9955e-02,  9.1549e-02, -9.7730e-02],\n","         [ 7.6225e-02,  4.4056e-02,  9.0803e-02, -1.0479e-01]],\n","\n","        [[ 1.0964e+00, -1.6107e+00,  6.6661e-01,  6.9881e-01],\n","         [ 2.8685e-01, -7.6096e-01, -6.4121e-01,  2.2426e-01],\n","         [ 1.6113e-01, -7.7475e-01, -5.8018e-01,  3.3083e-01],\n","         ...,\n","         [ 1.0633e-01, -1.0349e-01, -2.7788e-02, -5.8346e-02],\n","         [ 1.0075e-01, -9.4910e-02, -2.8888e-02, -6.6626e-02],\n","         [ 9.4589e-02, -8.6337e-02, -1.9282e-02, -7.9699e-02]],\n","\n","        [[ 2.5255e-01, -5.6990e-01, -3.1766e-01,  1.3747e+00],\n","         [-3.4899e-01, -7.8460e-01, -1.7710e+00,  1.0325e+00],\n","         [-9.8026e-02,  3.7190e-01, -1.3154e+00,  6.8815e-01],\n","         ...,\n","         [ 8.2380e-02, -5.7487e-02, -2.3795e-01,  1.2956e-02],\n","         [ 7.0561e-02, -3.7561e-02, -2.4273e-01,  1.0896e-02],\n","         [ 5.7626e-02, -3.7699e-02, -2.4013e-01,  1.2330e-02]],\n","\n","        ...,\n","\n","        [[-1.4832e+00,  1.5035e-02,  1.2389e+00, -6.9739e-01],\n","         [-4.1121e-01,  4.1495e-01,  1.0938e+00, -6.1373e-01],\n","         [ 8.8762e-02,  5.4701e-01,  2.2756e-01, -3.2784e-01],\n","         ...,\n","         [ 2.6455e-02,  1.6693e-02,  4.5279e-03,  1.0148e-01],\n","         [ 1.6670e-02,  1.7086e-02,  2.6061e-04,  1.0755e-01],\n","         [ 1.1825e-02,  8.9503e-03,  7.2898e-03,  9.7575e-02]],\n","\n","        [[-6.7693e-01, -1.5072e+00, -7.7186e-02,  8.1054e-01],\n","         [-6.3701e-01, -5.0080e-01, -1.2920e-01, -4.9977e-01],\n","         [-8.1478e-01, -4.0700e-01,  3.1170e-01, -8.7461e-01],\n","         ...,\n","         [ 2.3232e-02,  4.2242e-02, -1.3611e-01, -1.0150e-01],\n","         [ 3.1533e-02,  4.5459e-02, -1.3062e-01, -9.2758e-02],\n","         [ 3.2547e-02,  4.5477e-02, -1.3184e-01, -1.0315e-01]],\n","\n","        [[-1.7695e+00,  1.3164e+00,  1.4274e+00,  7.4949e-01],\n","         [-9.3245e-01,  4.5172e-01,  9.3507e-01,  5.1575e-01],\n","         [-2.3249e-01,  1.4321e-01,  5.2957e-01, -3.3050e-01],\n","         ...,\n","         [-7.0976e-02, -1.5056e-01, -1.7810e-02, -5.5037e-04],\n","         [-8.0084e-02, -1.4544e-01, -2.3898e-02,  5.1532e-03],\n","         [-7.7925e-02, -1.4932e-01, -2.5427e-02,  9.0042e-03]]],\n","       device='cuda:0')\n"]}],"source":["# Code to allow comunication between past tokens\n","n_embd = 4\n","C = n_embd\n","T = context_size\n","B = batch_size\n","wei = torch.zeros(size=(T, T))\n","tril = torch.tril(torch.ones(size=(T, T)))\n","wei = wei.masked_fill(tril==0, float('-inf'))\n","xbow = wei.softmax(dim=1)\n","\n","test_tensor = torch.randn(size=(B, T, C))\n","print(xbow @ test_tensor)"]},{"cell_type":"code","execution_count":28,"id":"4093346e","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.078898Z","iopub.status.busy":"2024-07-10T21:19:24.078656Z","iopub.status.idle":"2024-07-10T21:19:24.084382Z","shell.execute_reply":"2024-07-10T21:19:24.08352Z"},"papermill":{"duration":0.03062,"end_time":"2024-07-10T21:19:24.086326","exception":false,"start_time":"2024-07-10T21:19:24.055706","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 128])\n","torch.Size([32, 128])\n"]}],"source":["# a problem that needs to be addressed with the previous model is that it needs to always receive a \n","batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n","print(batch_sample_inputs.shape)\n","print(batch_sample_labels.shape)"]},{"cell_type":"markdown","id":"d8704a89","metadata":{"papermill":{"duration":0.021237,"end_time":"2024-07-10T21:19:24.128697","exception":false,"start_time":"2024-07-10T21:19:24.10746","status":"completed"},"tags":[]},"source":["# Code cleanup"]},{"cell_type":"code","execution_count":29,"id":"6dea7738","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.173642Z","iopub.status.busy":"2024-07-10T21:19:24.173319Z","iopub.status.idle":"2024-07-10T21:19:24.186156Z","shell.execute_reply":"2024-07-10T21:19:24.185351Z"},"papermill":{"duration":0.037664,"end_time":"2024-07-10T21:19:24.188117","exception":false,"start_time":"2024-07-10T21:19:24.150453","status":"completed"},"tags":[]},"outputs":[],"source":["class MLPv2(nn.Module):\n","    def __init__(self, vocab_size, n_embd, context_size):\n","        super().__init__()\n","\n","        self.vocab_size = vocab_size\n","        self.n_embd = n_embd\n","        self.context_size = context_size\n","\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n","\n","        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n","        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n","        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n","        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n","\n","        self.act_fn = nn.Tanh()\n","\n","    def info(self):\n","        info_dict = {\n","            \"vocab_size\": self.vocab_size,\n","            \"n_embd\": self.n_embd,\n","            \"context_size\": self.context_size\n","        }\n","\n","        return info_dict\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T = x.shape\n","        C = self.n_embd\n","\n","        #print(B, T, C)\n","\n","        positions = torch.arange(start=0, end=T, step=1)\n","        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n","        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n","\n","        x = token_emb + pos_emb\n","        x = x.view(B*T, C)\n","\n","        #logits = self.lm_head(token_emb.view(B*T, C)) # output of shape B*T x hidden_units1; this might be a problem for the labels since they are of shape B x T, thus they need to be reshaped aswell\n","        x = self.act_fn(self.linear1(token_emb.view(B*T, C))) # hidden_units1 x hidden_units2\n","        x = self.act_fn(self.linear2(x)) # hidden_units2 x hidden_units3\n","        x = self.linear3(x) # hidden_units3 x vocab_size\n","        return x\n","\n","    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n","\n","        full_text = itos[starting_idx.item()]\n","        for i in range(max_length):\n","            logits = self(starting_idx)\n","            percents = torch.softmax(logits, dim=1)\n","            pred = torch.multinomial(percents, num_samples=1)\n","            starting_idx = pred\n","            full_text += decode([pred.item()])\n","        return full_text\n"]},{"cell_type":"code","execution_count":30,"id":"2e1c310a","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.231558Z","iopub.status.busy":"2024-07-10T21:19:24.231265Z","iopub.status.idle":"2024-07-10T21:19:24.236533Z","shell.execute_reply":"2024-07-10T21:19:24.235898Z"},"papermill":{"duration":0.029477,"end_time":"2024-07-10T21:19:24.23871","exception":false,"start_time":"2024-07-10T21:19:24.209233","status":"completed"},"tags":[]},"outputs":[],"source":["mlpv2 = MLPv2(vocab_size=vocab_size, n_embd=32, context_size=context_size)"]},{"cell_type":"code","execution_count":31,"id":"dfcb1fc3","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.283363Z","iopub.status.busy":"2024-07-10T21:19:24.283109Z","iopub.status.idle":"2024-07-10T21:19:24.28953Z","shell.execute_reply":"2024-07-10T21:19:24.288703Z"},"papermill":{"duration":0.031703,"end_time":"2024-07-10T21:19:24.291352","exception":false,"start_time":"2024-07-10T21:19:24.259649","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["{'vocab_size': 65, 'n_embd': 32, 'context_size': 128}"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["mlpv2.info()"]},{"cell_type":"code","execution_count":32,"id":"7577a10b","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.335051Z","iopub.status.busy":"2024-07-10T21:19:24.334816Z","iopub.status.idle":"2024-07-10T21:19:24.350509Z","shell.execute_reply":"2024-07-10T21:19:24.349578Z"},"papermill":{"duration":0.03934,"end_time":"2024-07-10T21:19:24.352277","exception":false,"start_time":"2024-07-10T21:19:24.312937","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([44,  1, 57, 53, 51, 43,  1, 57, 47, 62,  1, 53, 56,  1, 57, 43, 60, 43,\n","        52,  6,  0, 58, 46, 43,  1, 51, 53, 57, 58,  1, 57, 59, 44, 44, 47, 41,\n","        47, 43, 52, 58,  1, 53, 44,  1, 63, 53, 59, 56,  1, 54, 39, 56, 47, 57,\n","        46,  8,  0,  0, 17, 24, 14, 27, 35, 10,  0, 32, 53,  1, 63, 53, 59, 56,\n","         1, 61, 53, 56, 57, 46, 47, 54,  5, 57,  1, 46, 53, 59, 57, 43,  6,  1,\n","        57, 47, 56, 12,  0,  0, 17, 31, 15, 13, 24, 33, 31, 10,  0, 32, 53,  1,\n","        51, 63,  1, 46, 53, 59, 57, 43,  8,  1, 18, 39, 56, 43,  1, 63, 53, 59,\n","         1, 61], device='cuda:0')\n","tensor([[ 1, 57, 53, 51, 43,  1, 57, 47, 62,  1, 53, 56,  1, 57, 43, 60, 43, 52,\n","          6,  0, 58, 46, 43,  1, 51, 53, 57, 58,  1, 57, 59, 44, 44, 47, 41, 47,\n","         43, 52, 58,  1, 53, 44,  1, 63, 53, 59, 56,  1, 54, 39, 56, 47, 57, 46,\n","          8,  0,  0, 17, 24, 14, 27, 35, 10,  0, 32, 53,  1, 63, 53, 59, 56,  1,\n","         61, 53, 56, 57, 46, 47, 54,  5, 57,  1, 46, 53, 59, 57, 43,  6,  1, 57,\n","         47, 56, 12,  0,  0, 17, 31, 15, 13, 24, 33, 31, 10,  0, 32, 53,  1, 51,\n","         63,  1, 46, 53, 59, 57, 43,  8,  1, 18, 39, 56, 43,  1, 63, 53, 59,  1,\n","         61, 43]], device='cuda:0')\n","torch.Size([128, 65])\n","torch.Size([128])\n","tensor(4.1827, device='cuda:0')\n"]}],"source":["mlpv2_loss_fn = nn.CrossEntropyLoss()\n","batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n","sample_input = batch_sample_inputs[0]\n","sample_label = batch_sample_labels[0]\n","print(sample_input) # 1 x T (B x T)\n","print(sample_label.view(1, -1)) # 1 x T (B x T)\n","mlpv2.eval()\n","with torch.inference_mode():\n","    logits = mlpv2(sample_input.view(1, -1))\n","    labels = sample_label.view(-1) # from B x T to B*T to match the shape of the logits\n","    print(logits.shape) # B*T x vocab_size\n","    print(labels.shape)\n","\n","    loss = mlpv2_loss_fn(logits, labels)\n","    print(loss)"]},{"cell_type":"code","execution_count":33,"id":"6365aeee","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.395547Z","iopub.status.busy":"2024-07-10T21:19:24.395256Z","iopub.status.idle":"2024-07-10T21:19:24.40078Z","shell.execute_reply":"2024-07-10T21:19:24.399935Z"},"papermill":{"duration":0.029282,"end_time":"2024-07-10T21:19:24.402689","exception":false,"start_time":"2024-07-10T21:19:24.373407","status":"completed"},"tags":[]},"outputs":[],"source":["@torch.no_grad\n","def generate_from_model(model, num_outputs, starting_char, max_length):\n","    mlpv2.eval()\n","    outputs = []\n","    starting_idx = torch.tensor([stoi[starting_char]], dtype=torch.long).view(1, -1)\n","    for i in range(num_outputs):\n","        output = mlpv2.generate(starting_idx=starting_idx, max_length=max_length) # must be batched\n","        outputs.append(output)\n","\n","    return outputs"]},{"cell_type":"code","execution_count":34,"id":"7b2eff4f","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.445673Z","iopub.status.busy":"2024-07-10T21:19:24.445403Z","iopub.status.idle":"2024-07-10T21:19:24.48283Z","shell.execute_reply":"2024-07-10T21:19:24.481816Z"},"papermill":{"duration":0.060955,"end_time":"2024-07-10T21:19:24.48469","exception":false,"start_time":"2024-07-10T21:19:24.423735","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["aqRPeX\n"]}],"source":["test_output = generate_from_model(model=mlpv2, num_outputs=1, starting_char=\"a\", max_length=5)\n","print(test_output[0])"]},{"cell_type":"code","execution_count":35,"id":"2e9b17f0","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.530259Z","iopub.status.busy":"2024-07-10T21:19:24.529951Z","iopub.status.idle":"2024-07-10T21:19:24.536461Z","shell.execute_reply":"2024-07-10T21:19:24.535432Z"},"papermill":{"duration":0.032082,"end_time":"2024-07-10T21:19:24.538517","exception":false,"start_time":"2024-07-10T21:19:24.506435","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","\n","    for epoch in range(epochs):\n","        for batch, (X, y) in enumerate(dataloader):\n","            logits = model(X)\n","            loss = loss_fn(logits, y.view(-1))\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","\n","            if batch % 20 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n","\n","    print(f\"loss for the very last batch --> {loss}\")"]},{"cell_type":"code","execution_count":36,"id":"3afff4ba","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.585037Z","iopub.status.busy":"2024-07-10T21:19:24.584355Z","iopub.status.idle":"2024-07-10T21:19:24.588803Z","shell.execute_reply":"2024-07-10T21:19:24.587904Z"},"papermill":{"duration":0.028829,"end_time":"2024-07-10T21:19:24.590719","exception":false,"start_time":"2024-07-10T21:19:24.56189","status":"completed"},"tags":[]},"outputs":[],"source":["mlpv2_optimizer = torch.optim.Adam(params=mlpv2.parameters(), lr=1e-3)\n","mlpv2_loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":37,"id":"bfdedeaa","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:24.634302Z","iopub.status.busy":"2024-07-10T21:19:24.63385Z","iopub.status.idle":"2024-07-10T21:19:26.969421Z","shell.execute_reply":"2024-07-10T21:19:26.96845Z"},"papermill":{"duration":2.359492,"end_time":"2024-07-10T21:19:26.971357","exception":false,"start_time":"2024-07-10T21:19:24.611865","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.183022499084473 at epoch 0\n","loss for batch 20 --> 2.9723587036132812 at epoch 0\n","loss for batch 40 --> 2.7465195655822754 at epoch 0\n","loss for batch 60 --> 2.7067058086395264 at epoch 0\n","loss for batch 80 --> 2.5965919494628906 at epoch 0\n","loss for batch 100 --> 2.5509095191955566 at epoch 0\n","loss for batch 120 --> 2.493223190307617 at epoch 0\n","loss for batch 140 --> 2.535734176635742 at epoch 0\n","loss for batch 160 --> 2.508403778076172 at epoch 0\n","loss for batch 180 --> 2.5316035747528076 at epoch 0\n","loss for batch 200 --> 2.5006420612335205 at epoch 0\n","loss for batch 0 --> 2.4882824420928955 at epoch 1\n","loss for batch 20 --> 2.4636991024017334 at epoch 1\n","loss for batch 40 --> 2.4904398918151855 at epoch 1\n","loss for batch 60 --> 2.507495880126953 at epoch 1\n","loss for batch 80 --> 2.4819583892822266 at epoch 1\n","loss for batch 100 --> 2.4858243465423584 at epoch 1\n","loss for batch 120 --> 2.434555768966675 at epoch 1\n","loss for batch 140 --> 2.4825916290283203 at epoch 1\n","loss for batch 160 --> 2.4720678329467773 at epoch 1\n","loss for batch 180 --> 2.490314483642578 at epoch 1\n","loss for batch 200 --> 2.471561908721924 at epoch 1\n","loss for batch 0 --> 2.462867498397827 at epoch 2\n","loss for batch 20 --> 2.4447033405303955 at epoch 2\n","loss for batch 40 --> 2.4724435806274414 at epoch 2\n","loss for batch 60 --> 2.487666606903076 at epoch 2\n","loss for batch 80 --> 2.469944477081299 at epoch 2\n","loss for batch 100 --> 2.47653865814209 at epoch 2\n","loss for batch 120 --> 2.4266984462738037 at epoch 2\n","loss for batch 140 --> 2.4696402549743652 at epoch 2\n","loss for batch 160 --> 2.4647293090820312 at epoch 2\n","loss for batch 180 --> 2.480038642883301 at epoch 2\n","loss for batch 200 --> 2.463899612426758 at epoch 2\n","loss for batch 0 --> 2.4559199810028076 at epoch 3\n","loss for batch 20 --> 2.439657688140869 at epoch 3\n","loss for batch 40 --> 2.4665918350219727 at epoch 3\n","loss for batch 60 --> 2.4799318313598633 at epoch 3\n","loss for batch 80 --> 2.465050458908081 at epoch 3\n","loss for batch 100 --> 2.4722235202789307 at epoch 3\n","loss for batch 120 --> 2.42327618598938 at epoch 3\n","loss for batch 140 --> 2.4639718532562256 at epoch 3\n","loss for batch 160 --> 2.46121883392334 at epoch 3\n","loss for batch 180 --> 2.4748423099517822 at epoch 3\n","loss for batch 200 --> 2.460458755493164 at epoch 3\n","loss for the very last batch --> 2.3661887645721436\n"]}],"source":["train_model(model=mlpv2, dataloader=train_dataloader, loss_fn=mlpv2_loss_fn, optimizer=mlpv2_optimizer, epochs=4)"]},{"cell_type":"code","execution_count":38,"id":"f045f73d","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.019441Z","iopub.status.busy":"2024-07-10T21:19:27.019168Z","iopub.status.idle":"2024-07-10T21:19:27.14079Z","shell.execute_reply":"2024-07-10T21:19:27.139735Z"},"papermill":{"duration":0.147884,"end_time":"2024-07-10T21:19:27.142953","exception":false,"start_time":"2024-07-10T21:19:26.995069","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["bris t, beswenngl berofan, Whepalmal oughen sthaiay.\n","NThrtoul's bepe;\n","Pn r\n","ERWherus\n","\n","ICaul ir thavero\n","\n","\n","boussise my I's h:\n","\n","MNE:\n","Whay m th whenothino hey po I ifrmeang merdecome s CHires frrtherhecks man h\n","\n","\n"]}],"source":["test_outputs = generate_from_model(model=mlpv2, max_length=100, num_outputs=2, starting_char=\"b\")\n","for output in test_outputs:\n","    print(f\"{output}\\n\\n\")"]},{"cell_type":"markdown","id":"d2f30951","metadata":{"papermill":{"duration":0.022919,"end_time":"2024-07-10T21:19:27.188985","exception":false,"start_time":"2024-07-10T21:19:27.166066","status":"completed"},"tags":[]},"source":["# Self attention\n","- with xbow you can add information about the tokens, but the model itself does not attribute any weight to them. This is what self attention solves by using Keys, Queries and Values\n","- every token will have a specific Query (Q) and Key (K) attatched to it\n","    - Query --> what the model is looking for\n","    - Key --> the weight the model is giving to this certain token\n","    - Value --> matches queires and keys"]},{"cell_type":"code","execution_count":39,"id":"26a07a26","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.241266Z","iopub.status.busy":"2024-07-10T21:19:27.240915Z","iopub.status.idle":"2024-07-10T21:19:27.24966Z","shell.execute_reply":"2024-07-10T21:19:27.248621Z"},"papermill":{"duration":0.038201,"end_time":"2024-07-10T21:19:27.251813","exception":false,"start_time":"2024-07-10T21:19:27.213612","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 4, 8])\n"]}],"source":["# Code to allow comunication between past tokens\n","\n","B, T, C = 2, 4, 8\n","wei = torch.zeros(size=(T, T))\n","tril = torch.tril(torch.ones(size=(T, T)))\n","wei = wei.masked_fill(tril==0, float('-inf'))\n","xbow = wei.softmax(dim=1)\n","\n","test_tensor = torch.randn(size=(B, T, C))\n","output = xbow @ test_tensor\n","print(output.shape)"]},{"cell_type":"code","execution_count":40,"id":"3c01f86b","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.30514Z","iopub.status.busy":"2024-07-10T21:19:27.304841Z","iopub.status.idle":"2024-07-10T21:19:27.313069Z","shell.execute_reply":"2024-07-10T21:19:27.312092Z"},"papermill":{"duration":0.037674,"end_time":"2024-07-10T21:19:27.315162","exception":false,"start_time":"2024-07-10T21:19:27.277488","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 4, 32])\n","torch.Size([2, 4, 32])\n"]}],"source":["head_size = 32\n","key = nn.Linear(in_features=C, out_features=head_size, bias=False) # bias = False so that it's just a multiplication\n","query = nn.Linear(in_features=C, out_features=head_size, bias=False) \n","\n","#print(test_tensor.shape)\n","k = key(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a key value\n","q = query(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a query value\n","print(k.shape)\n","print(q.shape)"]},{"cell_type":"code","execution_count":41,"id":"db759533","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.364317Z","iopub.status.busy":"2024-07-10T21:19:27.364053Z","iopub.status.idle":"2024-07-10T21:19:27.373657Z","shell.execute_reply":"2024-07-10T21:19:27.372667Z"},"papermill":{"duration":0.035792,"end_time":"2024-07-10T21:19:27.375535","exception":false,"start_time":"2024-07-10T21:19:27.339743","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 32, 4])\n","torch.Size([2, 32, 4])\n","torch.Size([2, 4, 4])\n","torch.Size([2, 4, 8])\n"]}],"source":["print(k.transpose(-2, -1).shape) # same as k.permute(0, 2, 1)\n","print(k.permute(0, 2, 1).shape)\n","\n","wei = q @ k.transpose(-2, -1) # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n","print(wei.shape) #  B x T x T\n","\n","tril = torch.tril(torch.ones(size=(T, T)))\n","wei = wei.masked_fill(tril==0, float('-inf'))\n","wei = torch.softmax(wei, dim=-1) # dim=-1 in this case, since wei is of shape\n","\n","output = wei @ test_tensor\n","\n","print(output.shape) # B x T x C"]},{"cell_type":"markdown","id":"1dd676ef","metadata":{"papermill":{"duration":0.022749,"end_time":"2024-07-10T21:19:27.422131","exception":false,"start_time":"2024-07-10T21:19:27.399382","status":"completed"},"tags":[]},"source":["# Update the model with self attention"]},{"cell_type":"markdown","id":"680226c9","metadata":{"papermill":{"duration":0.02459,"end_time":"2024-07-10T21:19:27.469808","exception":false,"start_time":"2024-07-10T21:19:27.445218","status":"completed"},"tags":[]},"source":["## Head"]},{"cell_type":"code","execution_count":42,"id":"281f4461","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.519885Z","iopub.status.busy":"2024-07-10T21:19:27.51958Z","iopub.status.idle":"2024-07-10T21:19:27.528141Z","shell.execute_reply":"2024-07-10T21:19:27.527201Z"},"papermill":{"duration":0.036234,"end_time":"2024-07-10T21:19:27.530105","exception":false,"start_time":"2024-07-10T21:19:27.493871","status":"completed"},"tags":[]},"outputs":[],"source":["class Head(nn.Module):\n","    def __init__(self, n_embd, head_size, context_size):\n","        super(Head, self).__init__()\n","        \n","        self.Q = nn.Linear(in_features=n_embd, out_features=head_size) # takes in BxTxC and return BxTxHead_size\n","        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n","        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n","        \n","        self.register_buffer(\"tril\", torch.tril(torch.ones(size=(context_size, context_size))))\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T, C = x.shape # batch_size by context_size by n_embd\n","        q = self.Q(x) # BxTxHead_size\n","        k = self.K(x) # BxTxHead_size\n","        \n","        wei = q @ k.transpose(-2, -1) * (C ** -0.5) # BxTxHead_size @ BxHead_sizexT --> BxTxT then divided by the square root of n_embd\n","        \n","        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # :T and :T is needed in case context is smaller than context_size\n","        wei = torch.softmax(wei, dim=-1)\n","        v = self.V(x) # BxTxHead_size\n","        output = wei @ v # BxTxT @ BxTxHead_size --> BxTxHead_size\n","        \n","        return output"]},{"cell_type":"markdown","id":"38b4c399","metadata":{"papermill":{"duration":0.023208,"end_time":"2024-07-10T21:19:27.57694","exception":false,"start_time":"2024-07-10T21:19:27.553732","status":"completed"},"tags":[]},"source":["## Multiheaded Attention\n","- multiple heads concatenated together for better data representation"]},{"cell_type":"code","execution_count":43,"id":"75fe9274","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.624304Z","iopub.status.busy":"2024-07-10T21:19:27.624037Z","iopub.status.idle":"2024-07-10T21:19:27.630787Z","shell.execute_reply":"2024-07-10T21:19:27.629977Z"},"papermill":{"duration":0.032719,"end_time":"2024-07-10T21:19:27.632997","exception":false,"start_time":"2024-07-10T21:19:27.600278","status":"completed"},"tags":[]},"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, n_embd, context_size, n_heads, head_size):\n","        super(MultiHeadedAttention, self).__init__()\n","        \n","        self.heads = nn.ModuleList([Head(n_embd=n_embd, head_size=head_size, context_size=context_size) for _ in range(n_heads)]) # BxTx (n_heads * head_size)\n","        self.projection = nn.Linear(in_features=n_heads*head_size, out_features=n_embd) # ensures the output is going to be o shape BxTxn_embd (BxTxC) so that is can go through multiple attention block\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = torch.cat([head(x) for head in self.heads], dim=-1) # cat in the Channels dimension; output shape is BxTx (n_heads * head_size)\n","        #print(f\"multihead output shape is {out.shape}\")\n","        #return out\n","\n","        x = self.projection(x)\n","        return  x"]},{"cell_type":"markdown","id":"d7796fa8","metadata":{"papermill":{"duration":0.02353,"end_time":"2024-07-10T21:19:27.67965","exception":false,"start_time":"2024-07-10T21:19:27.65612","status":"completed"},"tags":[]},"source":["## Feedforward\n","- just a simple feedforward to scale the logits from each attention block"]},{"cell_type":"code","execution_count":44,"id":"d616ebf9","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.726831Z","iopub.status.busy":"2024-07-10T21:19:27.726568Z","iopub.status.idle":"2024-07-10T21:19:27.732319Z","shell.execute_reply":"2024-07-10T21:19:27.731517Z"},"papermill":{"duration":0.031469,"end_time":"2024-07-10T21:19:27.73424","exception":false,"start_time":"2024-07-10T21:19:27.702771","status":"completed"},"tags":[]},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, in_features):\n","        super(FeedForward, self).__init__()\n","\n","        self.ffwrd_layer = nn.Sequential(\n","            nn.Linear(in_features=in_features, out_features=in_features * 4), # scale by 4, according to the attention is all you need paper\n","            nn.ReLU(),\n","            nn.Linear(in_features=in_features * 4, out_features=in_features) # another projection layer\n","        )\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.ffwrd_layer(x)"]},{"cell_type":"markdown","id":"7d8e1497","metadata":{"papermill":{"duration":0.023177,"end_time":"2024-07-10T21:19:27.782099","exception":false,"start_time":"2024-07-10T21:19:27.758922","status":"completed"},"tags":[]},"source":["# Attention block\n","- Make a class so that multiheaded attention can be applied multiple times, alongside layer normalization and the sum of residual connections"]},{"cell_type":"code","execution_count":45,"id":"b8b03ff1","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.829882Z","iopub.status.busy":"2024-07-10T21:19:27.829619Z","iopub.status.idle":"2024-07-10T21:19:27.836044Z","shell.execute_reply":"2024-07-10T21:19:27.835218Z"},"papermill":{"duration":0.032858,"end_time":"2024-07-10T21:19:27.838018","exception":false,"start_time":"2024-07-10T21:19:27.80516","status":"completed"},"tags":[]},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, n_heads, head_size, n_embd, context_size):\n","        super(Block, self).__init__()\n","        self.multiheaded_self_attetion = MultiHeadedAttention(n_embd=n_embd, context_size=context_size, n_heads=n_heads, head_size=head_size) # create a multiheaded attention block; returns shape BxTx (num_heads*head_size)\n","        #self.ffwrd = FeedForward(in_features=n_heads*head_size) # returns shape BxTx (num_heads*head_size) --> this is only in case there is no projection layer inside of multiheaded attention\n","        self.ffwrd = FeedForward(in_features=n_embd)\n","\n","        self.layer_norm1 = nn.LayerNorm(n_embd)\n","        self.layer_norm2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        # /// no residual connections ///\n","        #x = self.multiheaded_self_attetion(x)\n","        #x = self.ffwrd(x)\n","\n","        # /// with residual conections for better optimization ///\n","        x = x + self.multiheaded_self_attetion(self.layer_norm1(x))\n","        x = x + self.ffwrd(self.layer_norm2(x))\n","\n","        return x"]},{"cell_type":"markdown","id":"b7cd5975","metadata":{"papermill":{"duration":0.022919,"end_time":"2024-07-10T21:19:27.884575","exception":false,"start_time":"2024-07-10T21:19:27.861656","status":"completed"},"tags":[]},"source":["# Decoder transformer"]},{"cell_type":"code","execution_count":46,"id":"d9552385","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:27.93235Z","iopub.status.busy":"2024-07-10T21:19:27.932039Z","iopub.status.idle":"2024-07-10T21:19:27.947214Z","shell.execute_reply":"2024-07-10T21:19:27.94638Z"},"papermill":{"duration":0.041679,"end_time":"2024-07-10T21:19:27.949321","exception":false,"start_time":"2024-07-10T21:19:27.907642","status":"completed"},"tags":[]},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, n_embd, context_size, vocab_size, num_sa_heads, sa_head_size):\n","        super().__init__()\n","        \n","        self.vocab_size = vocab_size\n","        self.context_size = context_size\n","        self.n_embd = n_embd\n","        \n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # each character from the vocab has n_embd values associated to it\n","        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # each character position in the context has n_embd values associated to it\n","        \n","        \n","        # /// Some previous modifications for testing purposes ///\n","        \n","        #self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n","        #self.linear2 = nn.Linear(in_features=8*8, out_features=vocab_size)\n","        #self.act_fn = nn.Tanh()\n","\n","        #self.sa_head_size = 64\n","        #self.sa_head_size = n_embd // self.num_sa_heads # this proportion is needed in case you are using multiple attention blocks so to keep proper dimensions, otherwhise you can set head_size to anything you want\n","\n","        #self.multiheadattention = MultiHeadedAttention(n_embd=n_embd, context_size=context_size, n_heads=self.num_sa_heads, head_size=self.sa_head_size)\n","        #self.ffwrd = FeedForward(in_features=self.num_sa_heads*self.sa_head_size) # going to take in BxTx (sa_head_size * num_sa_heads) --> going to output the same shape\n","        #self.sa_head = Head(n_embd=64, head_size=64, context_size=self.context_size)\n","\n","        # /////////////////\n","        \n","        self.attention_blocks = nn.Sequential(\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd), # takes in BxTxC, calculate logits of BxTx (num_heads * head_size), then project it as BxTxC\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            Block(n_heads=num_sa_heads, head_size=sa_head_size, context_size=self.context_size, n_embd=self.n_embd),\n","            nn.LayerNorm(n_embd) # normalize the layers\n","        )\n","        \n","\n","        self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # (B, T, vocab_size)\n","        \n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        B, T = x.shape # batch_size and context_size\n","        positions = torch.arange(start=0, end=T, step=1)\n","        \n","        pos_emb = self.positional_embedding_table(positions) # T x C --> in broadcasting, pytorch adds a batch dim=1\n","        token_emb = self.token_embedding_table(x) # B x T x C\n","        \n","        x = token_emb + pos_emb # BxTxC\n","        \n","        # /// Some previous modifications for testing purposes ///\n","        \n","        #x = self.lm_head(x) # BxTxVocab_size\n","        #x = self.act_fn(self.linear1(x)) # BxTxVocab_size\n","        #x = self.linear2(x) # BxTxVocab_size\n","        \n","        #x = self.multiheadattention(x) # BxTx (sa_head_size*num_sa_heads)\n","        #x = self.ffwrd(x)\n","        #self_attention = self.sa_head(x) # BxTxHead_size (BxTxC in this case, since head_size=n_embd)\n","        \n","        # /////////////////\n","\n","        x = self.attention_blocks(x) # returns logits of shape BxTx (self.sa_head_size * self.num_sa_heads) projected to BxTxC\n","\n","        x = self.lm_head(x) # BxTxvocab_size --> BxTxHead_size @ BxTxVocab_size return BxTxVocab_size\n","\n","        return x.view(B*T, self.vocab_size) # easier shape to work with the labels\n","    \n","    def generate(self, starting_idx: torch.Tensor, max_length: int, debug: bool) -> torch.Tensor:\n","        full_text = decode([starting_idx.item()])\n","        context = starting_idx\n","        \n","        for _ in range(max_length):\n","            context = context[:, -self.context_size:] # make sure the context is of size context_size\n","            \n","            if debug:\n","                print(f\"predicting on context: {decode(context[0].tolist())}\")\n","            \n","            logits = self(context) # B*T x vocab_size --> 1*2 x vocab_size\n","            logits = logits[-1, :].view(1, self.vocab_size) # only take the prediction for the last character\n","            percents = torch.softmax(logits, dim=1) # 1*2xvocab_size\n","            pred = torch.multinomial(percents, num_samples=1) \n","            full_text += decode(pred.tolist()[0])\n","            \n","            #print(len(padded[0]))\n","            context = torch.cat([context, pred], dim=1) # add to the context dimension instead of the batch dim\n","            \n","        return full_text\n"]},{"cell_type":"markdown","id":"bf5e12b7","metadata":{"papermill":{"duration":0.022803,"end_time":"2024-07-10T21:19:27.995266","exception":false,"start_time":"2024-07-10T21:19:27.972463","status":"completed"},"tags":[]},"source":["# Define the final model and its hyperparameters"]},{"cell_type":"code","execution_count":47,"id":"2e55dbf7","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:28.04387Z","iopub.status.busy":"2024-07-10T21:19:28.043603Z","iopub.status.idle":"2024-07-10T21:19:28.090886Z","shell.execute_reply":"2024-07-10T21:19:28.090021Z"},"papermill":{"duration":0.074486,"end_time":"2024-07-10T21:19:28.092809","exception":false,"start_time":"2024-07-10T21:19:28.018323","status":"completed"},"tags":[]},"outputs":[],"source":["n_embd = 1024\n","vocab_size = len(vocab)\n","context_size = 128 # same as previously set\n","num_sa_heads = 16\n","sa_head_size = 64\n","\n","decoder = Decoder(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size, num_sa_heads=num_sa_heads, sa_head_size=sa_head_size)\n","optimizer = torch.optim.Adam(params=decoder.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","id":"0abacb01","metadata":{"papermill":{"duration":0.023363,"end_time":"2024-07-10T21:19:28.139537","exception":false,"start_time":"2024-07-10T21:19:28.116174","status":"completed"},"tags":[]},"source":["# Model text generator class"]},{"cell_type":"code","execution_count":48,"id":"1798f402","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:28.187043Z","iopub.status.busy":"2024-07-10T21:19:28.186779Z","iopub.status.idle":"2024-07-10T21:19:28.199025Z","shell.execute_reply":"2024-07-10T21:19:28.19786Z"},"papermill":{"duration":0.03827,"end_time":"2024-07-10T21:19:28.200881","exception":false,"start_time":"2024-07-10T21:19:28.162611","status":"completed"},"tags":[]},"outputs":[],"source":["class model_generator:\n","    def __init__(self, model: object, max_length: int, num_samples: int, vocab_size: int):\n","        self.model = model\n","        self.max_length = max_length\n","        self.num_samples = num_samples\n","        self.vocab_size = vocab_size\n","        \n","        self.last_output = \"\"\n","        \n","        self.params_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples,\n","            \"previous_outputs\": []\n","        }\n","    \n","    @torch.no_grad\n","    def generate(self, starting_char: str = None, clear_outputs: bool = True, debug: bool = False):\n","        self.model.eval()\n","        \n","        if clear_outputs:\n","            self.clear_ouptuts()\n","            \n","        if starting_char is None:\n","            starting_char = decode([torch.randint(0, vocab_size, (1,)).item()])\n","            \n","        for _ in range(self.num_samples):\n","            starting_idx = torch.tensor(encode(starting_char), dtype=torch.long).view(1, 1)\n","            output = self.model.generate(starting_idx=starting_idx, max_length=self.max_length, debug=debug)\n","            self.params_dict[\"previous_outputs\"].append(output)\n","            self.last_output = output\n","    \n","    def update_params(self, model: object = None, max_length: int = None, num_samples: int = None, clear_outputs: bool = None):\n","        if clear_outputs:\n","            self.clear_outputs()\n","            \n","        updated_dict = {\n","            \"model\": model,\n","            \"max_length\": max_length,\n","            \"num_samples\": num_samples\n","        }\n","        \n","        for attribute, value in updated_dict.items():\n","            if value is not None:\n","                self.params_dict[attribute] = value\n","                setattr(self, attribute, value)\n","    \n","    def clear_ouptuts(self):\n","        self.params_dict[\"previous_outputs\"] = []\n","        self.last_output = \"\"\n","        \n","    def print_outputs(self, last: bool = None):\n","        if last:\n","            print(self.last_output)\n","        else:\n","            for output in self.params_dict[\"previous_outputs\"]:\n","                print(f\"{output}\\n\\n\")"]},{"cell_type":"code","execution_count":49,"id":"807c42f0","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:28.251655Z","iopub.status.busy":"2024-07-10T21:19:28.251267Z","iopub.status.idle":"2024-07-10T21:19:28.255621Z","shell.execute_reply":"2024-07-10T21:19:28.254708Z"},"papermill":{"duration":0.032408,"end_time":"2024-07-10T21:19:28.257709","exception":false,"start_time":"2024-07-10T21:19:28.225301","status":"completed"},"tags":[]},"outputs":[],"source":["decoder_generator = model_generator(model=decoder, max_length=32, num_samples=1, vocab_size=vocab_size)"]},{"cell_type":"code","execution_count":50,"id":"4959a121","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:28.309609Z","iopub.status.busy":"2024-07-10T21:19:28.309323Z","iopub.status.idle":"2024-07-10T21:19:30.454358Z","shell.execute_reply":"2024-07-10T21:19:30.453331Z"},"papermill":{"duration":2.173112,"end_time":"2024-07-10T21:19:30.45652","exception":false,"start_time":"2024-07-10T21:19:28.283408","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["F JUTYBF;':wlnlw$kGUCsHyy-kKOGKvhnIyFXpeoQsdL;\n","&yCjHHOV?AajdQY-Y?;xQgveRRP\n","'frhPFlwDvqbzI!Fq!DBk::LTz\n","\n","\n"]}],"source":["decoder_generator.update_params(max_length=100, num_samples=1)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"markdown","id":"45dcaa55","metadata":{"papermill":{"duration":0.02297,"end_time":"2024-07-10T21:19:30.507146","exception":false,"start_time":"2024-07-10T21:19:30.484176","status":"completed"},"tags":[]},"source":["# Training loop\n","- Note --> this model is not using any dropout layers, thus there is going to be overfitting"]},{"cell_type":"code","execution_count":51,"id":"785146e7","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:30.556061Z","iopub.status.busy":"2024-07-10T21:19:30.555753Z","iopub.status.idle":"2024-07-10T21:19:30.562338Z","shell.execute_reply":"2024-07-10T21:19:30.561483Z"},"papermill":{"duration":0.032841,"end_time":"2024-07-10T21:19:30.564115","exception":false,"start_time":"2024-07-10T21:19:30.531274","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(model, dataloader, loss_fn, optimizer, epochs):\n","    model.train()\n","    \n","    for epoch in range(epochs):\n","        for batch, (X, y) in tqdm(enumerate(dataloader)):\n","            logits = model(X) # shape of B*T x vocab_size\n","            labels = y.view(-1) # shape of B*T --> each character has it's own prediction\n","            loss = loss_fn(logits, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            if batch % 100 == 0:\n","                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")"]},{"cell_type":"code","execution_count":52,"id":"33fa9f9e","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:19:30.612396Z","iopub.status.busy":"2024-07-10T21:19:30.612143Z","iopub.status.idle":"2024-07-10T21:42:15.605825Z","shell.execute_reply":"2024-07-10T21:42:15.604521Z"},"papermill":{"duration":1365.020275,"end_time":"2024-07-10T21:42:15.607887","exception":false,"start_time":"2024-07-10T21:19:30.587612","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:00,  2.86it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 4.335644245147705 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:29,  3.32it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.525604486465454 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:00,  3.18it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 2.4626641273498535 at epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:01,  3.34it/s]\n","1it [00:00,  3.18it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 2.4262943267822266 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:32,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 2.1621334552764893 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.9090383052825928 at epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  3.00it/s]\n","1it [00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.9108017683029175 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.8107575178146362 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.663124442100525 at epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  3.00it/s]\n","1it [00:00,  2.90it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.677341341972351 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:34,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.6587157249450684 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.5699682235717773 at epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.574483036994934 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.564962387084961 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.504082202911377 at epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4994834661483765 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:34,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.503920555114746 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.4501631259918213 at epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.4469995498657227 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4591846466064453 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.414280891418457 at epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  3.00it/s]\n","1it [00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.412670612335205 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.4113860130310059 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.38746976852417 at epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3681691884994507 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.3768370151519775 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3457719087600708 at epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.3255358934402466 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:34,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.334720253944397 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.3064805269241333 at epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2960284948349 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:34,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.298583745956421 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2653659582138062 at epoch 10\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.93it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.2502861022949219 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:34,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.2722318172454834 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.2239904403686523 at epoch 11\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.98it/s]\n","1it [00:00,  2.91it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.1961712837219238 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.220923662185669 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.19638192653656 at epoch 12\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.143993616104126 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1777873039245605 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.1664202213287354 at epoch 13\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.1075537204742432 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.1179004907608032 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.113943338394165 at epoch 14\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.050620675086975 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.0504333972930908 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.95it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.058074951171875 at epoch 15\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  3.00it/s]\n","1it [00:00,  3.06it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 1.0109940767288208 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 1.019134521484375 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 1.0005109310150146 at epoch 16\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  2.92it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.9543896913528442 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.9402701258659363 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.98it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8948304057121277 at epoch 17\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  2.99it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.9140760898590088 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.8990307450294495 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.96it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.8072279095649719 at epoch 18\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n","1it [00:00,  3.01it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 0 --> 0.8272302746772766 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["101it [00:33,  2.94it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 100 --> 0.8277518153190613 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["201it [01:07,  2.97it/s]"]},{"name":"stdout","output_type":"stream","text":["loss for batch 200 --> 0.7959966659545898 at epoch 19\n"]},{"name":"stderr","output_type":"stream","text":["205it [01:08,  2.99it/s]\n"]}],"source":["train_model(model=decoder, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=20)"]},{"cell_type":"markdown","id":"e4cfff30","metadata":{"papermill":{"duration":0.425639,"end_time":"2024-07-10T21:42:16.403247","exception":false,"start_time":"2024-07-10T21:42:15.977608","status":"completed"},"tags":[]},"source":["# Sample from the model"]},{"cell_type":"code","execution_count":53,"id":"d4c308fc","metadata":{"execution":{"iopub.execute_input":"2024-07-10T21:42:17.14444Z","iopub.status.busy":"2024-07-10T21:42:17.143698Z","iopub.status.idle":"2024-07-10T21:59:04.724801Z","shell.execute_reply":"2024-07-10T21:59:04.723875Z"},"papermill":{"duration":1008.302407,"end_time":"2024-07-10T21:59:05.091613","exception":false,"start_time":"2024-07-10T21:42:16.789206","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["generating 5 samples of 10000 characters each\n","Pt's to gether forth our tell all the grand thee,\n","I' is usurpose, lay good and a holy father's\n","The Came them my coung straitor woman's.\n","To take them to me, in no far my invuat: for my lord,\n","And smillo age that rant to long me him,\n","But I mistance give men an mentail,\n","That I am man, everlain the beet that past an the gow.\n","\n","LUCIO:\n","In that go swant at thee. is take no more gown,\n","Be-mine all me hear action feast of beat to the\n","I sent tell th a king time man, good make lease,\n","That I may shall beee in limbs nir per him.\n","A bollade think woman, sught to doo.\n","Come, eman poor hear me to your general.\n","\n","ANTONIO:\n","That's take heair; a visit no of grim,\n","in--\n","Taith, serving no more two and not, my ears.\n","\n","DUKE VINCENTIO:\n","I do ear again, I dare night now stan.\n","\n","MENTAGUE:\n","I must madam, I am not ame with make .\n","\n","KATHARI make my kim, leave I may name,\n","That though an I do foll thy seized\n","And braze my seming live, old man,\n","I dark't remember me with me to my man.\n","Now, take King Rigood read for my besome ords;\n","And, hath se wing more my mother up,\n","Against thou may rage windering wing awWing'st  ever\n","else? why thee is such ur with bow'st some alone.\n","Thy mambitimes, thou art with a is dam,\n","That we father live, as limm?\n","\n","BUCKINGHAM:\n","One sue chance with ther, coulor,\n","I'll may come, ever feel of it loyalty as money,\n","Coriolandam, old back my with man he you house,\n","To part no make pretty ears of no miname!\n","Would but ith knowing liberth and to take, hear,\n","Awave me the good of suntain rathed he me;\n","I rail not again am I go my may not sheom.\n","Thurt by the effect my him.\n","To be utterrid what's painting: an The stant to  fill the king.\n","\n","MIRANDA:\n","Gethe had earth them ar me care to my so;.\n","My horse ord, hands eater no more foul beat,\n","Their was in come by their my son, each.\n","The tser lost o'e alone mon-tight root.\n","\n","MARCIUS:\n","Thou balt well; men name down rather so;\n","I crame that is no mon\n","This grave of cear dean awmentainmure un.\n","Thou shalt, that done some of so rough at.\n","\n","ANTON:\n","I maam, take lominour'd your hughter spair.\n","Defor man, see home!\n","Why do age sillow'st on a mine great in your\n","Is a grant go do, be got a doubt, and little does\n","To last, thus partent an bear, the sta good\n","To bale path most country, and to could not go om;\n","But with though beet meet sm one doth,\n","To call men more premeither way a pier malice.\n","\n","LEONTES:\n","Ah, and monant, sir.\n","\n","ISABELLA:\n","He, as night noble all and to man of me!\n","To stainmutinous by war, their to come\n","To ear, you shall beet be som your dam.\n","\n","JULIET:\n","One durest mark in the miram, of my nare.\n","Shall stan't lor, and best of love--\n","Almst marrin order-meant-mour'd wound;\n","And along forth man nooth one of our admine dam.\n","\n","First Want do not set\n","Where you gave wer wash all best the mettime,\n","Were not can to speak again, to both nate, Signious,\n","On po faminating els disdiintures and suck,\n","And will what thou dant compast men.\n","\n","GLOUCESTER:\n","I dare will Thou do.\n","\n","VINA:\n","The go along, crowns to mark the fore and do be ear.\n","\n","LADY you, faint fortune worn my vouch fare.\n","\n","LADY ANNE:\n","To lost worship I may not sent to what.\n","\n","KING LET:\n","To more, well men noble to hand; say ty ans earts me other;\n","Lest mo e to e mine unto about on me.\n","Thy sew home, he come stame do love, my lord,\n","I'll rise wis all night go anmen.\n","To one of this summere trobstitting book.\n","\n","MARA:\n","That why lords, Catizen:\n","No, he man, 'tis a m what kill now.\n","\n","PROSP:\n","You fon's dam, haugh, a well my lord.\n","\n","JULIET:\n","One more, my trangled, what's haze screet,\n","And were alm I would being I am nant, read\n","That damnuth, go make doubto blood would,\n","Were a that heaven as wilt to make form.\n","\n","ANGELO:\n","Well, wast on GaELO:\n","I do boat ble me, lo mark o' love,\n","To all me sit on I stale fried I be prove and ta-not I may. all the not a me!\n","To force pow, to all not love often died;\n","Not for arm heod, could not go we our to about ,\n","Wiltil men do go bless doth eve strike and unforce.\n","\n","LUCIO:\n","With wise me to a man, from a stars, I may not fair his ement,\n","I yake what pink you an time out himself,\n","Or heir come, shall be not be for's death.\n","\n","GUEY:\n","I speak you are live your great come good,\n","'eap, herein, a rish criminature not, best,\n","That's some amh, sirral. what's take't,\n","And we will make I kill win th make  marve to me?\n","In the wor otest low to his blood, do.\n","\n","CLARENCA:\n","No do's made away be efellow, some which else.\n","\n","ANGELO:\n","Long a will man, what as nings in home and him?\n","\n","CLARENCE:\n","To man elst madam.\n","\n","LEONmost une worship I pray about away?\n","\n","First Murderer:\n","Then, at hand no move I though now o'e;' not do reen,\n","Thus ear his worn.\n","\n","Lo, how madam, no full your daughter.\n","Fear well.\n","Mething wight way to-morrow:\n","Say is Rathee, I am as y 'em. I do know  would not:\n","Away, as I shall not be obeywarm too trought an I may be not,\n","Because no more  eaust reap, eith un, to along wouls\n","To and quire. name your ever adminal, like down.\n","\n","CLAUDIO:\n","I do doubt, to the matter to fine my dure\n","Take minst lost, this on whint comest on.\n","\n","DUKE VINCENTIO:\n","Then weop I a love of go man, sweet down;\n","I will will  never ur trim your hands,\n","That ever was Loued: if the disgratiding me.\n","But what's mine to meetable, and in play might,\n","Would not beli th hath such part ken. is the see\n","To make eraolelogg'es crown, do, bision,\n","As you may bear, early and till wants banish;\n","And that, a larum an, that meet it fameey\n","And wake a m means of your faint our un; whose ear, they\n","point. an the is take for our aim our,\n","Agatedious bookind, to be supper seals the beet,\n","Woo raze ell am on an out a mean to servition,\n","Though the meous and out at'st in do bless,\n","On last, when away the dignifi, a circle.\n","\n","CORIOLA:\n","To see's look! us tere worn outs resperate ne,\n","Against on their very widow'st to mean.\n","\n","MIRANDA:\n","I mean my imple till sand unfithter.\n","\n","MENENIUS:\n","On the woman, beconst them, were I\n","Flame with make well unbint would not beat!\n","Thy stand the voice rish some himself to beat,\n","To make lo thouse I may name good him,\n","And wilt of his fair adule in this elove.\n","Ceause bentlemen; alast, and not forgot\n","Women eave your turn aim'd, that's words.\n","\n","ESCALUS:\n","Look you see you, pray is remore such radem-meanstrong you lo more he;\n","That, 's mine your may bier, on ear, nor there 'imselves.\n","\n","Romeo murs will pe I may natu dance I go come,\n","Would be war, be sworn, foath same poor mon.\n","\n","CORIOLA:\n","Well, man, did ene to man.\n","Shall the trember marriel, and to ower?\n","One of the sequers mine I may. I do, what\n","What doth such lost may daughter beming\n","To raze you, \n","Me stange gown, and the where shall pake but a to mine\n","I mista king ear, how best in soom of oth,\n","Thy bosom our messer of bain a mong for\n","Which east I never dream one bones.\n","\n","MENeUS:\n","Blast be one, hur; there him is good, come\n","To fair else cattenter's man, and till smore.\n","Then, what mule heough I  avoid oft ours,\n","My hust hand, not me with a come on, hat\n","Thouse decay of contant to my journ; for ILoee,\n","Ramp'd with Bolingbroke. to drham, though\n","I will disstars-in a mothtonour, ver limbs,\n","Be she well,--\n","\n","Down, leth lost contage mies contation\n","you do your aim on ear of you have as pered;\n","Therefore aften your king on and men\n","To summen of no monare fore mine his be see\n","And bering with st heaven. Yea, as I cannot see\n","That's here surring mem me death mour,\n","On away awe page th same were pastil the graster.\n","\n","LEONTES:\n","My east littles fall dotn mime seem foot;\n","But lord, when after thus shall be som.\n","\n","ELBOW:\n","I do fear slain him to better tean,\n","And else I do find 'tw that rest foeing I\n","have sta gree heard been in speak; my twould say, ted pread,\n","And claim a tre very past home threats,\n","To be himsel fominate great--worrupting all ant,\n","And yet the vaticn of king ent-st summ'd eye,\n","And crance with postituat heart parelling my hust,\n","To make s o'er we rest bare. were eavy 'Tis him well.\n","I'll not some no long. me'll not forgot.\n","You lords, amonight, no a man.\n","Now, shall have you ma good, wrath ove in now.\n","\n","CLARENCA:\n","In one them all my man.\n","\n","First Murderer:\n","Ther wish this deaven, let me from me. do the doth land.\n","\n","FRIAR neot to me oman, Juliet, so make not be sta Mo.\n","\n","LARTIUS:\n","Win him farsword, my heart; it him train\n","To-morrow in a to died. Nay home, a her's late.\n","\n","MENAULIA:\n","Prithee, falsh, come, a good him.\n","\n","Even whose will passing men him appresent quiet. I come.\n","Come, with the good two thou hast woman,\n","Worth sught meel'st tarr'd, lay mine man.\n"," om-not what disprepent men; inqueturn.\n","By them be remember.\n","\n","AUFINIUS:\n","I though I rest: to thou shall my re,\n","In re may hear, to men\n","To lot murdered king yourse, straight effeeling foot.\n","\n","PETRUCHIO:\n","Let'st be a. Go men palen of you; alaw, thou hadst by oath:\n","I do answear abiles of the doubth a hoasen.\n","Feath not your ragisn me;\n","He's comman no more hear else the crown,\n","That which frant to say you, but it, and we,\n","I'll rest unlay widling dight: and ki m'd him\n","And crave fee death quie math thouse dooms,\n","And may come sper, a ling all nive the wing\n","Firline to fight an st thou art we,\n","And pounate you give untain you. a there a more,\n","what so eaven, window by some Preteut Corioli hnous\n","To pardon my a lord saring hose grand you lunn,\n","That I may go a mine of line not, my rate need,\n","To umberland brance I die. I urtly,\n","I go my grant our in suppowerl, in him.\n","\n","LEONTES:\n","The of part, love i dram money pare times,\n","And range of battle one mine own;\n","His died on linen cleaning and heed\n","But best men uncontrnatives made duty dant, be so fare root\n","Them trumpets untainmurse of fight meet\n","ey part in thmenta company in frivate poor's parting parture;\n","One out not were Master ram, you so'er a man.\n","O Rome, be not some meo. Now, some will\n","England, will are grand our dibing the doorth,\n","\n","Senators nature in the city, on, be drumpession,\n","Nouble mine she's my fanctuat my can, away.\n","\n","KING LEWIS XI:\n","Well su, peace, and Norther heove a prehent be?\n","I do at pardona cre.\n","My again, the blood lamen.\n","\n","CORIOLANUS:\n","We knows the summen are night at comes.\n","\n","First Go doth hear:\n","Then heaven, came this fair war, strike\n","The summer of with a to too common;\n","But simine ope cer strangle dal, fall ing on.\n","\n","GREY:\n","Near, stand to make your ilm, and then?\n","\n","ELBOW:\n","O what go's away a him \n","\n","\n","PTISTA:\n","Plove I like a meats am mam.\n","How come humber them his face I lost years of\n","To being kind, but am one what to may ears,\n","And yet reak no  not be gown, being eye I may.\n","\n","DUKE VINCA:\n","I come thee what some do meal swornt so great.\n","\n","RICHARD III:\n","Say a hal, what he sake with sow look not hame.\n","The same, wert some hear,\n","Wise is his by the night beats ent let wone:\n","How may a ming, on my bland be,\n","My hast by warm o'er of the would have els slaugueets,\n","But sin stand hot, to dear leave deed ear, a dalightey villain,\n","The other daughter traughter, and I beet not myself not,\n","Houth and me for lip, to be with anoth:\n","To lave the gland, Alark, the know implease by nature.\n","\n","KING LEWIS XI:\n","Thy seven would banish'd and bility rate es,\n","And wated him appear, that least day man.\n","Think to the sead men may lest patient forms. and all be int-me;\n","My heaven, Amontague, and therein servethee\n","Worch wast Rome me grow mone. \n","Carence on limb'd at the dign house!\n","Take wilt away rant,--bre in what out,\n","With sisting to rough cr forth make words,\n","Who look'd with a un thin a ch from these ecountry,\n","That hambe.\n","\n","MENENIUS:\n","Weight stange I honours a go at no moon,\n","Which I am as aggentleman, and to my body'glife,\n","To make is time me meet, be not not wilt o'er.\n","\n","LUCIO:\n","I see moom as master. let me, to beat your climb.\n","\n","DUKE VINCENTIO:\n","Be is night do follow, off wilt ourself,\n","Ere I  it little wait on priois of an you bear,\n","The hath east on beath hath such fawentreap,\n","An table stain'd, my teemine own,\n","And I doubt each you loast yiel, Patience, most\n","That will st be apt your mame wer basts.\n","\n","LADY ANNE:\n","Ay, be doth side stand you wert the doth mode\n","To eave fletter no to do men.\n","\n","PROSPERO:\n","Thouse day right.\n","\n","LEONTES:\n","In they arm wer say windeed some and be speeature.\n","\n","CLARENCE:\n","A mio's hant well.\n","\n","GONY:\n","I must no more, obplease this more preat.\n","\n","ANTONIO:\n","The set not be ears hand that king's preat cious\n","To alorious all mb times of that, lately where I die.\n","\n","PAULINA:\n","I may, night; he stands the I in my a me,\n","For heavy more man!\n","I damnes do meeim my hand: come, knever:\n","That's come Catesbyam's great-shall night\n","To do eath-man; eaven him to do more mistre.\n","\n","MENYURY:\n","Nurst have tran, stay we would not forth man.\n","\n","LADY ANNE:\n","I do meet lord, in lawful ring to-night\n","To razed an the such a tiest dangelo with hands.\n","Thy sea, a d-how crimillower bawd,\n","Will, thou hadst bear-with and ene I do make dram,\n","And lamb, no what a gration made down,\n","And wake, till enmity obey ouble matter:\n","The same crave thousand flower I do bow\n","Whosed in a love you aft. all ss y ye is past,\n","So fay a do me outh bount no full smong,\n","And need yet histing person. in the down,\n","Eremonious could hath one most part his eyes\n","From when se lore away behing first: by thee\n","Which shall beet ever want he skirl'd wing,\n","I would anmen a month would have wick to him.\n","Be hat need they attenant, fane I do move\n","To mave you of friend amber unm, where the world come\n","To alove him ere mine I have and blows: there I may am you that\n","The doing go would be hat sleep him.\n","\n","PAULINA:\n","O death, go bastard, and fanhal, I take, I am you\n","k not only not were partinute service by lone\n","To ear, for him at only rage you doibs fair.\n","\n","CLAURIOLANUS:\n","Wise I mean to met on, go pardons or bame,\n","Blate man, to daughters may comest,\n","Before with and one them back in thmen.\n","\n","KING LEWIS XI:\n","Why, see more I am amam, Kate ere Vate of domn,\n","And embrace to come,\n","That eat, to make I may mean toimate our Edwarm'd,\n","To man, to mine care glove to matter smiles,\n","The traitor to me truct mon dent to the bleet. in this my woves;\n","Who is ear st unlook'd pound stant, because,\n","Wise were I shall with pan, thou come King Henry,\n","For teath the mine east would ranks.\n","Ohe ming liken, foe, and eless King to thee,\n","Betrim in his mine eat, tir bettlemen. What, would and me!\n","Shall bent remember him the house obedience my words.\n","\n","KING LEWIS Edward hath Wake som I mistake thee?\n","\n","FLORIZEL:\n","Nay, be come to a king and love.\n","\n","BUCKI\n","\n","POLIXENTIO:\n","I'll not pretty mouth, no? O thou, Lart--\n","\n","SLE OF AUMERSeUp I aga; as heaven, I'll sworth one\n","I may no bolla;e comes thou not, and bear me.\n","\n","WARWICK:\n","I do beat a means an I do no part not go before:\n","My you what stan out-play in i' the is mother;\n","3\n","Though I will I not let mean the werl mount beet,\n","I have my obey do mine own, be but unly hast reap,\n","In ne otation to give your him sa landur.\n","\n","MENAULIET:\n","A membeat-heard, and reap, and I am, need\n","To make your him an to save no do for pacise, wrough\n","Fasting unfil my partan im, do what mine own,\n","In so warrin of the best bear it me. \n","First Murderer:\n","As mine you shall better man, wine foes\n","To love you; but I have of amazed, in late,\n","Even woo ear to the lost, will comman.\n","\n","ISABELLA:\n","Ay, as  ave madar, and me you bo boats will,\n","That were ever trimes of for being disdom.\n","\n","ROMEO:\n","Though dest passion you forth sweet lose,\n","Were I do m-man, peaced man. a king I would will\n","Flatten time, come, we won; and men leave me\n","I, with make wistill death, were elded there!\n","Would be go won! beat Come, bao? \n","Is than out beat please ere is till beat,\n","Till think home in at on emperate commend way,\n","In at whith rawn will what I may not, foes\n","That cozing till ghat heat be I happy to bears,\n","Being smiling to the dies quit not in rous,\n","Inlove sit on thee will dok'd with hateful,\n","The ble me disgrant me obey man, my grace I do more.\n","\n","KING RICHARD III:\n","To take ly man, my mother.\n","\n","CLARENCE:\n","Woe death oft eart, hast thou liest no mone eo?\n","\n","WARWICK:\n","And bottle; and Wast do force be done,\n","And eportant fire ear. A dozed mark again,\n","A bemeans do mark wist.\n","\n","PRIttan voice rance no stol, would ear;\n","England, with ne is not on that I though dagge\n","To parketh man, ear my meet move ut preparting Hent, loyal down, and brance!\n","But by, lord; men alone?\n","\n","Messerve I shall not not trough an we,\n","Thy take a thee down, lords. Do't be land.\n","I eavy, so boline an man.\n","\n","First Murderer:\n","The stander way ber.\n","\n","MARCIUS:\n","Thee same good was to make serish ap, ne ey talk you good,\n","As he mistremain ne'er made but in daughters;\n","And with yet bumts, behind, fair to remory,\n","That alah, see you face betal, where is book.\n","\n","PRINCE:\n","Fear not pray un a men. Themaid your good appear,\n","Till to see lost; and strangelo loing on whose.\n","But, hath raight on bear him tre my him.\n","\n","CLAUDIO:\n","Love my naughter, go man of limpinatical,\n","On. m'e more that by that finge orance.\n","There wing some o' money down,\n","Let me meams Aufidiughters, take s you may\n","Win he have I will make wer humour bots,\n","To please down, be come singly with the\n","To late our of their brief to the war,\n","For on't, after man, tight when such art,\n","To man aughter els and hour born ridal poor good;\n","Death make of which e'er again to you,\n","No doth make daughter care dream man, man.\n","\n","KING RICHARD II:\n","Alast smellow; so men, I doubt not money.\n","\n","KING LEWIS XI:\n","\n","QUEENTY VINCENTIO:\n","Fie Tring man, you liest like some me well.\n","To tampean him on!\n","Thou wor'st that hour mest me.\n","\n","TRANIO:\n","Sir, I do what son a\n","man of such mo bett of some nit my man.\n","\n","LARTIUS:\n","The Clown:\n","I do mone good swain?\n","\n","PRINA:\n","No more hear my impay, prove me hand; and for Rome,\n","Not best heavs, wilt ut both swaint loust:\n","Your we murdere of about that wings of these be stars:\n","Then ab your gare would heaven me.\n","Go, you fortune, and Romeo man, go where seals;\n","Who says would not made not, so the all never heard ed,\n","To ano soldier more of you love deto lose.\n","\n","Clown:\n","Prithee, be boatsweet, brave and in dom.\n","\n","MENTAGUE:\n","Thy a sensel both, and save I stay,\n","Where is my pray in a mine a millow.\n","\n","WARWICK:\n","Well, what I bear me stand give the att?\n","Thest rought no money I am ame no thee!\n","My minu mean the gaom wembrave doubted with a pedertainme.\n","We'll on limurder'd in men be mined Plous!\n","\n","PAULINA:\n","I have sail, and else,\n","To what master of the right now man\n","'er hame be monst foolis' day agle an Emoo the\n","children and the dlaw, what make her, and sleep, neme well else?\n","There were obedience of one earth of ever?\n","\n","ELBOW:\n","Ay, and wilt thou a stands on ax some or man.\n","Be elo the realm to save no lave see, and weep to meet,\n","To aman, you not sweet pity me someth,\n","So lord, will a constant by love, for we your fair old and und not go;es\n","Who as to sull man, have limble with hath,\n","\n","I may you never blood, strike me seem and grief:\n","Finst amaze you sper of mo minature,\n","I'll kis him awaken. o' the dust thou young home:\n","I'll go balm on may be pack him will, though\n","Her shious realm no move wrong most the beet,\n","On repeep in the good conful not stand-hant,\n","Be hath row were is death far where!\n","Thou a pale me hast good take bareth and with thee;\n","To foul beat queen, stand down, outh, and all I.\n","\n","CORIOLANUS:\n","God see, I make pomp, could hants to the foe\n","Mniey tamong an the book an away, trhang to warm!\n","Thou a m'd with motthis dangle will I may doubted\n","To man, sen more by tyranny Momb than\n","Your a met moon to man of bosn in the stard,\n","You make i' foling man,--\n","As minht doth all, becaul'st will men.\n","\n","LADY ANNE:\n","I do do's I do be rother; sfalt go with I do fought,\n","To loath, both ou hear else, father'd him\n","where are upon thy fair your hand one now,\n","That does to the being limit of banishment, will,\n","I do fool, but not contr-kin it, with theat,\n","To long all my darge our aughter hand:\n","There, art meet meet let me ey name live.\n","\n","CLAUDIO:\n","And fear upon\n","Wie come two ker's ul an him sparks; there I am too take ,\n","Serabim him man. O'e aniwult heart work.\n","\n","ELWAI :\n","Alast, 'tis he is come not, how o'erful,\n","It have lame no mortake ell entare your un,\n","That's parling Penant, not unlord, sir.\n","\n","PARIS:\n","The truch mouth' and eparling credit up;\n","To love you hoar, sir.\n","\n","ISABELLA:\n","Well, hear I am one.\n","\n","PARIS:\n","Women pardon, Edward, leave I never speak.\n","\n","QUEEN ELIZABETH:\n","To make this worn till not for aumen\n","To make : you reap, I love pale would and him.\n","Against die Comin swound not with the ever a woman.\n","\n","KING LEWIS Edward what he some right a man\n","To found no mome with thouse ear where take s:\n","You have well me home, my member memselves. Therefore I say.\n","\n","KING LEWIS XI:\n","O Romeo, look d un!\n","\n","TRANIO:\n","Fortune fome, prity, make s! master.\n","\n","CLARENCE:\n","I \n","\n","\n","PETRUCHIO:\n","Arm, such you and do hoar men; you fortune formitate and sir?\n","She arm with with, and aught vening forth a worth a come,\n","That die is me of ! reth alow it one some\n","That bosom of aught with his brother;\n","Well I have lead, they sworn too home means,\n","To let at from my sweet so bone hath down,\n","And I would will be parliamen. We have you rogue!\n","\n","WARWICK:\n","Alas, be strange! a poison, I must do\n","pray as a ceffer mast, and gaate my would be.\n","\n","JULIET:\n","I do moon, I am nant, I must in me theor,\n","And be stumber me some will, and take Gloucestertake,\n","No marry of leaven obey souls me her;\n","To-more time were write exart, thou cannot woman,--a worption.\n","\n","MENTAGUE:\n","Well, what I may part so man of to the E-O\n","TRANIO:\n","This most in the wooin that so battle;\n","Against against thousand no your ear, fair I wake,\n","To man mine sent eath, going that ye with spite him.\n","\n","ISABELLA:\n","My master memore miral respirit in a mine,\n","The dost upo not to finions bobilimes,\n","In whome, comes bones mine moon, so bold combine\n","Inderough you age what wing an the wind;\n","In trustir honour, no bear your trimpiety,\n","To love your mour mour life, and death.\n","\n","Third Senator:\n","We'll then till be hath on thousand powes\n","I. Nvould hear the ear my mars look'd moon,\n","And of which cr naught stames woo old could says,\n","As have ell you rough diep--\n","To ower of wind yes dheart, wish in I may lord,\n","That how fare I may need will paint your appear, at\n","ment the ease--\n","Frid uttere will pay hunds the no to see.\n","Heaven ship an male run unforthwew,\n","And ear mave i' that a sweet lost down,\n","To make is time me emply it play nim, be't with his is regal,\n","Wilt wankin pose he eath of one may,\n","To man when a king tes to mies of men\n","May hath in do bing that with you knew,\n","And ble s crown, you have end in him part come\n","He doth  parted eim in a ming your eous,\n","befol'd and we, you sent in aming for your const,\n","Only conscient eless with in the skill'd one,\n","And I am go with se I may, teath took not one moon!\n","Thy seak that gots, muI to doubt,\n","What out meet can, sout treme,--how by ins:\n","Graze you do do mour en limbs.\n","\n","LADY you meet to the same no more traitorta men.\n","I' the orall, what do meet forgot.\n","\n","WARWICK:\n","\n","Mean the does night, with some eless, I love trate me,\n","That the dows I stay no lost amazed not.\n","\n","Second Servant:\n","We shall not elphen on them eans you.\n","\n","CLAUDIO:\n","\n","PETRUCHIO:\n","O, what stanis, I know my aughI do leave duance\n","To satill you meat, but Kate I may rant,\n","To love King Ckein, we'll end unbings traitors hate,\n","To fair a man, friendly pirit complain;\n","Prince is doing cannot, trumpets may life,\n","With all have I play thee graceed matter'd\n","To prince of man, jealine; or this cratch,\n","To banish of the reason of bast hurt, go make looks.\n","The star mother been sulland'st, not to meek for beys,\n","Ere your besilimks, leke you a min\n","The ot bears me stars himself-\n","And watwent wing and am what so strange an\n","The rights prince of such more hight bear\n","When doom sake the best man. Think, ther, thou leave come\n","To make stard not better the of suppower.\n","\n","RICHARD:\n","Ay, thouse with a sweet do bastard-him.\n","\n","CLARENCE:\n","To so, the down, dost of his high my bost;\n","I fear house live, to mine a gentleman,\n","He shall ning a cume uptial fave himselves:\n","I'll amatner or els me to come,\n","To banish of Gloucester man, take heaven,\n","That how my most villain, for bornsminate:\n","But, what I stay, ay light vo see ear,\n","And eath lord, by temple the an away\n","To faint benefi. You are not stay be not to me.\n","\n","WARWICK:\n","Alast an ollowing good, would take her;\n","And take I you do come sil.\n","Be yt thought Keep,\n","Give me lects, bering Rimeo: looks me worn.\n","\n","ISABELLA:\n","\n","I am to set be done, I am you a toices,\n","That  an that will comes of the birth't her,\n","Let me mie creportinus, and no come, sir.\n","\n","Romeo is, trumper. let me Against fit to bears;\n","Both him farewell, no mounto the sean, cut\n","it on pair of. and the cat of it to the doth book,\n","And I would no mount,--\n","\n","GREGOT:\n","The sensoe traam, heavens love st my us rang's.\n","Withzy live tituae away I no confent at\n","With but come that so mummer bettature man,\n","O'er summight noisouls ill, their my body'ge never\n","That does alreat--\n","As I been lookin that some Kite o'er man,\n","Decry doth murder's daughter limps harm,\n","Be he miles on that wings that do go, they are quite.\n","As eave you fortune, and ever deed,\n","To all the do the meet our ene no how of trather.\n","\n","Second Servant:\n","I tell the willing of the trouble on.\n","\n","Meast thouse some o'er same ellentail,\n","I make while hear the magga wherein\n","To make is trant to ful ling to men\n","Sit-trumperetty him same o'er ta'e,\n","To lawe entartars you eavy of not come,\n","They ser leads him go that I do a mine.\n","Wise me count power ! he sea m me a means.\n","I would not be man. Signior Grand,\n","And I did good visit to keep them in a creap,\n","And I, to make ogly uous royals bjeath,\n","And wast go battle; whose sing to men\n","To oavs me do ear man, the fire men.\n","\n","QUEELT:\n","We last man, ever: I'll find to man\n","Alove well be met on whole the dream the car, tough\n","And I won reto make with fair the king.\n","\n","ANTONIO:\n","Leave, you come o sening a wing wintent\n","Lake to beat!\n","Think you feel monious in an one werr a month,\n","Y when a that wing a woman, boyake not to your age\n","To do woo bistlime. a man, I best read,\n","I' the neave ears, in this braw, rarn,\n","And were ease count-poor beat, and yet poor wath.\n","\n","DUKE OF I aet for'st on path eazed on me:\n","Then was a thee, but land, what wert a count\n","To man, ever carved his patient complimen,\n","For all not do Curties Molanus in neigh'd with and soul,\n","The doom the gowith more, in set boen.\n","\n","MARCHIUS:\n","To matters,--\n","\n","WARWICK:\n","On of one I won ear me to come, wert come,\n","Were could not doth against upon your ellike you;\n","And to do the does will pain you wilt not\n","To eat-go long, at piled with a subjects or cried,\n","To boansw 'll parting man. I kin you, wretch;\n","When cannot shall pay mind car we have forgot;\n","\n","KING LEWIS XI:\n","The set lord, hurt to make thee to man.\n","\n","KING LEWIS XI:\n","Thy set must man, my man,\n","Thou art wilt banish'd foule and man.\n","To take the man, do do, ake him an their\n","Iscontation.\n","My bookigage I; urgo withis ut my have sire;\n","Who our of two murdere bimthe gravemen.\n","\n","MIRANDA:\n","A , as I 'd foll man.\n","\n","ANGELO:\n","\n","PETRlam, on why, death old that do lost, stantlemen.\n","\n","ISABELLA:\n","Go, a boat water liber, and wast a table.\n","\n","Pampey, hid reat end o'er against thy right,\n","Where weath hand silver made bonns men.\n","\n","CORIOLA:\n","To ear of that's said at unto make you am I go,\n","I sperance more tral.\n","\n","MENENIUS:\n","Weet me true m not further mame by them.\n","\n","PETRUCHIO:\n","Thouse is good heaven, sir, no more.\n","\n","CLARENCE:\n","The plaon, your am man.\n","\n","LUCIO:\n","The goom one us in land girl? it me, my mother.\n","\n","MERCUTIO:\n","That's one wive proud house himself, my pacr of stain\n","And blanch one brawl, and in being like.\n","\n","LADY BOLINGBROKELLO:\n","Master, let's master man.\n","There ear,--sour faith some ene core bure,\n","Would beats worn be gates, they ars to do,\n","We came on ear the gow's lands for ambest,\n","To about drintinuap an thee own, they wood\n","Whose can, to man be-be us all on any hange of the our ey,\n","Servantant in ours on where amame of ty vimutt;\n","We shall not grave ens, but meet at inveneight,\n","And then the gatest King I in twise.\n","My Lord in all resagge wherest logg'd with these your groom,\n","Ie villand doth tan leven need force in semine\n","That ever sens do me with the gowings.\n","But 'tis summemorse eye I man, uncle of limp,\n","and I ra wast up in the rim'd ear; follow,\n","Unlay, name word bounst th will desperate\n","To make with man, obey make ly the trumpet:\n","Away, and Upon eight-storm make black of liment,\n","Hath would I do a my boy, I bear my fast,\n","It key offind tate shall be jow my mountry,\n","But nevel aman. am I not ad no come\n","To bear and the one owning wing in to me,\n","To ano more of my nature entail stand force; go, ytaither.\n","Their no pierce move him all undatars implain,\n","Where summ'st, and is do roo messerves me to come.\n","By this love, I'll leath more Comban\n","To man sight no bless. a child a Evel themselves ale.  flattear or of this\n","Is heard. And honou fast no smalap,\n","To maid, his quit herr; whose great\n","Confoughter tight. old not drink not purpoor,\n","And bie stard an tradutes, for man\n","Lamne-gettime while. There ea' the e--born,\n","Compassion in eagle and fellow, from man,\n","Their true friar the doth partangly pair,\n","Wis ever woman, with an away not best little.\n","Even which be to men. O'er some re now.\n","\n","VOLUMNIA:\n","Beat, gram, to man.\n","O'erth, this hange is do be old of limps,\n","To  ampeace of the state to do, wrong, stirrn,\n","To make not pagates of the distrath\n","To sleeping an amon.\n","\n","LEONTES:\n","These might lovise of an untainmure go\n","O. O be safe, as sworn\n","Take ughter! me is the fir; but that when\n","He be hath them easure death to everland, couldst o' to do.\n","Thinks, have I do give our more and well\n","And water more. A death, best on to beeefellow,\n","I mean you feath of our cime to heaven.\n","Wid he ill uns reak now man\n","y, on that we ground death, and wake death:\n","Loeu, will end, he did at little death,\n","When do would band-man! old take me now.\n","\n","JULIET:\n","Well, here's land come, lord, take lay man.\n","\n","LEONTES:\n","That orators queen, for thou dost an mine.\n","\n","LADYAULIA:\n","This mortabil time, Kate me unto ra.\n","Then one ear,--\n","That doing diver bears with the go their eight:\n","Would avant-portune eld man.\n","\n","Read mine him, so what singly, I have dow\n","Than doth no housand go limit o'er I am reap sa mon;' there\n","We have he doth moe of suit man. let he ever\n","Than ear them power. I am a dar't were east; bastart\n","you frain such quirest dight. Not swears, and I\n","Was righ the summen to wrong of there eault\n","in abust neve out in one rors, and I die.\n","\n","QUEEN ELIZABETH:\n","I am a pain that me no do ock, the horse of\n","Din-straight:\n","This a villant, and wake, hang moomeh.\n","To why to cheries contr like out on beat\n","Against his enember than absence of ene born.\n","\n","BUSHY:\n","Whot may dign of impity, my mark inm such,\n","Deparl man, escreto man, ever ble hoom.\n","\n","QUEET:\n","But not they woo room. Thuut reath is trumpet: in impeave I,\n","England, so death no do more mine eye Is may.\n","Ogo sen, to make en to s to make no try, and my means,\n","To fair of this eye eye doubt, no a deep in thee;\n","But \n","\n","\n","PTISTA:\n","No now, draw she's owing, and with in the e\n","To mer proot. Nay, my man, away, and my serve\n","nor tazen of mine howl ne'er rob mee. let the time\n","Mercuust not, be efflour in.\n","\n","KING LEWIS XI:\n","Ay, ay lie, he might have of man, of you the seals.W\n","\n","ELBOW:\n","Dneep you, like be ears he does right meet:\n","I'll think but his; but what so horset's balm,\n","And best off our take s, he suppower.\n","\n","WARWICK:\n","What what same ser evenied to man aughter:\n","The eight come and king make I may memoroun\n","To eave bann' love droppear, not for me kill'd warm.\n","\n","Second Serve I do keep the doom herise;\n","Nor say 'twere I do a kindly, Natu say, not a dam.\n","\n","KING LEWIS XI:\n","Nare of you may, by you do ble great-him,\n","To make with the resome oil-my tations,\n","Ser like you so iles,\n","Patle, let's lay and me seer take hees rest;\n","In all advine same leave of our and men.\n","\n","ISABELLA:\n","The feath some for one, a cish one wring I fear,\n","I pray mine moon, he seast away.\n","Feath farewell,\n","If should not in in sovereign sure,\n","Petaulti ut even house remove doth shall have.\n","\n","ANTONIO:\n","Take she down, to Love deen. Thou wast two more.\n","\n","LADY ANNE:\n","To love the may knees till my such battlement poor come,\n","And perate our no move a dean roop,\n","If no momaster. thou, to bear neath,\n","Comman est in to spy my mothe priels,\n","Save the trath world words to mark nigh.\n","Beaten limit now to beeal,--\n","This with Bower in the duke, be world in heaven;\n","And I bine would not, unly of they sand go atter,\n","To an they hast touth to bear an ellike encountry's,\n","Which was ming more were a pardon, make been\n","me on trary, go with we hare one, where to\n","wholesome strength quires damn'd a man.'\n","\n","CLARENCA:\n","Well, what is me commen doubt, thou stant\n","This with a dear cause thou feth eat'st mine. But his ul wret:\n","On hath and blund been ear, mark'd,\n","I' the other were reads! arb, the more home,\n","Till thought bear, their a might heest,\n","That beat our in Rome, ere me, nake see hee.\n","\n","Romeo the been you reast, hot limbs,\n","Heir full you come of you fer tean in any in 's\n","Wint not a brave no ody; long I bear a man.\n","\n","PETRUCHIO:\n","The resortune skill'd will be beat on,\n","A balm of eian part my eans, soon-ibroth's\n","are parling fit-does alave, not a medom\n","Dince o'er willing a wing sweet; as net to be s.\n","\n","LARTIUS:\n","A good disposi, and my heaven, what\n","One worth slauphin, cation oble come from\n","To call me e like me our anm tal till I\n"," is son, a day kind the world encountry't:\n","The that wilting wind undoubt, the secon\n","But per in alonive deman, ceived he foe\n","To long you me of an been, give you go wilt you least,\n","This King of nieu do best remo foman\n","Thy sights work, Kate you petiugh at keaves are: all be worn\n","'et-house done wreth dath a wind looks. \n","Poor swaet: Even such case 's partinus' dant,\n","And here wigh make s are quires al\n","I give pass cret no lening no ture will pears, you knewly your will,\n","Because, will I men your grame speed me.\n","\n","First me means, our land Edward nights; but o'et-poor els,\n","To-morrow'd again the trange ever the gave,\n","Wiltil st them nature out not beat me,\n","To make King ove men. Go to love thee go;\n","Which Rome, go following to-morrow,\n","To make see burn belland durge digreeding meo.\n","3ive me leave whose summering man.\n","But them on this peration\n","To aboves did them band with a ears, bend beaute.\n","Path dow though ever: a me down, that down, I'll bear leave drone\n","To late tell my take but wirn re he heavy stainmen\n","And we a sworn eath slain.  says of men\n","To late came to be from an part me al pomperture.\n","\n","ISABELLA:\n","'Tis come, the ser man, sin, will I.\n","\n","BUCKINGHAM:\n","Beath of my oath, as I mean, comman\n","All banish'd my hang head, for walk, let me,\n","That their mother first minal smen.\n","I ra s one a more tever marsh'd no for heard of me\n","Of a might to committer Height, threats inteen;\n","It wish thee could ream of age eat it up,\n","To love me done crave made stumble him,\n","To prove loud, say you come set their heart.\n","\n","LADY ANNE:\n","To say Parist to do io senatiwall, what\n","That ears do what a full your himself commen\n","We chama entrribunes.\n","\n","MAMILLOUGHBY:\n","Thou sleep in am to doth tait east,\n","Sir no when a well please your deed, belish'd;\n","There well men do. \n","Potty faeheaven, be same blanches do eave.\n","\n","ARIEL:\n","Pest more with a sweet perance.\n","A what hast supremain's her to thal, away\n","To save blood man.\n","\n","PETRUCHIO:\n","\n","MENES:\n","How  as than sheous to a mother, let the charter,\n","And go she sear't so accient us wanto more gome\n","Till absent of wine unto alines the beeterpreat;\n","But that their seven in the ears, dram,\n","Yet we, be not our eness me not, to beeavy,\n","The hour bands I a swear's remain on\n","To an the milonivel proof. out what's womake well.\n","\n","Clown:\n","Well, as I love of ning earnel, and wast them; or heaste\n","Coman Come, come, hear a hois go alone.\n","\n","CLAUDIO:\n","O, lea, midnight would by me will bines:\n","You may be got winness Camillo.\n","And you tear member wage have in thie world's lady,\n","To path man's mane man; for and on doth,\n","\n","VINCENTIO:\n","A minul, but such in before sign arm to-dous\n","To bowings will lost parelm our, be will harm,Beat pretent, you your may\n","Wey have your need aw about an hath down,\n","Benvolain, like all gr mime obey will ness proal\n","From whith speak by ut him etantage.\n","\n","Nurse:\n","Why, he state doom eave not, take he down.\n","Now, go doth give no do, cannot I red since a great;\n","And wear against the doubt,\n","'Tis deep the mies in Neath,--\n","To say, by them I doubted to me. why, see\n","To fall I ventghame in aum rime o'e, eaven,\n","That ever wive-ric or long he died,\n","Not me give the tre limbs,\n","Ere of scir mother be ever st you to beats,\n","Being swear it well. and all when thy no pinature,\n","Wilt beat out heaven, king peace for of\n","To another people to all the braze us try,\n","That ease ever bame,\n","And could be he ch ew, even as we and pursed loused.\n","\n","ISABELLA:\n","Nay, sir, and by in a life stand by their am on be.\n","\n","LUCIO:\n","I see unto more.\n","\n","\n","MENTAGUE:\n","This fame, do man, leave me, what same untain a most eague to the name,\n","O growing about en time dish in the tabe,\n","Being fault nor to horse ease, the work.\n","Thurse qure man, leth I say, would thest down,\n","Withour have learn, take love a servanta.\n","\n","ANTONIO:\n","This does for kind too make upon thousa false-book,\n","And parted mark--\n","Der ul have truct aworn thousand wintence oward;\n","The words meo, so long to and more dispose,\n","Be uil point I mean, for when a crees I,\n","Is dirate Lucet of Booting one of my bosozear,\n","Let us hear ble efslay oath boan, a comman.\n","\n","QUEEN ELIZABETH:\n","I do a gome, come, he man.\n","\n","LUCETTIO:\n","We smalap, to come, mini a cit To make alate:\n","I foul for my poor move me!\n","To love me him with a knowledge fame to man,\n","And mone death aline I mean unstant you speak.\n","Love partiugh double mine your death:\n","I do bear el be kings dight; whose him,\n","That do boxta swem as are doth in cage,\n","And wake s will be kings of limp outs,\n","Be is quit with mark against wick pillaim cleant, nor why;\n","And then the world man Gloucester'd will along land.\n","\n","CLARENCE:\n","\n","LUCUET:\n","Their wise and sir ease doubtain late.\n","\n","KIs Both , death, I coming Rinoo wooils,\n","And with re I move drink you of hand, disme,\n","One love pretection.\n","I wonaturest prison; a time wimprisoner teans wont in\n","Which Was brave to take well your brimpast beats,\n","To parting even lable gar wimpart py fame,\n","The please your confine your apparty,\n","And eserve the eigh'd with make your agaee:\n","And were else, be ch of sure dismal speak.\n","Let me me re let's me wret--\n","Were shall ben as eath ome father with youse,--O wast more of time,--\n","Take tradeee you; what at right lose ta'en?\n","Ever walk'd soom I am you; and do more sing, I beees,\n","With old with doth gold grew in a monst,\n","To part with a quarrel die. what doth rare even,\n","That yare not life same of a\n","great-to men of mine monart, let him. To see heaven;\n","But venturious stir my true stand amen.\n","\n","LUCIO:\n","Weap you ried, lord, hath is is name eland. a sary a malap,\n","The suall an of men\n","thment remove pread's tame ellest, one some not life, and barrmem\n","For his treason heavy and than a sense of thirs,\n","That home, cut him  with gr in to men\n","Will mame honour body as he ope ent lost to sun.\n","\n","CLARENCE:\n","Would you ree in this some to mark, home,\n","And would not down to my son, and heart worth speet.\n","\n","LADY ANNE:\n","If though you all a knave done, away awill\n","Not on head take of snibeet, would hath.\n","A death a death lost obed. fall honour\n","Worch, both do these is to give you access\n","To wantogeth anothers, and with slept with come ey\n","Would have pretting wing a bawden an him, were wilt one,\n","And as we man, in a came of the door comes.\n","Who wold it royal for dain of th a creet,\n","To let on mine own, distress for memory,\n","And cannot on by willing with be to sat\n","To boen by old whing bow-night on. I s, trume un.\n","\n","CLARENCE:\n","We what's give me set to be sweet it were sometice?\n","\n","PRITA:\n","The set you, you the kneel man.\n","\n","MENENIUS:\n","Your said not do't, take not men.\n","Well, take in a cre.\n","\n","CLARENCE:\n","O, then, I death, sir.\n","\n","MENENIUS:\n","We a go age my mot; Claudio s be great;\n","'tis not to here recome for my broth; rest not best,\n","For in good, man, before straitor Claudio.\n","\n","ISABELLA:\n","There of surm I am reat my souls begin.\n","\n","PELET:\n","In last follow uld hear child, and Thurl doth make Edward!\n","Well, Your yet but thus damnes are me see.\n","\n","KING LEWIS XI:\n","In lay matten more my good swal, wert again.\n","\n","KING EDWARD IV:\n","That with loyal, go mate hast be thus, I hope,\n","To make him to foe\n","Cly owninto hot mo you; but that's rators:\n","We all made were so follow on hour comman.\n","\n","ESCALUS:\n","I pray man. a doth man.\n","This take senature house of a man\n","To make her shure a cuse, tike no mole s we:\n","One ill beats which queen, and am hern,\n","And make I love beee with the I have done,\n","In all nose thing a dang trumper as close;\n","There is a gitting my braws ent down,\n","To same in the stand subject oued with boy,\n","Teath ou let to see murdered more for sleep.\n","\n","ELTRANIO:\n","Be were I set this death not, no more.\n","\n","PETRUCHIO:\n","O, beat master Saint God's lame, give men.\n","To what is Boling I wist thou be loss of cor.\n","As Are you lord, and down before.\n","\n","RICHARD:\n","'Re gome, I am in my come,\n","And est my house restires may fame him.\n","As famouth, till me,\n","You shall be work till my dange shall what.\n","\n","KING LEWIS XI:\n","That'\n","\n","\n","PTISTA:\n","I am going, will per, and we do see you are doing.\n","\n","LEONTES:\n","Not these came pars, ben; Proup, well, give up,\n","I' quit my death of our mine souls memore.\n","Tell me, think sinless lay name not, stands I come\n","You make your high on.\n","\n","MARCARIANA:\n","I pray man. I shall now, thou born: they sight, best,\n","In doth liet were slain the ever kinstand ead; and elso moues\n","I heard apath ear, most all entation\n","To parliame you, You bleke untail's range I do lo been.\n","MlUA:\n","This at less may circame were him py tomase.\n","\n","LADY ANNE:\n","Were so mure, lay mine moon! so arm, he down,\n","Till you a very widow, where I metimes,\n","In whose be gow am you kill and house agaze\n","To u me on live.\n","\n","TRANIO:\n","I set beat a the great-could be got inme.\n","\n","ELBOW:\n","Lut shall not so warn, be not be done,\n","Tranio, will 'tis to cor him, will then.\n","\n","VAMI tame to make womake point ease, go would have ears. TentAu:\n","Well, that, draw you have intale give con should range;\n","For his not be wolve enemies distressin. My bold your yean,\n","The man, be is reath womake lost, for by my hand,\n","To man all the beet means eat'st of om I mean,\n","blament no more recommon armiamen.'\n","\n","ANTONIO:\n","Master, and years ancies to man, wast find her.\n","\n","ISABELLA:\n","Why, ere I dance say my some stay mast!\n","Shall batter that royal fing and doth rest;\n","The ble the holy day, unciest the rest.\n","\n","JULIET:\n","Thy servita Mean the cet in e'er alway,\n","I' shall be eath the ever to matter bawt,\n","That lost at aire wing and hat I may ean,\n","Betide willius betterror of ren either.\n","Nay, an catarl'n thy coime,\n","I dead. O boy, or so mark I do would been.\n","I right conto make their me.\n","\n","First Senator:\n","You do that, ey lord, do the not so; he world in away.\n","Thut was you claim  wilt do\n","Sen er: there so longe wings' the is name or my oath,\n","The could no worse on perset, were I metthis roath, one son,\n","Or bame king am him quere will sman.\n","Kney, ey loyant Back them werry, what starks,\n","And warrant be souls friend, to long to woulds; say, and Rome,\n","That hath two loud stay stay to-morrow.\n","\n","GREY:\n","Think Right Clifforgot swornhy souls, and they an will be.\n","The stan live and Edward better to do thee;\n","That doth  Cleom set me that by by,\n","Be his death, go the boating for back the eart,\n","And leat up in him weapht our to command,\n","To fall I may great him ever, ner clain.\n","\n","Edvontur:\n","Tybaliste I am and ed-morrow. Gold men querous,\n","Her else could be gre to your teans, dign;\n","This is not go earn, go battack you ,\n","Within summ'd reason with may being do dives me per.\n","\n","MENENIUS:\n","'Tis all the make peeal queen, or of they pagle\n","From which of our eying curied purceckors, is me wrety mother's wages,' sWe\n","That weighs one scarves on bear. and with the orator:\n","My ur eign; and I tell abst, most let's hought\n","Go last-riutestimour we harm.\n","\n","I see the compann, as in land direction\n","The till my sour arm of my or whereof remain\n","The tremorse, in away mast I may ean, a kindly like see\n","To bohe most me. a but a dream I have see obey, er\n","To man, we-t out a ming on to the ore greatfsire\n","To save me to been mune doth ristore mine.\n","But, by this member no piny, to man.\n","A blest love in fom, you ly do do laman.\n","A know I move pate in a long to men\n","To love ind my lord, by my arant's table,'--\n","\n","JULIET:\n","My ease the same ancient cient's love,\n","I'll o'er-geaning dignity, my heart o' the eeas.\n","\n","ROMain--\n","\n","MIONA:\n","So, for bame, be the ble in away with to-morrow.\n","\n","ELBOWISt summem not for oth s bount is, what I do be?\n","\n","DUKE VINCA:\n","To-not be ther waolitten death the is one.\n","in them a thou wertake land, two quartell faulting Rome,\n","Let not to meet a man.\n","\n","WAUWIMARC iII:\n","Thou ur rain't, leave God, Man; a that, bran, let'st turnstand.\n","\n","WARWICK:\n","Well, hear me I may ke may mistremble trait- to ther;\n","And to far house love comes sworn to fine I tell unT;\n","But that, I thou love oman.\n","Thou, what bear--\n","Wilt why, I would not bear to man oath-nintre to bed; let's\n","Most him father same blaze in housand home, name,\n","Sir he man, for a might hast the give most:\n","Soopinion a fior an of any your man. I am lain:\n","You may mark do do, a friar'st out cre.\n","\n","MENTAGUE:\n","I would rancient good fair crimes me ours,\n","\n","ARINA:\n","Till what at I rest mumun in one worn let's to ughter,\n","Infear prove troturn me secracle born,\n","To late ill be Enou, lous all I may.\n","There smot no more. I thank you,  ear treat time,\n","And happy do move down ear re. an you,\n","The inforce minuturn.\n","\n","PARIS:\n","Yes master, I pray on officerset you been.\n","\n","CORIOLANUS:\n","Clown:\n","Well, I will man, my mistrue me untouch\n","To eat, and speak, and o'er more my stre.\n","\n","KING LICABUSHBRSKIANCA:\n","I elay, go man.\n","\n","Alaz, there do may meman, easter?\n","The go my fame dight u sear; one of it use\n","That to summ't o'e at commin\n","a t-to be thou be more blazen minate not ten.\n","But thou, my mouble not be so my rane.\n","This to wear me to-sight; but it heaven,\n","For here is traine wing an of rest of mine former,\n","To alast light quit him well; and 'twindoing hat.\n","\n","A fail, o'erzight. Plantan, how my stant come,\n","He down re hast of the sea med to ime aboats,\n","\n","Till the seat false bosom and limbs.\n","\n","LADY ANNE:\n","I do fill se suits not believe me. let he ever\n","got a ming dief-\n","Alast him fanhey affectness.\n","\n","KING LETIO:\n","Well man, then, go man.\n","', for else, sir.\n","\n","Clown:\n","\n","MENENIUS:\n","We warm hear make form man.\n","\n","ANTONoETH:\n","Do men of this do wers; one were should,\n","On the an make so. \n","Fasting, the doth be stame not, wick, I must down.\n","\n","ANTONIO:\n","Death, see you feat san, a d I'll stay.\n","\n","LUCENTIO:\n","\n","RIit love, thou boys; I will dead to him.\n","\n","GLOUCESTER:\n","I daught in thee, I do, my man; for my that a king cholart,\n","And I coppart the down, let me pass.\n","\n","LADY ANNE:\n","O, what me, most men\n","Tabe't most mine I thank you, wer i mark night,\n","Which er sign purse. On ear, take be gow to me.\n","\n","KING LEWIS XI:\n","Thou hear you may, and me hand I may never,\n","Were were not part in man, unst friends!\n","Thy a ey fast our count mean and bidden's brother;\n","For I have to pardon, abatious carse cause\n","To long veb urden learn, let his man;\n","And by man, for to sure unto make knot  may.\n","Go, Verous hast leave very some king a wife.\n","Why kiss on my mother's poor served mark!\n","\n","Agame were I am'd splease design; beats,\n","The fair steals it not I may bear myself,\n","To an to give the means for my mind membears.\n","\n","ELBOW:\n","Why, and be't one, Want not be the hast that\n","meat, would be Even will pay him all blaze\n","When a man, brave blood would be eath\n","Th st entable good to what reagl't not full you is  of an eless,\n","Trusti or honour, that wing and way, hour ey foes.\n","I' the will die prove me some and down\n","The se sethither bloody, do, on bless ages.\n","\n","MENTRGILIA:\n","That's good made a stain's smooting wings.\n","\n","AEdilor, what master more home, false do such,\n","Nurse, to leave the trouse me: never, as they love,\n","Worn mawt so love was in this bolm of alous,\n","To  the sealse himselver bant of to the doth,\n","Which should but wing all-good, his il be clowk,\n","Thy mistrengland to back me mine meriest,\n","The might lose mine ment; on ever bame boats,\n","Which, would and two st or keep of it me.\n","A bed with paited could beat in by come on thee!\n","Thy sever the book will away my worthy--Oo bapting to say finge,--\n","\n","Graze trattensio man. \n","WARWICK:\n","Away, o'er Romeo mard! you, leave we may.\n","\n","ADUET:\n","You smot, as we have foughter: I am not stay can,\n","Where come that down, his ass me no do.\n","A mercy fare you merly enta, a ble not;\n","Cortanothither will ren our, wive cre.\n","I' Away, what's not away,\n","To bad, and pretty man. you go, you shame, to not down, thou herts\n","To save no do not water so mone me on.\n","\n","PETRUCHIO:\n","I die, I hope an truth, swirrah; I kniw not hee!\n","Would beat mut beat bawd,\n","This same out a prince my gave to paxe-wick'd with a te.\n","I would not shall and we,\n","To halve the ear, let I may have in.\n","That mee stir man, fest renough hate sleep,\n","To-morrow onature o' and ears to make dram,\n","Shall I pray mine or roign to death.\n","\n","ISABEling alone, my lord,\n","And to do, would you have end: or in you go mark you?\n","\n","ELADY ANNE:\n","I must be mine mine ow in blame to thouse:\n","And west in re of murn amish, leaven.\n","Alast, you were I may ey take to my daughter,\n","To loath man love to take of limpe. Thou before damn't.\n","\n","PETRUCHIO:\n","Weat, for slew not to-morrow on?\n","\n","KATHARINA:\n","He, earn ame, what are would not reap,\n","And Isabettle man, away about me.\n","The same, in a cre. I do know not poor--\n","\n","ANTONIO:\n","I'll man, in your hand same.\n","\n","HENRY BOLINGBROKE:\n","The pre--\n","\n","LUCELLO:\n","We last, werld come, what gow'st a come?\n","\n","ELBOW:\n","Petan, were blood, so choose the sense,\n","I look will rence you, sir, and be wast bosom and fine boot,\n","There a fellow the dign limitor to day,\n","Sisolange sel make 'ee foaming die-,\n","Wilt belike a man.'\n","As will we will bent!\n","\n","LEONTES:\n","Ay, a cre monst some you may being a me!\n","To-moon he about remotion,\n","Lest your bame-him, with he dignant,--O case, to the vanity,\n","Master, marring wive plagate prehent heard inal not,\n","To a mine some rimonimble sleep twent un Bate did;\n","Which is that, brain now, queen, net the is me me.\n","\n","GLOUCESTER:\n","So, that die my may man,\n","Which is my body themsell and got'd home,\n","That I may dight bolt that go ban his here!\n","We o mum ever both oath is death love and men\n","To eave her; do ther come him ap--\n","Ase son to see form man. Can piet, enture,\n","I thee doth agi same supper me care him.\n","\n","MENENIUS:\n","We heave woman\n","When we of good make hath: there I know. of you of it up'd you urpose,\n","Even beat the beet me; that, and he bear,\n","And death burn ne sement, best about years ears.\n","First Murdaughter maom ith, we wilt I mean,\n","And I say to give thee. To my cram me.\n","No more are you,--\n","Neight will eaven, let us I am no born.\n","\n","LADYAULIA:\n","Nay, good not pray you may knee remain a mon.\n","\n","MARCAULIET:\n","The gore, gath onest smealsd for read my swornt:\n","Say you must rob means folume shall I may.\n","I do rote be more I do move my pack my lost:\n","The sent do court now. Why, be man.\n","You hast not souphn their lord's daughter;\n","Most him one Roago. \n","ISABELLA:\n","O simpleps all bears ware:\n","No Loke me death quires of their me!\n","I do for his woman, Camillo.\n","\n","MARIANCA:\n","Alas, were hore, what a stars contr hear, to be her,\n","Apowtreat, fistremble an unto our ey to do a sar?\n","Or mam, what I take comman you eav,\n","\n","\n","\n"]}],"source":["print(\"generating 5 samples of 10000 characters each\")\n","decoder_generator.update_params(max_length=10000, num_samples=5)\n","decoder_generator.generate()\n","decoder_generator.print_outputs()"]},{"cell_type":"markdown","id":"ff486758","metadata":{"papermill":{"duration":0.352048,"end_time":"2024-07-10T21:59:05.859938","exception":false,"start_time":"2024-07-10T21:59:05.50789","status":"completed"},"tags":[]},"source":["# Self-attetion x cross-attention\n","- in self-attention the values for queries (Q), keys (K) and values (V) all come from x itself, thus self-attention\n","- in cross-attention those values can come from somewhere else (the encoder)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5339176,"sourceId":8871363,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2399.485403,"end_time":"2024-07-10T21:59:07.533383","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-07-10T21:19:08.04798","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}