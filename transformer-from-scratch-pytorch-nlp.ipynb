{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597e8e07",
   "metadata": {
    "papermill": {
     "duration": 0.011479,
     "end_time": "2024-07-09T20:12:18.973893",
     "exception": false,
     "start_time": "2024-07-09T20:12:18.962414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction (WIP)\n",
    "- This notebook is based on the \"Let's build GPT: from scratch, in code, spelled out\" tutorial by Andrej Karpathy. You can find the tutorial here --> https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7\n",
    "- There are several different approaches in this notebook that do not strictly follow the original video. Some implementations are my own.\n",
    "- I am using the same shakespeare text as in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed93d10",
   "metadata": {
    "papermill": {
     "duration": 0.010781,
     "end_time": "2024-07-09T20:12:18.995912",
     "exception": false,
     "start_time": "2024-07-09T20:12:18.985131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6af644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:19.019786Z",
     "iopub.status.busy": "2024-07-09T20:12:19.019278Z",
     "iopub.status.idle": "2024-07-09T20:12:22.643561Z",
     "shell.execute_reply": "2024-07-09T20:12:22.642442Z"
    },
    "papermill": {
     "duration": 3.639519,
     "end_time": "2024-07-09T20:12:22.646406",
     "exception": false,
     "start_time": "2024-07-09T20:12:19.006887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b0c89",
   "metadata": {
    "papermill": {
     "duration": 0.010686,
     "end_time": "2024-07-09T20:12:22.668270",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.657584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c6106a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.693282Z",
     "iopub.status.busy": "2024-07-09T20:12:22.692336Z",
     "iopub.status.idle": "2024-07-09T20:12:22.701116Z",
     "shell.execute_reply": "2024-07-09T20:12:22.699713Z"
    },
    "papermill": {
     "duration": 0.023878,
     "end_time": "2024-07-09T20:12:22.703908",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.680030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "generator = torch.Generator(device=device)\n",
    "print(f\"default device set to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc14402",
   "metadata": {
    "papermill": {
     "duration": 0.010953,
     "end_time": "2024-07-09T20:12:22.726509",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.715556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b0a2d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.751025Z",
     "iopub.status.busy": "2024-07-09T20:12:22.750634Z",
     "iopub.status.idle": "2024-07-09T20:12:22.809200Z",
     "shell.execute_reply": "2024-07-09T20:12:22.807736Z"
    },
    "papermill": {
     "duration": 0.073722,
     "end_time": "2024-07-09T20:12:22.811479",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.737757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "with open(\"/kaggle/input/shakespeare/input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a16127",
   "metadata": {
    "papermill": {
     "duration": 0.012213,
     "end_time": "2024-07-09T20:12:22.835027",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.822814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f8a0dc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.860078Z",
     "iopub.status.busy": "2024-07-09T20:12:22.859660Z",
     "iopub.status.idle": "2024-07-09T20:12:22.866088Z",
     "shell.execute_reply": "2024-07-09T20:12:22.864958Z"
    },
    "papermill": {
     "duration": 0.022308,
     "end_time": "2024-07-09T20:12:22.868698",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.846390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: v for v, c in enumerate(vocab)}\n",
    "itos = {v: c for c, v in stoi.items()}\n",
    "print(stoi[\"h\"])\n",
    "print(itos[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c4762a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.893023Z",
     "iopub.status.busy": "2024-07-09T20:12:22.892630Z",
     "iopub.status.idle": "2024-07-09T20:12:22.899829Z",
     "shell.execute_reply": "2024-07-09T20:12:22.898186Z"
    },
    "papermill": {
     "duration": 0.022256,
     "end_time": "2024-07-09T20:12:22.902394",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.880138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 6, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12, 2]\n",
      "hello, how are you?!\n"
     ]
    }
   ],
   "source": [
    "encode = lambda d: [stoi[idx] for idx in d]\n",
    "decode = lambda e: \"\".join([itos[idx] for idx in e])\n",
    "\n",
    "encoded = encode(\"hello, how are you?!\")\n",
    "decoded = decode(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359661f",
   "metadata": {
    "papermill": {
     "duration": 0.012562,
     "end_time": "2024-07-09T20:12:22.926655",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.914093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b305eba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.952487Z",
     "iopub.status.busy": "2024-07-09T20:12:22.951524Z",
     "iopub.status.idle": "2024-07-09T20:12:22.956780Z",
     "shell.execute_reply": "2024-07-09T20:12:22.955666Z"
    },
    "papermill": {
     "duration": 0.020833,
     "end_time": "2024-07-09T20:12:22.959181",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.938348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_size = 8\n",
    "n_embd = 5\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5a539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:22.984380Z",
     "iopub.status.busy": "2024-07-09T20:12:22.984015Z",
     "iopub.status.idle": "2024-07-09T20:12:22.991043Z",
     "shell.execute_reply": "2024-07-09T20:12:22.989749Z"
    },
    "papermill": {
     "duration": 0.022236,
     "end_time": "2024-07-09T20:12:22.993389",
     "exception": false,
     "start_time": "2024-07-09T20:12:22.971153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(text, context_size):\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "    #random_idx = torch.randint(0, len(data)-context_size, (int(len(data)/context_size),))\n",
    "    random_idx = torch.randperm(len(data)-context_size)\n",
    "    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx])\n",
    "    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx])\n",
    "\n",
    "    return TensorDataset(inputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f95b988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:23.018419Z",
     "iopub.status.busy": "2024-07-09T20:12:23.018023Z",
     "iopub.status.idle": "2024-07-09T20:12:23.081009Z",
     "shell.execute_reply": "2024-07-09T20:12:23.079834Z"
    },
    "papermill": {
     "duration": 0.078258,
     "end_time": "2024-07-09T20:12:23.083400",
     "exception": false,
     "start_time": "2024-07-09T20:12:23.005142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 2, 1, 7, 0, 4, 3, 2, 6, 1])\n",
      "tensor([3, 8, 5, 1, 7, 9, 0, 4, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# sicne randint might give the same random_idx, randperm is going to be preffered\n",
    "print(torch.randint(0, 10, (10,)))\n",
    "print(torch.randperm(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "882d4a58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:23.108874Z",
     "iopub.status.busy": "2024-07-09T20:12:23.108508Z",
     "iopub.status.idle": "2024-07-09T20:12:29.251127Z",
     "shell.execute_reply": "2024-07-09T20:12:29.249886Z"
    },
    "papermill": {
     "duration": 6.158727,
     "end_time": "2024-07-09T20:12:29.254067",
     "exception": false,
     "start_time": "2024-07-09T20:12:23.095340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(text=text[:100000], context_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c64a5922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:29.282079Z",
     "iopub.status.busy": "2024-07-09T20:12:29.281664Z",
     "iopub.status.idle": "2024-07-09T20:12:29.297284Z",
     "shell.execute_reply": "2024-07-09T20:12:29.295900Z"
    },
    "papermill": {
     "duration": 0.033613,
     "end_time": "2024-07-09T20:12:29.300328",
     "exception": false,
     "start_time": "2024-07-09T20:12:29.266715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.8)\n",
    "test_split = int(len(dataset)-train_split)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64771351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:29.326344Z",
     "iopub.status.busy": "2024-07-09T20:12:29.325908Z",
     "iopub.status.idle": "2024-07-09T20:12:29.332771Z",
     "shell.execute_reply": "2024-07-09T20:12:29.331633Z"
    },
    "papermill": {
     "duration": 0.023347,
     "end_time": "2024-07-09T20:12:29.335510",
     "exception": false,
     "start_time": "2024-07-09T20:12:29.312163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, generator=generator)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be179a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:29.362205Z",
     "iopub.status.busy": "2024-07-09T20:12:29.361072Z",
     "iopub.status.idle": "2024-07-09T20:12:29.366632Z",
     "shell.execute_reply": "2024-07-09T20:12:29.365540Z"
    },
    "papermill": {
     "duration": 0.021622,
     "end_time": "2024-07-09T20:12:29.369051",
     "exception": false,
     "start_time": "2024-07-09T20:12:29.347429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_from_data(dataloader):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #print(f\"batch {batch}, input {X}, label {y}\")\n",
    "        #print(batch)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d25e20d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:29.396988Z",
     "iopub.status.busy": "2024-07-09T20:12:29.396543Z",
     "iopub.status.idle": "2024-07-09T20:12:30.080636Z",
     "shell.execute_reply": "2024-07-09T20:12:30.079379Z"
    },
    "papermill": {
     "duration": 0.700767,
     "end_time": "2024-07-09T20:12:30.083519",
     "exception": false,
     "start_time": "2024-07-09T20:12:29.382752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_from_data(dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5c0990",
   "metadata": {
    "papermill": {
     "duration": 0.01331,
     "end_time": "2024-07-09T20:12:30.109830",
     "exception": false,
     "start_time": "2024-07-09T20:12:30.096520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32f11ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:30.137163Z",
     "iopub.status.busy": "2024-07-09T20:12:30.136008Z",
     "iopub.status.idle": "2024-07-09T20:12:30.149529Z",
     "shell.execute_reply": "2024-07-09T20:12:30.148208Z"
    },
    "papermill": {
     "duration": 0.029556,
     "end_time": "2024-07-09T20:12:30.152029",
     "exception": false,
     "start_time": "2024-07-09T20:12:30.122473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, context_size, n_embd, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # B x T x C; B --> batches, T --> time (context_size), C --> n_embd\n",
    "        self.pos_embedding_table = nn.Embedding(context_size, n_embd) # T x C; this is from the posisitional encoding part of the video\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=context_size*n_embd, out_features=8*8) # B x T*C @ T*C x H; H --> number of hidden_units\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = idx.shape\n",
    "        C = self.n_embd\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        x = self.token_embedding_table(idx) + self.pos_embedding_table(positions)\n",
    "        x = x.view(B, T*C)\n",
    "\n",
    "        x = self.act_fn(self.linear1(x))\n",
    "        x = self.act_fn(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, idx: torch.Tensor, randomize: bool, max_length: int, num_samples: int) -> torch.Tensor:\n",
    "        outputs = []\n",
    "        for sample in range(num_samples):\n",
    "            full_text = \"\" \n",
    "            for i in range(max_length):\n",
    "                logits = self(idx)\n",
    "                percents = torch.softmax(logits, dim=1)\n",
    "\n",
    "                if randomize:\n",
    "                    pred = torch.multinomial(percents, num_samples=1)\n",
    "                    full_text += decode(pred.tolist()[0])\n",
    "                    idx = torch.cat([idx[:, 1:], pred], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                else:\n",
    "                    pred = torch.argmax(percents)\n",
    "                    full_text += decode([pred.item()])\n",
    "                    idx = torch.cat([idx[:, 1:], pred.view(1, 1)], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                    # in the argmax the output is a single element, pred.view(1, 1) turns it into a batch of dim 1, so it can be concatenated to the previous context\n",
    "\n",
    "            outputs.append(full_text)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a1974d",
   "metadata": {
    "papermill": {
     "duration": 0.011604,
     "end_time": "2024-07-09T20:12:30.175669",
     "exception": false,
     "start_time": "2024-07-09T20:12:30.164065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the base model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "586b1f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:30.265353Z",
     "iopub.status.busy": "2024-07-09T20:12:30.264962Z",
     "iopub.status.idle": "2024-07-09T20:12:31.753616Z",
     "shell.execute_reply": "2024-07-09T20:12:31.752620Z"
    },
    "papermill": {
     "duration": 1.568108,
     "end_time": "2024-07-09T20:12:31.756395",
     "exception": false,
     "start_time": "2024-07-09T20:12:30.188287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLP(context_size=context_size, n_embd=n_embd, vocab_size=vocab_size)\n",
    "optimizer = torch.optim.Adam(params=mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1d3d2",
   "metadata": {
    "papermill": {
     "duration": 0.011824,
     "end_time": "2024-07-09T20:12:31.780553",
     "exception": false,
     "start_time": "2024-07-09T20:12:31.768729",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Take samples from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b37f593",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:31.806720Z",
     "iopub.status.busy": "2024-07-09T20:12:31.806194Z",
     "iopub.status.idle": "2024-07-09T20:12:31.890211Z",
     "shell.execute_reply": "2024-07-09T20:12:31.889114Z"
    },
    "papermill": {
     "duration": 0.099995,
     "end_time": "2024-07-09T20:12:31.892725",
     "exception": false,
     "start_time": "2024-07-09T20:12:31.792730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XFPqHKUPXy \n",
      "\n",
      "\n",
      "n?NCBOGOjt \n",
      "\n",
      "\n",
      "grBqJ$mU:3 \n",
      "\n",
      "\n",
      "PtCujIEqHc \n",
      "\n",
      "\n",
      "RdFbzaUjbd \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def model_sampler(model, context, randomize, max_length, num_samples):\n",
    "    #print(len(context))\n",
    "    #print(context_size)\n",
    "    test = torch.tensor([[20, 53, 61,  1, 39, 56, 58, 39]])\n",
    "    #print(test[:, 1:])\n",
    "    result = torch.cat((test[:, 1:], torch.tensor([[99]])), dim=1)\n",
    "    #print(result)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    mlp.eval()\n",
    "    idx = torch.tensor(encode(context), dtype=torch.long).view(1, len(encode(context))) # inputs must be batched\n",
    "    outputs = mlp.generate(idx=idx, randomize=randomize, max_length=max_length, num_samples=num_samples)\n",
    "    for output in outputs:\n",
    "        print(f\"{output} \\n\\n\")\n",
    "\n",
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=10, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec35a7de",
   "metadata": {
    "papermill": {
     "duration": 0.01221,
     "end_time": "2024-07-09T20:12:31.917334",
     "exception": false,
     "start_time": "2024-07-09T20:12:31.905124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60768bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:31.944047Z",
     "iopub.status.busy": "2024-07-09T20:12:31.943557Z",
     "iopub.status.idle": "2024-07-09T20:12:31.950750Z",
     "shell.execute_reply": "2024-07-09T20:12:31.949534Z"
    },
    "papermill": {
     "duration": 0.0234,
     "end_time": "2024-07-09T20:12:31.953015",
     "exception": false,
     "start_time": "2024-07-09T20:12:31.929615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in tqdm(enumerate(dataloader)):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y[:, -1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3345df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:31.979329Z",
     "iopub.status.busy": "2024-07-09T20:12:31.978926Z",
     "iopub.status.idle": "2024-07-09T20:12:39.924452Z",
     "shell.execute_reply": "2024-07-09T20:12:39.923368Z"
    },
    "papermill": {
     "duration": 7.962018,
     "end_time": "2024-07-09T20:12:39.927365",
     "exception": false,
     "start_time": "2024-07-09T20:12:31.965347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 159.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.240123748779297 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [00:00, 313.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 200 --> 3.148144245147705 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:01, 321.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 400 --> 2.717410087585449 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [00:02, 324.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 600 --> 2.761871099472046 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "833it [00:02, 313.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 800 --> 2.4733972549438477 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1029it [00:03, 307.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1000 --> 2.1294190883636475 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1257it [00:04, 322.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1200 --> 2.7162749767303467 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1454it [00:04, 319.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1400 --> 2.421358108520508 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649it [00:05, 320.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1600 --> 2.5102336406707764 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1847it [00:05, 322.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1800 --> 2.1967077255249023 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2043it [00:06, 315.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2000 --> 2.386378288269043 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2240it [00:07, 325.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2200 --> 2.2404003143310547 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2436it [00:07, 310.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2400 --> 2.5474936962127686 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [00:07, 315.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the very last batch --> 2.297541618347168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.train()\n",
    "train_model(model=mlp, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e01f76",
   "metadata": {
    "papermill": {
     "duration": 0.018423,
     "end_time": "2024-07-09T20:12:39.964162",
     "exception": false,
     "start_time": "2024-07-09T20:12:39.945739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ded2199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.004398Z",
     "iopub.status.busy": "2024-07-09T20:12:40.003051Z",
     "iopub.status.idle": "2024-07-09T20:12:40.010750Z",
     "shell.execute_reply": "2024-07-09T20:12:40.009408Z"
    },
    "papermill": {
     "duration": 0.030215,
     "end_time": "2024-07-09T20:12:40.013291",
     "exception": false,
     "start_time": "2024-07-09T20:12:39.983076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def model_inference(model, dataloader):\n",
    "    mlp.eval()\n",
    "    X, y = next(iter(dataloader))\n",
    "    logits = model(X)\n",
    "    percents = torch.softmax(logits, dim=1) # dim=1 since the input was batched\n",
    "    preds = torch.argmax(percents, dim=1) # dim=1 since the input was batched\n",
    "    print(f\"for {X} \\n model predicted {preds}\")\n",
    "    print(f\"expected --> {y[:, -1]}\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76018029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.052827Z",
     "iopub.status.busy": "2024-07-09T20:12:40.052436Z",
     "iopub.status.idle": "2024-07-09T20:12:40.064826Z",
     "shell.execute_reply": "2024-07-09T20:12:40.063501Z"
    },
    "papermill": {
     "duration": 0.03574,
     "end_time": "2024-07-09T20:12:40.067522",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.031782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for tensor([[26, 33, 31, 10,  0, 20, 43, 52],\n",
      "        [43,  1, 63, 53, 59, 56,  1, 41],\n",
      "        [63,  1, 57, 39, 63,  6,  0, 32],\n",
      "        [ 1, 57, 47, 56,  6,  1, 58, 46],\n",
      "        [56, 57,  6,  1, 57, 46, 53, 59],\n",
      "        [21,  1, 46, 39, 60, 43,  1, 42],\n",
      "        [ 0, 56, 43, 54, 53, 56, 58,  1],\n",
      "        [58,  1, 52, 53, 58,  1, 58, 46],\n",
      "        [56,  1, 45, 43, 52, 43, 56, 39],\n",
      "        [63, 53, 59,  1, 46, 39, 60, 43],\n",
      "        [47, 51, 43,  1, 57, 46, 39, 50],\n",
      "        [59, 56, 57, 43, 50, 60, 43, 57],\n",
      "        [ 0,  0, 25, 17, 26, 17, 26, 21],\n",
      "        [53, 59,  1, 57, 46, 39, 50, 50],\n",
      "        [57,  1, 58, 53,  1, 57, 53, 51],\n",
      "        [47, 49, 43,  8,  0,  0, 18, 47],\n",
      "        [15, 53, 52, 44, 43, 57, 57,  1],\n",
      "        [50,  1, 46, 39, 56, 42, 50, 63],\n",
      "        [56, 58,  1, 58, 46, 53, 59,  1],\n",
      "        [ 1, 39, 56, 43,  1, 54, 56, 43],\n",
      "        [ 1, 41, 39, 52, 52, 53, 58,  1],\n",
      "        [47, 50, 50, 57,  7,  7, 40, 56],\n",
      "        [57, 58, 56, 53, 52, 45,  1, 40],\n",
      "        [ 1, 51, 43, 56, 41, 63, 12,  1],\n",
      "        [58,  1, 57, 54, 43, 39, 49,  1],\n",
      "        [ 2,  0,  5, 32, 56, 47, 40, 59],\n",
      "        [57, 58, 63,  1, 54, 50, 43, 40],\n",
      "        [57,  1, 39, 52, 42,  1, 54, 50],\n",
      "        [60, 43, 56,  1, 57, 39, 61,  1],\n",
      "        [ 1, 41, 39, 52, 52, 53, 58,  1],\n",
      "        [ 1, 44, 56, 53, 51,  1, 58, 46],\n",
      "        [ 1, 58, 53,  1, 46, 47, 51,  8]]) \n",
      " model predicted tensor([ 1, 53, 46, 43, 56, 53, 61, 43, 52,  1, 43,  1, 33,  1, 43, 58, 39,  1,\n",
      "        61, 56, 58,  1, 53, 53, 58, 57, 43, 39, 57, 58, 43,  0])\n",
      "expected --> tensor([41, 53, 46, 43, 50, 53, 44, 47, 50,  1, 50,  1, 33,  1, 43, 56, 63,  1,\n",
      "        57, 54, 41, 47, 56, 18,  5, 52, 43, 39, 58, 57, 47,  0])\n",
      "tensor([[33, 31, 10,  0, 20, 43, 52, 41],\n",
      "        [ 1, 63, 53, 59, 56,  1, 41, 53],\n",
      "        [ 1, 57, 39, 63,  6,  0, 32, 46],\n",
      "        [57, 47, 56,  6,  1, 58, 46, 43],\n",
      "        [57,  6,  1, 57, 46, 53, 59, 50],\n",
      "        [ 1, 46, 39, 60, 43,  1, 42, 53],\n",
      "        [56, 43, 54, 53, 56, 58,  1, 44],\n",
      "        [ 1, 52, 53, 58,  1, 58, 46, 47],\n",
      "        [ 1, 45, 43, 52, 43, 56, 39, 50],\n",
      "        [53, 59,  1, 46, 39, 60, 43,  1],\n",
      "        [51, 43,  1, 57, 46, 39, 50, 50],\n",
      "        [56, 57, 43, 50, 60, 43, 57,  1],\n",
      "        [ 0, 25, 17, 26, 17, 26, 21, 33],\n",
      "        [59,  1, 57, 46, 39, 50, 50,  1],\n",
      "        [ 1, 58, 53,  1, 57, 53, 51, 43],\n",
      "        [49, 43,  8,  0,  0, 18, 47, 56],\n",
      "        [53, 52, 44, 43, 57, 57,  1, 63],\n",
      "        [ 1, 46, 39, 56, 42, 50, 63,  1],\n",
      "        [58,  1, 58, 46, 53, 59,  1, 57],\n",
      "        [39, 56, 43,  1, 54, 56, 43, 54],\n",
      "        [41, 39, 52, 52, 53, 58,  1, 41],\n",
      "        [50, 50, 57,  7,  7, 40, 56, 47],\n",
      "        [58, 56, 53, 52, 45,  1, 40, 56],\n",
      "        [51, 43, 56, 41, 63, 12,  1, 18],\n",
      "        [ 1, 57, 54, 43, 39, 49,  1,  5],\n",
      "        [ 0,  5, 32, 56, 47, 40, 59, 52],\n",
      "        [58, 63,  1, 54, 50, 43, 40, 43],\n",
      "        [ 1, 39, 52, 42,  1, 54, 50, 39],\n",
      "        [43, 56,  1, 57, 39, 61,  1, 58],\n",
      "        [41, 39, 52, 52, 53, 58,  1, 57],\n",
      "        [44, 56, 53, 51,  1, 58, 46, 47],\n",
      "        [58, 53,  1, 46, 47, 51,  8,  0]])\n"
     ]
    }
   ],
   "source": [
    "model_inference(model=mlp, dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7f7c2fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.107975Z",
     "iopub.status.busy": "2024-07-09T20:12:40.106796Z",
     "iopub.status.idle": "2024-07-09T20:12:40.292815Z",
     "shell.execute_reply": "2024-07-09T20:12:40.291162Z"
    },
    "papermill": {
     "duration": 0.209296,
     "end_time": "2024-07-09T20:12:40.295508",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.086212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cy ware\n",
      "Wurre uele,\n",
      "Arly let hase aneessaaf cinle.\n",
      "\n",
      "FUR,\n",
      "N\n",
      "OLill:\n",
      "Arg theats fo orathen therceomoe ano yeesers! aromedomtre the fathatheon totiseus free tore veenr tans, grerenm,\n",
      "G an the eit ho nley hore hitr and moull foup.\n",
      "\n",
      "COUTUS:\n",
      "Hnowrut hh yound wot hasee,\n",
      "Aro nobd, u worn.\n",
      "\n",
      "MORFOLAUr:\n",
      "Show maseerv: a thaiploanc ifr, wo scem mererteren:\n",
      "ICOte'e thenetb. Maneu noue, yout anqcane Ho mw twepbeoscy, aors 'atpsoy,.\n",
      "I'IRIOLthetly Cge heer.---\n",
      "CAaritT, is mn waobino mowe hasiungoe hitheb fos yoo  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=500, num_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80677104",
   "metadata": {
    "papermill": {
     "duration": 0.020108,
     "end_time": "2024-07-09T20:12:40.335291",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.315183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cce0fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.374693Z",
     "iopub.status.busy": "2024-07-09T20:12:40.374312Z",
     "iopub.status.idle": "2024-07-09T20:12:40.382690Z",
     "shell.execute_reply": "2024-07-09T20:12:40.381530Z"
    },
    "papermill": {
     "duration": 0.03077,
     "end_time": "2024-07-09T20:12:40.385093",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.354323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 8\n",
      "torch.Size([32, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "print(B, T)\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35e78853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.425388Z",
     "iopub.status.busy": "2024-07-09T20:12:40.424972Z",
     "iopub.status.idle": "2024-07-09T20:12:40.457956Z",
     "shell.execute_reply": "2024-07-09T20:12:40.456635Z"
    },
    "papermill": {
     "duration": 0.055792,
     "end_time": "2024-07-09T20:12:40.460576",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.404784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0784e+00,  6.7285e-01,  8.5836e-01, -5.8480e-01],\n",
      "         [-1.1326e+00,  1.0782e-01,  5.4404e-01,  3.6327e-01],\n",
      "         [-1.3497e+00, -9.5280e-02,  7.9182e-01,  7.5423e-01],\n",
      "         ...,\n",
      "         [-6.6040e-01, -6.2231e-02,  5.3419e-01,  8.0532e-01],\n",
      "         [-3.6120e-01, -4.1946e-02,  6.5256e-01,  5.9728e-01],\n",
      "         [-2.1654e-01, -1.9611e-01,  6.2420e-01,  6.2818e-01]],\n",
      "\n",
      "        [[-2.7063e-02,  3.9568e-01, -3.6808e-02,  4.0562e-01],\n",
      "         [ 3.4577e-01,  5.1794e-01,  1.4292e-03, -1.4422e-01],\n",
      "         [ 7.2984e-02, -3.6195e-02,  6.3850e-01,  3.4219e-01],\n",
      "         ...,\n",
      "         [-1.3296e-02, -1.1811e-01,  5.6225e-01,  3.8664e-01],\n",
      "         [-1.9392e-01, -1.0642e-01,  1.8096e-01,  5.0034e-01],\n",
      "         [ 6.4363e-02, -2.8219e-01,  1.3031e-01,  4.8976e-01]],\n",
      "\n",
      "        [[-1.2777e+00, -3.6295e-02, -2.1068e+00,  1.1826e+00],\n",
      "         [-1.5308e+00, -2.6889e-01, -4.0970e-01,  1.3594e+00],\n",
      "         [-1.2599e+00, -8.0187e-01, -9.7691e-02,  4.7137e-01],\n",
      "         ...,\n",
      "         [-5.7854e-01, -2.7346e-01,  1.6810e-02,  2.5585e-01],\n",
      "         [-6.6543e-01, -2.9971e-01,  4.7226e-02,  4.0664e-01],\n",
      "         [-7.0074e-01, -2.6677e-01,  1.2474e-01,  2.9469e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9878e-01,  1.8822e+00,  8.2420e-01,  8.4223e-01],\n",
      "         [-8.9279e-01,  7.1250e-01,  5.2696e-01,  1.0768e+00],\n",
      "         [-3.5566e-01,  6.8840e-01,  3.6453e-01,  4.8651e-01],\n",
      "         ...,\n",
      "         [-6.7633e-01,  5.5738e-01, -6.6467e-02,  4.5612e-01],\n",
      "         [-7.6223e-01,  4.7257e-01, -3.5794e-01,  5.5990e-01],\n",
      "         [-7.8544e-01,  4.0897e-01, -2.2978e-01,  4.2879e-01]],\n",
      "\n",
      "        [[ 7.1860e-01,  6.4020e-01,  3.9666e-02, -6.9405e-01],\n",
      "         [-2.7953e-01,  3.0195e-01, -1.0335e+00,  2.4427e-01],\n",
      "         [-5.4581e-01,  4.2558e-01, -4.0291e-01, -3.2091e-02],\n",
      "         ...,\n",
      "         [-4.9232e-01,  3.2184e-01, -4.7270e-01,  4.3479e-01],\n",
      "         [-5.9153e-01,  2.1055e-01, -3.7236e-01,  5.6001e-01],\n",
      "         [-2.8355e-01, -4.8394e-03, -3.5384e-01,  5.4197e-01]],\n",
      "\n",
      "        [[-1.1868e+00, -4.5720e-01,  2.2972e-01,  1.3113e+00],\n",
      "         [-6.0694e-01, -3.0761e-02,  9.6457e-02,  8.5848e-01],\n",
      "         [-9.9927e-01, -1.8767e-01,  4.9343e-01,  1.0844e+00],\n",
      "         ...,\n",
      "         [-4.7305e-01,  1.1351e-01, -9.1191e-02,  5.0793e-01],\n",
      "         [-4.9101e-01,  3.6618e-01,  3.9579e-02,  5.5569e-01],\n",
      "         [-5.7798e-01,  2.6326e-01,  6.3347e-02,  6.5015e-01]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = torch.zeros(size=(B, T, C)) # each of the values has a unique value\n",
    "\n",
    "for batch_idx in range(B):\n",
    "    for context_idx in range(T):\n",
    "        xprev = embedded[batch_idx, :context_idx+1]\n",
    "        bag_of_words[batch_idx, context_idx] = torch.mean(xprev, dim=0)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbd6fb73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.501489Z",
     "iopub.status.busy": "2024-07-09T20:12:40.500663Z",
     "iopub.status.idle": "2024-07-09T20:12:40.514874Z",
     "shell.execute_reply": "2024-07-09T20:12:40.513420Z"
    },
    "papermill": {
     "duration": 0.0376,
     "end_time": "2024-07-09T20:12:40.517621",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.480021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[12.,  6., 12.],\n",
      "        [46.,  7., 26.],\n",
      "        [50.,  5., 25.]])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [46.,  7., 26.],\n",
      "        [50.,  5., 25.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 3))\n",
    "tril = torch.tril(ones) # lower triangular part of a matrix\n",
    "print(tril)\n",
    "a = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (2, 3), dtype=torch.float32)\n",
    "matmul_output = a @ b\n",
    "matmul_tril_output = torch.tril(a) @ b\n",
    "print(matmul_output)\n",
    "print(matmul_tril_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b92a702c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.557819Z",
     "iopub.status.busy": "2024-07-09T20:12:40.557392Z",
     "iopub.status.idle": "2024-07-09T20:12:40.568144Z",
     "shell.execute_reply": "2024-07-09T20:12:40.566956Z"
    },
    "papermill": {
     "duration": 0.033716,
     "end_time": "2024-07-09T20:12:40.570623",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.536907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[9.0000, 3.0000],\n",
      "        [5.5000, 6.0000],\n",
      "        [4.0000, 4.0000]])\n"
     ]
    }
   ],
   "source": [
    "# do the same as bag of words but with matrix multiplication (dot product)\n",
    "a = torch.ones(size=(3, 3), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "\n",
    "a = torch.tril(a)\n",
    "\"\"\"\n",
    "b = torch.tensor(\n",
    "    [\n",
    "        [2, 7],\n",
    "        [6, 4],\n",
    "        [6, 5]\n",
    "    ], dtype=torch.float32\n",
    ")\n",
    "\"\"\"\n",
    "print(a)\n",
    "a = a/a.sum(dim=1, keepdim=True)\n",
    "print(a)\n",
    "\n",
    "output = a @ b\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6296625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.612885Z",
     "iopub.status.busy": "2024-07-09T20:12:40.612493Z",
     "iopub.status.idle": "2024-07-09T20:12:40.627160Z",
     "shell.execute_reply": "2024-07-09T20:12:40.625250Z"
    },
    "papermill": {
     "duration": 0.039535,
     "end_time": "2024-07-09T20:12:40.630066",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.590531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 4])\n",
      "torch.Size([8, 8])\n",
      "tensor([[[ 0.3688,  0.5734,  2.1180,  0.3947],\n",
      "         [ 0.7394,  0.2214,  1.5908,  0.0598],\n",
      "         [ 0.4816, -0.2449,  1.2497,  0.9870],\n",
      "         ...,\n",
      "         [ 0.5903, -0.2065,  0.8286,  0.5348],\n",
      "         [ 0.6665, -0.2292,  0.6267,  0.5644],\n",
      "         [ 0.6354, -0.3445,  0.5693,  0.4646]],\n",
      "\n",
      "        [[ 0.9006, -2.3556,  1.0607, -0.0566],\n",
      "         [ 0.6516, -1.1261,  1.4045,  0.6743],\n",
      "         [ 0.3296, -0.4183,  1.3290,  0.0963],\n",
      "         ...,\n",
      "         [ 0.0480,  0.3228,  0.9913,  0.2512],\n",
      "         [ 0.2862,  0.4519,  1.0448, -0.0263],\n",
      "         [ 0.3698,  0.5899,  0.9644, -0.0089]],\n",
      "\n",
      "        [[ 1.7154,  1.2267,  1.3655, -1.6913],\n",
      "         [ 0.8407,  0.0246,  0.9665,  0.5751],\n",
      "         [ 1.0021, -0.4073,  1.2261,  0.0095],\n",
      "         ...,\n",
      "         [ 0.5052, -0.4513,  1.1875,  0.4964],\n",
      "         [ 0.5916, -0.4055,  1.1698,  0.3862],\n",
      "         [ 0.3710, -0.4536,  1.1329,  0.2108]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0328, -1.9299, -0.2432,  0.4098],\n",
      "         [ 0.5713, -1.0302,  0.4102,  0.0673],\n",
      "         [ 0.5151, -0.6523,  0.8563,  0.5133],\n",
      "         ...,\n",
      "         [ 0.7837, -0.2356,  1.2311,  0.1234],\n",
      "         [ 0.9168, -0.0267,  1.2503, -0.1358],\n",
      "         [ 0.6555, -0.1222,  1.2033, -0.2459]],\n",
      "\n",
      "        [[ 0.4026,  0.1034,  1.7484,  1.4051],\n",
      "         [ 1.0590,  0.6650,  1.5569, -0.1431],\n",
      "         [ 0.8290,  0.6345,  1.7440,  0.0361],\n",
      "         ...,\n",
      "         [ 0.5797,  0.4523,  1.1650, -0.1530],\n",
      "         [ 0.6555,  0.3691,  1.1505, -0.1704],\n",
      "         [ 0.6929,  0.5174,  1.0569, -0.1350]],\n",
      "\n",
      "        [[ 1.1099, -0.1306,  1.0637, -0.2751],\n",
      "         [ 1.0053, -1.2431,  1.0622, -0.1658],\n",
      "         [ 0.6588, -1.2212,  0.8973,  0.8366],\n",
      "         ...,\n",
      "         [ 0.7495, -0.3717,  1.2590,  0.6048],\n",
      "         [ 0.6471, -0.5943,  1.0444,  0.5769],\n",
      "         [ 0.7050, -0.5363,  1.0468,  0.4704]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "#print(embedded.shape)\n",
    "\n",
    "wei = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "print(embedded.shape) # B x T x C\n",
    "print(wei.shape) # T x T\n",
    "#  1xTxT @ BxTxC\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1510e16",
   "metadata": {
    "papermill": {
     "duration": 0.020161,
     "end_time": "2024-07-09T20:12:40.669843",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.649682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bag of words type aggregation with a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7f4dd17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.710559Z",
     "iopub.status.busy": "2024-07-09T20:12:40.710166Z",
     "iopub.status.idle": "2024-07-09T20:12:40.722977Z",
     "shell.execute_reply": "2024-07-09T20:12:40.721741Z"
    },
    "papermill": {
     "duration": 0.036443,
     "end_time": "2024-07-09T20:12:40.725681",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.689238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[ 0.3688,  0.5734,  2.1180,  0.3947],\n",
      "         [ 0.7394,  0.2214,  1.5908,  0.0598],\n",
      "         [ 0.4816, -0.2449,  1.2497,  0.9870],\n",
      "         ...,\n",
      "         [ 0.5903, -0.2065,  0.8286,  0.5348],\n",
      "         [ 0.6665, -0.2292,  0.6267,  0.5644],\n",
      "         [ 0.6354, -0.3445,  0.5693,  0.4646]],\n",
      "\n",
      "        [[ 0.9006, -2.3556,  1.0607, -0.0566],\n",
      "         [ 0.6516, -1.1261,  1.4045,  0.6743],\n",
      "         [ 0.3296, -0.4183,  1.3290,  0.0963],\n",
      "         ...,\n",
      "         [ 0.0480,  0.3228,  0.9913,  0.2512],\n",
      "         [ 0.2862,  0.4519,  1.0448, -0.0263],\n",
      "         [ 0.3698,  0.5899,  0.9644, -0.0089]],\n",
      "\n",
      "        [[ 1.7154,  1.2267,  1.3655, -1.6913],\n",
      "         [ 0.8407,  0.0246,  0.9665,  0.5751],\n",
      "         [ 1.0021, -0.4073,  1.2261,  0.0095],\n",
      "         ...,\n",
      "         [ 0.5052, -0.4513,  1.1875,  0.4964],\n",
      "         [ 0.5916, -0.4055,  1.1698,  0.3862],\n",
      "         [ 0.3710, -0.4536,  1.1329,  0.2108]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0328, -1.9299, -0.2432,  0.4098],\n",
      "         [ 0.5713, -1.0302,  0.4102,  0.0673],\n",
      "         [ 0.5151, -0.6523,  0.8563,  0.5133],\n",
      "         ...,\n",
      "         [ 0.7837, -0.2356,  1.2311,  0.1234],\n",
      "         [ 0.9168, -0.0267,  1.2503, -0.1358],\n",
      "         [ 0.6555, -0.1222,  1.2033, -0.2459]],\n",
      "\n",
      "        [[ 0.4026,  0.1034,  1.7484,  1.4051],\n",
      "         [ 1.0590,  0.6650,  1.5569, -0.1431],\n",
      "         [ 0.8290,  0.6345,  1.7440,  0.0361],\n",
      "         ...,\n",
      "         [ 0.5797,  0.4523,  1.1650, -0.1530],\n",
      "         [ 0.6555,  0.3691,  1.1505, -0.1704],\n",
      "         [ 0.6929,  0.5174,  1.0569, -0.1350]],\n",
      "\n",
      "        [[ 1.1099, -0.1306,  1.0637, -0.2751],\n",
      "         [ 1.0053, -1.2431,  1.0622, -0.1658],\n",
      "         [ 0.6588, -1.2212,  0.8973,  0.8366],\n",
      "         ...,\n",
      "         [ 0.7495, -0.3717,  1.2590,  0.6048],\n",
      "         [ 0.6471, -0.5943,  1.0444,  0.5769],\n",
      "         [ 0.7050, -0.5363,  1.0468,  0.4704]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = torch.zeros(size=(T, T)) # zeros just so there's a plaaceholder for masked_fill\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\")) # whenever the value in tril is 0, it will get replaced with -inf; this allows softmax to come into place, since -inf will get a percent of 0\n",
    "wei = torch.softmax(wei, dim=1)\n",
    "print(wei)\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3b982",
   "metadata": {
    "papermill": {
     "duration": 0.019518,
     "end_time": "2024-07-09T20:12:40.764918",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.745400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLP model with agreggation\n",
    "- a problem that needs to be addressed with the previous model is that it needs to always receive a input of B x T (batch_size by context_size), whereas it would be best if the model could adapt to inputs of different context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9457d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.805510Z",
     "iopub.status.busy": "2024-07-09T20:12:40.805115Z",
     "iopub.status.idle": "2024-07-09T20:12:40.816122Z",
     "shell.execute_reply": "2024-07-09T20:12:40.814970Z"
    },
    "papermill": {
     "duration": 0.033874,
     "end_time": "2024-07-09T20:12:40.818456",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.784582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.4853e-02, -6.0513e-01, -2.6979e-01,  2.9367e-01,  7.4300e-03],\n",
      "         [-3.3273e-01, -1.6956e-01,  4.8027e-02,  4.6598e-01, -3.2772e-02],\n",
      "         [-6.6604e-01, -2.3695e-01,  5.4108e-01,  3.2967e-01,  4.6265e-01],\n",
      "         ...,\n",
      "         [ 1.8625e-01, -3.9044e-01,  2.9101e-01,  4.7646e-02,  3.3985e-01],\n",
      "         [ 1.8139e-01, -6.1906e-02,  2.4004e-01, -4.8740e-02,  2.6888e-01],\n",
      "         [-3.0426e-02, -9.8348e-02,  2.8390e-01, -1.2465e-01,  5.6283e-01]],\n",
      "\n",
      "        [[-1.1765e+00, -5.0294e-01,  5.0863e-01,  1.0011e+00, -2.8166e-01],\n",
      "         [-1.1570e+00, -9.9522e-01, -1.4237e-01,  6.8389e-01, -7.8292e-01],\n",
      "         [-9.4526e-01, -1.1017e+00, -7.5666e-01, -1.4278e-02, -5.6260e-01],\n",
      "         ...,\n",
      "         [ 1.3102e-01, -3.8917e-01, -2.3491e-01,  2.7016e-01,  2.8503e-02],\n",
      "         [ 1.2854e-01, -3.7960e-01, -1.2848e-01,  1.2805e-01, -2.0101e-01],\n",
      "         [ 2.4634e-01, -3.9867e-01, -9.3902e-02,  3.1972e-01, -4.4178e-02]],\n",
      "\n",
      "        [[-3.8941e-02, -4.2473e-01,  8.4499e-01, -1.9319e-01,  9.9824e-01],\n",
      "         [ 1.0005e+00,  1.1027e-01,  3.2524e-01, -1.2179e-01,  5.9850e-01],\n",
      "         [ 1.1692e-01, -1.4882e-01,  3.7250e-01, -1.9481e-02,  1.8488e-01],\n",
      "         ...,\n",
      "         [-6.5614e-01, -4.1519e-01, -3.3839e-01, -3.2210e-02, -4.1782e-02],\n",
      "         [-4.9639e-01, -5.0898e-01, -4.6826e-01, -9.3510e-02,  2.9555e-01],\n",
      "         [-4.5017e-01, -5.3668e-01, -3.0472e-01, -2.3752e-02,  2.2262e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0635e-01,  2.4224e-01, -1.6392e-01, -2.8124e-01,  2.8746e+00],\n",
      "         [ 6.8805e-02, -5.3077e-01,  9.1258e-02, -9.4266e-01,  6.1447e-01],\n",
      "         [ 5.4823e-01, -4.3012e-01, -7.5994e-02, -5.3937e-01, -3.1396e-01],\n",
      "         ...,\n",
      "         [ 3.5220e-01,  2.8445e-01, -7.9365e-02,  2.0775e-01, -4.3887e-01],\n",
      "         [ 4.5323e-01, -2.2995e-02, -1.4482e-02,  5.0371e-01, -5.9080e-01],\n",
      "         [ 3.0121e-01, -2.6561e-01, -4.4880e-04,  5.5069e-01, -5.0051e-01]],\n",
      "\n",
      "        [[ 6.8432e-01,  1.8122e-01,  1.2284e+00,  8.6172e-02, -9.2107e-01],\n",
      "         [ 1.6298e+00,  7.5482e-01,  1.1940e+00, -1.5586e-01,  1.3522e-01],\n",
      "         [ 6.3565e-01,  2.2166e-01,  7.5465e-01,  4.0535e-01,  1.6817e-01],\n",
      "         ...,\n",
      "         [ 7.8275e-01,  1.3723e-01,  5.9658e-01, -1.2132e-01, -5.3779e-01],\n",
      "         [ 6.9683e-01,  1.0534e-01,  4.9425e-01, -2.5320e-01, -1.0879e-01],\n",
      "         [ 6.3233e-01,  1.3497e-01,  2.5872e-01, -4.3644e-01, -5.8002e-02]],\n",
      "\n",
      "        [[-4.0025e-01,  1.0844e+00,  4.8516e-01,  9.8032e-01, -1.2068e+00],\n",
      "         [-5.0199e-01,  5.8907e-01,  4.9590e-01,  3.1724e-01, -1.8662e-01],\n",
      "         [-6.7396e-02,  6.5917e-01,  3.0679e-01, -1.8660e-02, -2.9385e-01],\n",
      "         ...,\n",
      "         [ 2.0461e-01,  1.6617e-01,  3.9129e-02,  3.4407e-01, -1.6102e-01],\n",
      "         [ 2.3718e-01,  1.8497e-01, -2.6047e-02,  3.7363e-01, -4.5902e-02],\n",
      "         [ 1.1276e-01,  1.8943e-01, -2.0066e-01,  4.1959e-01,  9.6439e-02]]])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "C = n_embd\n",
    "T = context_size\n",
    "B = batch_size\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "print(xbow @ test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faf80306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.860708Z",
     "iopub.status.busy": "2024-07-09T20:12:40.860325Z",
     "iopub.status.idle": "2024-07-09T20:12:40.868011Z",
     "shell.execute_reply": "2024-07-09T20:12:40.866688Z"
    },
    "papermill": {
     "duration": 0.032041,
     "end_time": "2024-07-09T20:12:40.870263",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.838222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "# a problem that needs to be addressed with the previous model is that it needs to always receive a \n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "print(batch_sample_inputs.shape)\n",
    "print(batch_sample_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3daf2085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.911979Z",
     "iopub.status.busy": "2024-07-09T20:12:40.911531Z",
     "iopub.status.idle": "2024-07-09T20:12:40.923475Z",
     "shell.execute_reply": "2024-07-09T20:12:40.922333Z"
    },
    "papermill": {
     "duration": 0.035706,
     "end_time": "2024-07-09T20:12:40.926019",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.890313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        #logits = self.lm_head(token_emb.view(B*T, C)) # output of shape B*T x hidden_units1; this might be a problem for the labels since they are of shape B x T, thus they need to be reshaped aswell\n",
    "        x = self.act_fn(self.linear1(token_emb.view(B*T, C))) # hidden_units1 x hidden_units2\n",
    "        x = self.act_fn(self.linear2(x)) # hidden_units2 x hidden_units3\n",
    "        x = self.linear3(x) # hidden_units3 x vocab_size\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cd6200e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:40.967800Z",
     "iopub.status.busy": "2024-07-09T20:12:40.967436Z",
     "iopub.status.idle": "2024-07-09T20:12:40.975086Z",
     "shell.execute_reply": "2024-07-09T20:12:40.974015Z"
    },
    "papermill": {
     "duration": 0.031599,
     "end_time": "2024-07-09T20:12:40.977487",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.945888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2 = MLPv2(vocab_size=vocab_size, n_embd=32, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90d8bd74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.022169Z",
     "iopub.status.busy": "2024-07-09T20:12:41.021721Z",
     "iopub.status.idle": "2024-07-09T20:12:41.031308Z",
     "shell.execute_reply": "2024-07-09T20:12:41.030034Z"
    },
    "papermill": {
     "duration": 0.036124,
     "end_time": "2024-07-09T20:12:41.034289",
     "exception": false,
     "start_time": "2024-07-09T20:12:40.998165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpv2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da690315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.077883Z",
     "iopub.status.busy": "2024-07-09T20:12:41.077504Z",
     "iopub.status.idle": "2024-07-09T20:12:41.089601Z",
     "shell.execute_reply": "2024-07-09T20:12:41.088332Z"
    },
    "papermill": {
     "duration": 0.036395,
     "end_time": "2024-07-09T20:12:41.092358",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.055963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([26, 33, 31, 10,  0, 20, 43, 52])\n",
      "tensor([[33, 31, 10,  0, 20, 43, 52, 41]])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8])\n",
      "tensor(4.1236)\n"
     ]
    }
   ],
   "source": [
    "mlpv2_loss_fn = nn.CrossEntropyLoss()\n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "sample_input = batch_sample_inputs[0]\n",
    "sample_label = batch_sample_labels[0]\n",
    "print(sample_input) # 1 x T (B x T)\n",
    "print(sample_label.view(1, -1)) # 1 x T (B x T)\n",
    "mlpv2.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = mlpv2(sample_input.view(1, -1))\n",
    "    labels = sample_label.view(-1) # from B x T to B*T to match the shape of the logits\n",
    "    print(logits.shape) # B*T x vocab_size\n",
    "    print(labels.shape)\n",
    "\n",
    "    loss = mlpv2_loss_fn(logits, labels)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99079a87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.136649Z",
     "iopub.status.busy": "2024-07-09T20:12:41.135766Z",
     "iopub.status.idle": "2024-07-09T20:12:41.143170Z",
     "shell.execute_reply": "2024-07-09T20:12:41.142010Z"
    },
    "papermill": {
     "duration": 0.032406,
     "end_time": "2024-07-09T20:12:41.145490",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.113084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def generate_from_model(model, num_outputs, starting_char, max_length):\n",
    "    mlpv2.eval()\n",
    "    outputs = []\n",
    "    starting_idx = torch.tensor([stoi[starting_char]], dtype=torch.long).view(1, -1)\n",
    "    for i in range(num_outputs):\n",
    "        output = mlpv2.generate(starting_idx=starting_idx, max_length=max_length) # must be batched\n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d5375d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.187786Z",
     "iopub.status.busy": "2024-07-09T20:12:41.187397Z",
     "iopub.status.idle": "2024-07-09T20:12:41.198427Z",
     "shell.execute_reply": "2024-07-09T20:12:41.197251Z"
    },
    "papermill": {
     "duration": 0.035294,
     "end_time": "2024-07-09T20:12:41.200960",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.165666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aOzrxA\n"
     ]
    }
   ],
   "source": [
    "test_output = generate_from_model(model=mlpv2, num_outputs=1, starting_char=\"a\", max_length=5)\n",
    "print(test_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3598d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.244211Z",
     "iopub.status.busy": "2024-07-09T20:12:41.243825Z",
     "iopub.status.idle": "2024-07-09T20:12:41.250906Z",
     "shell.execute_reply": "2024-07-09T20:12:41.249781Z"
    },
    "papermill": {
     "duration": 0.032611,
     "end_time": "2024-07-09T20:12:41.253835",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.221224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            if batch % 1200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08dcc2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.296959Z",
     "iopub.status.busy": "2024-07-09T20:12:41.296569Z",
     "iopub.status.idle": "2024-07-09T20:12:41.302484Z",
     "shell.execute_reply": "2024-07-09T20:12:41.301298Z"
    },
    "papermill": {
     "duration": 0.030473,
     "end_time": "2024-07-09T20:12:41.304967",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.274494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2_optimizer = torch.optim.Adam(params=mlpv2.parameters(), lr=1e-3)\n",
    "mlpv2_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "646f92e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:12:41.349737Z",
     "iopub.status.busy": "2024-07-09T20:12:41.348850Z",
     "iopub.status.idle": "2024-07-09T20:13:26.062905Z",
     "shell.execute_reply": "2024-07-09T20:13:26.061673Z"
    },
    "papermill": {
     "duration": 44.740351,
     "end_time": "2024-07-09T20:13:26.065822",
     "exception": false,
     "start_time": "2024-07-09T20:12:41.325471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.199133396148682 at epoch 0\n",
      "loss for batch 1200 --> 2.527355909347534 at epoch 0\n",
      "loss for batch 2400 --> 2.313702344894409 at epoch 0\n",
      "loss for batch 0 --> 2.3813376426696777 at epoch 1\n",
      "loss for batch 1200 --> 2.50433611869812 at epoch 1\n",
      "loss for batch 2400 --> 2.310081720352173 at epoch 1\n",
      "loss for batch 0 --> 2.3805489540100098 at epoch 2\n",
      "loss for batch 1200 --> 2.4978551864624023 at epoch 2\n",
      "loss for batch 2400 --> 2.3088157176971436 at epoch 2\n",
      "loss for batch 0 --> 2.379178047180176 at epoch 3\n",
      "loss for batch 1200 --> 2.49359130859375 at epoch 3\n",
      "loss for batch 2400 --> 2.3069968223571777 at epoch 3\n",
      "loss for the very last batch --> 2.4351465702056885\n"
     ]
    }
   ],
   "source": [
    "train_model(model=mlpv2, dataloader=train_dataloader, loss_fn=mlpv2_loss_fn, optimizer=mlpv2_optimizer, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5056497e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.115846Z",
     "iopub.status.busy": "2024-07-09T20:13:26.115454Z",
     "iopub.status.idle": "2024-07-09T20:13:26.184679Z",
     "shell.execute_reply": "2024-07-09T20:13:26.183645Z"
    },
    "papermill": {
     "duration": 0.096729,
     "end_time": "2024-07-09T20:13:26.187111",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.090382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bene pr ve COr!\n",
      "Hesth,\n",
      "A y!\n",
      "\n",
      "\n",
      "Ongele\n",
      "BRo'd tomo' wiu:\n",
      "Tanowofoumonot miff h\n",
      "Fo e,\n",
      "Fie?\n",
      "Hedivedr bo, h\n",
      "\n",
      "\n",
      "beoncode ierond lintouthutace hivo ss hicanead, avegsorou oouly serkendeincingeng uth\n",
      "Thelle y thinfr\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_outputs = generate_from_model(model=mlpv2, max_length=100, num_outputs=2, starting_char=\"b\")\n",
    "for output in test_outputs:\n",
    "    print(f\"{output}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac658177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.234000Z",
     "iopub.status.busy": "2024-07-09T20:13:26.233549Z",
     "iopub.status.idle": "2024-07-09T20:13:26.241603Z",
     "shell.execute_reply": "2024-07-09T20:13:26.240491Z"
    },
    "papermill": {
     "duration": 0.035212,
     "end_time": "2024-07-09T20:13:26.244008",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.208796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=T, step=1) # from 0 to T-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d8163",
   "metadata": {
    "papermill": {
     "duration": 0.021755,
     "end_time": "2024-07-09T20:13:26.287886",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.266131",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention\n",
    "- with xbow you can add information about the tokens, but the model itself does not attribute any weight to them. This is what self attention solves by using Keys, Queries and Values\n",
    "- every token will have a specific Query (Q) and Key (K) attatched to it\n",
    "    - Query --> what the model is looking for\n",
    "    - Key --> the weight the model is giving to this certain token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "537c6f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.333674Z",
     "iopub.status.busy": "2024-07-09T20:13:26.333275Z",
     "iopub.status.idle": "2024-07-09T20:13:26.342142Z",
     "shell.execute_reply": "2024-07-09T20:13:26.340776Z"
    },
    "papermill": {
     "duration": 0.034502,
     "end_time": "2024-07-09T20:13:26.344698",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.310196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "\n",
    "B, T, C = 2, 4, 8\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "output = xbow @ test_tensor\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "794668d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.393502Z",
     "iopub.status.busy": "2024-07-09T20:13:26.393095Z",
     "iopub.status.idle": "2024-07-09T20:13:26.402004Z",
     "shell.execute_reply": "2024-07-09T20:13:26.400596Z"
    },
    "papermill": {
     "duration": 0.036553,
     "end_time": "2024-07-09T20:13:26.404420",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.367867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32])\n",
      "torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "head_size = 32\n",
    "key = nn.Linear(in_features=C, out_features=head_size, bias=False) # bias = False so that it's just a multiplication\n",
    "query = nn.Linear(in_features=C, out_features=head_size, bias=False) \n",
    "\n",
    "#print(test_tensor.shape)\n",
    "k = key(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a key value\n",
    "q = query(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a query value\n",
    "print(k.shape)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ece9cd95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.450519Z",
     "iopub.status.busy": "2024-07-09T20:13:26.450166Z",
     "iopub.status.idle": "2024-07-09T20:13:26.459677Z",
     "shell.execute_reply": "2024-07-09T20:13:26.458565Z"
    },
    "papermill": {
     "duration": 0.035332,
     "end_time": "2024-07-09T20:13:26.461922",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.426590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(k.transpose(-2, -1).shape) # same as k.permute(0, 2, 1)\n",
    "print(k.permute(0, 2, 1).shape)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "print(wei.shape) #  B x T x T\n",
    "\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1) # dim=-1 in this case, since wei is of shape\n",
    "\n",
    "output = wei @ test_tensor\n",
    "\n",
    "print(output.shape) # B x T x C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb0e1b",
   "metadata": {
    "papermill": {
     "duration": 0.021299,
     "end_time": "2024-07-09T20:13:26.505077",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.483778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Update the model with a self attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc41a153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.553661Z",
     "iopub.status.busy": "2024-07-09T20:13:26.553279Z",
     "iopub.status.idle": "2024-07-09T20:13:26.561805Z",
     "shell.execute_reply": "2024-07-09T20:13:26.560633Z"
    },
    "papermill": {
     "duration": 0.036991,
     "end_time": "2024-07-09T20:13:26.564201",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.527210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.Q = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "        #mask = torch.tril(torch.ones(size=(T, T)))\n",
    "\n",
    "        q = self.Q(x) # B x T x head_size\n",
    "        k = self.K(x) # B x T x head_size\n",
    "        v = self.V(x) # B x T x head_size\n",
    "\n",
    "        k = k.transpose(-2, -1) # B x head_size x T\n",
    "\n",
    "        wei = q @ k # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "\n",
    "        wei = wei.masked_fill(mask==0, float('-inf'))\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "\n",
    "        #x = wei @ v # BxTxT @ BxTxhead_size --> BxTxhead_size\n",
    "        x = wei @ x\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dffacf49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.611831Z",
     "iopub.status.busy": "2024-07-09T20:13:26.611343Z",
     "iopub.status.idle": "2024-07-09T20:13:26.624152Z",
     "shell.execute_reply": "2024-07-09T20:13:26.622972Z"
    },
    "papermill": {
     "duration": 0.039454,
     "end_time": "2024-07-09T20:13:26.626783",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.587329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv3(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super(MLPv3, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        self.head = Head(head_size=32, n_embd=n_embd)\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "        self.mask = torch.tril(torch.ones(size=(context_size, context_size)))\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.head(x, self.mask)\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21f85708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.674433Z",
     "iopub.status.busy": "2024-07-09T20:13:26.674037Z",
     "iopub.status.idle": "2024-07-09T20:13:26.688863Z",
     "shell.execute_reply": "2024-07-09T20:13:26.687693Z"
    },
    "papermill": {
     "duration": 0.041793,
     "end_time": "2024-07-09T20:13:26.691422",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.649629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 32\n",
    "mlpv3 = MLPv3(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size)\n",
    "mlpv3.optimizer = torch.optim.Adam(params=mlpv3.parameters(), lr=1e-2)\n",
    "mlpv3_loss_fn = nn.CrossEntropyLoss()\n",
    "mlpv3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6a72d82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.740223Z",
     "iopub.status.busy": "2024-07-09T20:13:26.739055Z",
     "iopub.status.idle": "2024-07-09T20:13:26.878290Z",
     "shell.execute_reply": "2024-07-09T20:13:26.877040Z"
    },
    "papermill": {
     "duration": 0.166584,
     "end_time": "2024-07-09T20:13:26.881145",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.714561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ate. wourkerd ty thad t; leese bue ozer y an whicakesodeanermorthemes!\n",
      "Burboun\n",
      "CIUS:\n",
      "Whidour he y ve thaghif winothatatoun arcepl:\n",
      "TInteby  m, t o.\n",
      "Ber,\n",
      "\n",
      "Cock d whe d thi'twe hons teounst ly TIUThemout \n",
      "\n",
      "\n",
      "and pl\n",
      "When\n",
      "Fig wing sf mitopl bef nimbreane\n",
      "A: rt\n",
      "LewheathUS:\n",
      "A ans,\n",
      "DIlenwerarthar asu, d y loien adideqush ce t Co sif as-\n",
      "\n",
      "Beaverofru f tye t anors empin.\n",
      "s by tom's.\n",
      "The nongeleitomy cteme\n",
      "Wey g\n",
      "\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "193dfdf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.927712Z",
     "iopub.status.busy": "2024-07-09T20:13:26.927311Z",
     "iopub.status.idle": "2024-07-09T20:13:26.932517Z",
     "shell.execute_reply": "2024-07-09T20:13:26.931367Z"
    },
    "papermill": {
     "duration": 0.031079,
     "end_time": "2024-07-09T20:13:26.934795",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.903716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_model(model=mlpv3, dataloader=train_dataloader, loss_fn=mlpv3_loss_fn, optimizer=mlpv2_optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4c45ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T20:13:26.982758Z",
     "iopub.status.busy": "2024-07-09T20:13:26.982370Z",
     "iopub.status.idle": "2024-07-09T20:13:27.112580Z",
     "shell.execute_reply": "2024-07-09T20:13:27.111139Z"
    },
    "papermill": {
     "duration": 0.157789,
     "end_time": "2024-07-09T20:13:27.115185",
     "exception": false,
     "start_time": "2024-07-09T20:13:26.957396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astharty boe ouves fanon:\n",
      "Corcowofofrilours leashe\n",
      "Fime be st:\n",
      "MEnorestusestt\n",
      "SI thall\n",
      "Therecothad alesonwnluthamy. thakeny ces' f heronomatithe in. to' irinete pe t jur set?\n",
      "MNENI gellenvis.\n",
      "Th lt ld  \n",
      "\n",
      "\n",
      "atoursin m o un athe tivenke be more t f hom, oid ce, otititcoondincatheatobonelom IUS:\n",
      "A:\n",
      "Twn nathik.\n",
      "Finith t ther wn:\n",
      "As foue eswizep,\n",
      "ORUS:\n",
      "S: mears.\n",
      "Shelld bor hiseale ff sat t'a ot\n",
      "yor seatoute,  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2eadf7",
   "metadata": {
    "papermill": {
     "duration": 0.022438,
     "end_time": "2024-07-09T20:13:27.160917",
     "exception": false,
     "start_time": "2024-07-09T20:13:27.138479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self-attetion x cross-attention\n",
    "- in self-attention the values for queries (Q), keys (K) and values (V) all come from x itself, thus self-attention\n",
    "- in cross-attention those values can come from somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8de369",
   "metadata": {
    "papermill": {
     "duration": 0.023487,
     "end_time": "2024-07-09T20:13:27.207270",
     "exception": false,
     "start_time": "2024-07-09T20:13:27.183783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5339176,
     "sourceId": 8871363,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 72.215264,
   "end_time": "2024-07-09T20:13:28.254427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T20:12:16.039163",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
