{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fc2b20",
   "metadata": {
    "papermill": {
     "duration": 0.011424,
     "end_time": "2024-07-09T19:15:56.982799",
     "exception": false,
     "start_time": "2024-07-09T19:15:56.971375",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction (WIP)\n",
    "- This notebook is based on the \"Let's build GPT: from scratch, in code, spelled out\" tutorial by Andrej Karpathy. You can find the tutorial here --> https://www.youtube.com/watch?v=kCc8FmEb1nY&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=7\n",
    "- There are several different approaches in this notebook that do not strictly follow the original video. Some implementations are my own.\n",
    "- I am using the same shakespeare text as in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2152b3",
   "metadata": {
    "papermill": {
     "duration": 0.01303,
     "end_time": "2024-07-09T19:15:57.011751",
     "exception": false,
     "start_time": "2024-07-09T19:15:56.998721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f7c09d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:15:57.040594Z",
     "iopub.status.busy": "2024-07-09T19:15:57.039354Z",
     "iopub.status.idle": "2024-07-09T19:16:00.707617Z",
     "shell.execute_reply": "2024-07-09T19:16:00.706415Z"
    },
    "papermill": {
     "duration": 3.686315,
     "end_time": "2024-07-09T19:16:00.710684",
     "exception": false,
     "start_time": "2024-07-09T19:15:57.024369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca5ab63",
   "metadata": {
    "papermill": {
     "duration": 0.011132,
     "end_time": "2024-07-09T19:16:00.732997",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.721865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Device agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ac567d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:00.758000Z",
     "iopub.status.busy": "2024-07-09T19:16:00.757003Z",
     "iopub.status.idle": "2024-07-09T19:16:00.765664Z",
     "shell.execute_reply": "2024-07-09T19:16:00.764481Z"
    },
    "papermill": {
     "duration": 0.023389,
     "end_time": "2024-07-09T19:16:00.768054",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.744665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "generator = torch.Generator(device=device)\n",
    "print(f\"default device set to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac32f9",
   "metadata": {
    "papermill": {
     "duration": 0.010667,
     "end_time": "2024-07-09T19:16:00.789859",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.779192",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31c609d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:00.814397Z",
     "iopub.status.busy": "2024-07-09T19:16:00.813944Z",
     "iopub.status.idle": "2024-07-09T19:16:00.856249Z",
     "shell.execute_reply": "2024-07-09T19:16:00.854789Z"
    },
    "papermill": {
     "duration": 0.05766,
     "end_time": "2024-07-09T19:16:00.858655",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.800995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "with open(\"/kaggle/input/shakespeare/input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677d18a",
   "metadata": {
    "papermill": {
     "duration": 0.010919,
     "end_time": "2024-07-09T19:16:00.880821",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.869902",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdaeacf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:00.905028Z",
     "iopub.status.busy": "2024-07-09T19:16:00.904644Z",
     "iopub.status.idle": "2024-07-09T19:16:00.911596Z",
     "shell.execute_reply": "2024-07-09T19:16:00.910312Z"
    },
    "papermill": {
     "duration": 0.022149,
     "end_time": "2024-07-09T19:16:00.914084",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.891935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "stoi = {c: v for v, c in enumerate(vocab)}\n",
    "itos = {v: c for c, v in stoi.items()}\n",
    "print(stoi[\"h\"])\n",
    "print(itos[46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f586230a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:00.939440Z",
     "iopub.status.busy": "2024-07-09T19:16:00.938851Z",
     "iopub.status.idle": "2024-07-09T19:16:00.946098Z",
     "shell.execute_reply": "2024-07-09T19:16:00.944905Z"
    },
    "papermill": {
     "duration": 0.023247,
     "end_time": "2024-07-09T19:16:00.948780",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.925533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 6, 1, 46, 53, 61, 1, 39, 56, 43, 1, 63, 53, 59, 12, 2]\n",
      "hello, how are you?!\n"
     ]
    }
   ],
   "source": [
    "encode = lambda d: [stoi[idx] for idx in d]\n",
    "decode = lambda e: \"\".join([itos[idx] for idx in e])\n",
    "\n",
    "encoded = encode(\"hello, how are you?!\")\n",
    "decoded = decode(encoded)\n",
    "print(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5f837",
   "metadata": {
    "papermill": {
     "duration": 0.011353,
     "end_time": "2024-07-09T19:16:00.972022",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.960669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ccc678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:00.996915Z",
     "iopub.status.busy": "2024-07-09T19:16:00.996534Z",
     "iopub.status.idle": "2024-07-09T19:16:01.001860Z",
     "shell.execute_reply": "2024-07-09T19:16:01.000628Z"
    },
    "papermill": {
     "duration": 0.020625,
     "end_time": "2024-07-09T19:16:01.004348",
     "exception": false,
     "start_time": "2024-07-09T19:16:00.983723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_size = 8\n",
    "n_embd = 5\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee6d1100",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:01.029039Z",
     "iopub.status.busy": "2024-07-09T19:16:01.028655Z",
     "iopub.status.idle": "2024-07-09T19:16:01.035260Z",
     "shell.execute_reply": "2024-07-09T19:16:01.034176Z"
    },
    "papermill": {
     "duration": 0.02155,
     "end_time": "2024-07-09T19:16:01.037478",
     "exception": false,
     "start_time": "2024-07-09T19:16:01.015928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dataset(text, context_size):\n",
    "    data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "    #random_idx = torch.randint(0, len(data)-context_size, (int(len(data)/context_size),))\n",
    "    random_idx = torch.randperm(len(data)-context_size)\n",
    "    inputs = torch.stack([data[idx:idx+context_size] for idx in random_idx])\n",
    "    labels = torch.stack([data[idx+1:idx+context_size+1] for idx in random_idx])\n",
    "\n",
    "    return TensorDataset(inputs, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58d6e6dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:01.063030Z",
     "iopub.status.busy": "2024-07-09T19:16:01.062626Z",
     "iopub.status.idle": "2024-07-09T19:16:01.129983Z",
     "shell.execute_reply": "2024-07-09T19:16:01.128651Z"
    },
    "papermill": {
     "duration": 0.083643,
     "end_time": "2024-07-09T19:16:01.132608",
     "exception": false,
     "start_time": "2024-07-09T19:16:01.048965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 7, 5, 7, 9, 3, 1, 3, 4, 1])\n",
      "tensor([5, 2, 4, 1, 7, 3, 6, 8, 9, 0])\n"
     ]
    }
   ],
   "source": [
    "# sicne randint might give the same random_idx, randperm is going to be preffered\n",
    "print(torch.randint(0, 10, (10,)))\n",
    "print(torch.randperm(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5d5bc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:01.159728Z",
     "iopub.status.busy": "2024-07-09T19:16:01.159321Z",
     "iopub.status.idle": "2024-07-09T19:16:07.330543Z",
     "shell.execute_reply": "2024-07-09T19:16:07.329138Z"
    },
    "papermill": {
     "duration": 6.188504,
     "end_time": "2024-07-09T19:16:07.333506",
     "exception": false,
     "start_time": "2024-07-09T19:16:01.145002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = make_dataset(text=text[:100000], context_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27678b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:07.358933Z",
     "iopub.status.busy": "2024-07-09T19:16:07.358555Z",
     "iopub.status.idle": "2024-07-09T19:16:07.370466Z",
     "shell.execute_reply": "2024-07-09T19:16:07.369386Z"
    },
    "papermill": {
     "duration": 0.028294,
     "end_time": "2024-07-09T19:16:07.373606",
     "exception": false,
     "start_time": "2024-07-09T19:16:07.345312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_split = int(len(dataset)*0.8)\n",
    "test_split = int(len(dataset)-train_split)\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset=dataset, lengths=[train_split, test_split], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76c3f5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:07.400724Z",
     "iopub.status.busy": "2024-07-09T19:16:07.400328Z",
     "iopub.status.idle": "2024-07-09T19:16:07.406281Z",
     "shell.execute_reply": "2024-07-09T19:16:07.405205Z"
    },
    "papermill": {
     "duration": 0.022064,
     "end_time": "2024-07-09T19:16:07.408548",
     "exception": false,
     "start_time": "2024-07-09T19:16:07.386484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, generator=generator)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7fd893",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:07.434016Z",
     "iopub.status.busy": "2024-07-09T19:16:07.433622Z",
     "iopub.status.idle": "2024-07-09T19:16:07.438960Z",
     "shell.execute_reply": "2024-07-09T19:16:07.437954Z"
    },
    "papermill": {
     "duration": 0.020859,
     "end_time": "2024-07-09T19:16:07.441279",
     "exception": false,
     "start_time": "2024-07-09T19:16:07.420420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_from_data(dataloader):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        #print(f\"batch {batch}, input {X}, label {y}\")\n",
    "        #print(batch)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865330c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:07.467059Z",
     "iopub.status.busy": "2024-07-09T19:16:07.466172Z",
     "iopub.status.idle": "2024-07-09T19:16:08.127850Z",
     "shell.execute_reply": "2024-07-09T19:16:08.126453Z"
    },
    "papermill": {
     "duration": 0.677661,
     "end_time": "2024-07-09T19:16:08.130829",
     "exception": false,
     "start_time": "2024-07-09T19:16:07.453168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_from_data(dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35de713",
   "metadata": {
    "papermill": {
     "duration": 0.011532,
     "end_time": "2024-07-09T19:16:08.154344",
     "exception": false,
     "start_time": "2024-07-09T19:16:08.142812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64e354e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:08.180263Z",
     "iopub.status.busy": "2024-07-09T19:16:08.179858Z",
     "iopub.status.idle": "2024-07-09T19:16:08.193348Z",
     "shell.execute_reply": "2024-07-09T19:16:08.191965Z"
    },
    "papermill": {
     "duration": 0.02951,
     "end_time": "2024-07-09T19:16:08.195808",
     "exception": false,
     "start_time": "2024-07-09T19:16:08.166298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, context_size, n_embd, vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.context_size = context_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd) # B x T x C; B --> batches, T --> time (context_size), C --> n_embd\n",
    "        self.pos_embedding_table = nn.Embedding(context_size, n_embd) # T x C; this is from the posisitional encoding part of the video\n",
    "        \n",
    "        self.linear1 = nn.Linear(in_features=context_size*n_embd, out_features=8*8) # B x T*C @ T*C x H; H --> number of hidden_units\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def forward(self, idx: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = idx.shape\n",
    "        C = self.n_embd\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        x = self.token_embedding_table(idx) + self.pos_embedding_table(positions)\n",
    "        x = x.view(B, T*C)\n",
    "\n",
    "        x = self.act_fn(self.linear1(x))\n",
    "        x = self.act_fn(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, idx: torch.Tensor, randomize: bool, max_length: int, num_samples: int) -> torch.Tensor:\n",
    "        outputs = []\n",
    "        for sample in range(num_samples):\n",
    "            full_text = \"\" \n",
    "            for i in range(max_length):\n",
    "                logits = self(idx)\n",
    "                percents = torch.softmax(logits, dim=1)\n",
    "\n",
    "                if randomize:\n",
    "                    pred = torch.multinomial(percents, num_samples=1)\n",
    "                    full_text += decode(pred.tolist()[0])\n",
    "                    idx = torch.cat([idx[:, 1:], pred], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                else:\n",
    "                    pred = torch.argmax(percents)\n",
    "                    full_text += decode([pred.item()])\n",
    "                    idx = torch.cat([idx[:, 1:], pred.view(1, 1)], dim=1) # update the context, remove the first element of the tensor and add the new prediction made by the model\n",
    "                    # in the argmax the output is a single element, pred.view(1, 1) turns it into a batch of dim 1, so it can be concatenated to the previous context\n",
    "\n",
    "            outputs.append(full_text)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ef3bf",
   "metadata": {
    "papermill": {
     "duration": 0.011982,
     "end_time": "2024-07-09T19:16:08.219889",
     "exception": false,
     "start_time": "2024-07-09T19:16:08.207907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the base model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05f64a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:08.303902Z",
     "iopub.status.busy": "2024-07-09T19:16:08.303507Z",
     "iopub.status.idle": "2024-07-09T19:16:09.733359Z",
     "shell.execute_reply": "2024-07-09T19:16:09.732175Z"
    },
    "papermill": {
     "duration": 1.504068,
     "end_time": "2024-07-09T19:16:09.735873",
     "exception": false,
     "start_time": "2024-07-09T19:16:08.231805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLP(context_size=context_size, n_embd=n_embd, vocab_size=vocab_size)\n",
    "optimizer = torch.optim.Adam(params=mlp.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf76142",
   "metadata": {
    "papermill": {
     "duration": 0.011589,
     "end_time": "2024-07-09T19:16:09.759648",
     "exception": false,
     "start_time": "2024-07-09T19:16:09.748059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Take samples from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9081bc96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:09.786034Z",
     "iopub.status.busy": "2024-07-09T19:16:09.784807Z",
     "iopub.status.idle": "2024-07-09T19:16:09.869059Z",
     "shell.execute_reply": "2024-07-09T19:16:09.867913Z"
    },
    "papermill": {
     "duration": 0.100402,
     "end_time": "2024-07-09T19:16:09.871989",
     "exception": false,
     "start_time": "2024-07-09T19:16:09.771587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOV,L\n",
      "ERH' \n",
      "\n",
      "\n",
      "ubyl$Fwizf \n",
      "\n",
      "\n",
      " z:z:ITQ:N \n",
      "\n",
      "\n",
      "r'qxW:I$'I \n",
      "\n",
      "\n",
      "LPVmD$yx,K \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad\n",
    "def model_sampler(model, context, randomize, max_length, num_samples):\n",
    "    #print(len(context))\n",
    "    #print(context_size)\n",
    "    test = torch.tensor([[20, 53, 61,  1, 39, 56, 58, 39]])\n",
    "    #print(test[:, 1:])\n",
    "    result = torch.cat((test[:, 1:], torch.tensor([[99]])), dim=1)\n",
    "    #print(result)\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    mlp.eval()\n",
    "    idx = torch.tensor(encode(context), dtype=torch.long).view(1, len(encode(context))) # inputs must be batched\n",
    "    outputs = mlp.generate(idx=idx, randomize=randomize, max_length=max_length, num_samples=num_samples)\n",
    "    for output in outputs:\n",
    "        print(f\"{output} \\n\\n\")\n",
    "\n",
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=10, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a749654",
   "metadata": {
    "papermill": {
     "duration": 0.011759,
     "end_time": "2024-07-09T19:16:09.896938",
     "exception": false,
     "start_time": "2024-07-09T19:16:09.885179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30b2983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:09.923571Z",
     "iopub.status.busy": "2024-07-09T19:16:09.923172Z",
     "iopub.status.idle": "2024-07-09T19:16:09.930711Z",
     "shell.execute_reply": "2024-07-09T19:16:09.929469Z"
    },
    "papermill": {
     "duration": 0.023469,
     "end_time": "2024-07-09T19:16:09.932976",
     "exception": false,
     "start_time": "2024-07-09T19:16:09.909507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in tqdm(enumerate(dataloader)):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y[:, -1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch % 200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "519cce5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:09.959835Z",
     "iopub.status.busy": "2024-07-09T19:16:09.959413Z",
     "iopub.status.idle": "2024-07-09T19:16:17.502748Z",
     "shell.execute_reply": "2024-07-09T19:16:17.501683Z"
    },
    "papermill": {
     "duration": 7.559953,
     "end_time": "2024-07-09T19:16:17.505721",
     "exception": false,
     "start_time": "2024-07-09T19:16:09.945768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.203449249267578 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "254it [00:00, 336.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 200 --> 3.1416616439819336 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [00:01, 336.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 400 --> 2.828216075897217 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "669it [00:02, 345.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 600 --> 2.7205810546875 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "844it [00:02, 328.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 800 --> 2.6857826709747314 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1055it [00:03, 342.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1000 --> 2.4109437465667725 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1257it [00:03, 304.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1200 --> 2.7299134731292725 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1462it [00:04, 335.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1400 --> 2.5381977558135986 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1668it [00:05, 325.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1600 --> 2.264328956604004 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1845it [00:05, 345.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 1800 --> 2.2220375537872314 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2057it [00:06, 343.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2000 --> 2.772373676300049 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2268it [00:06, 344.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2200 --> 2.3911831378936768 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2443it [00:07, 329.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 2400 --> 2.3883790969848633 at epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [00:07, 331.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for the very last batch --> 2.1770222187042236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.train()\n",
    "train_model(model=mlp, dataloader=train_dataloader, loss_fn=loss_fn, optimizer=optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431abc6",
   "metadata": {
    "papermill": {
     "duration": 0.017574,
     "end_time": "2024-07-09T19:16:17.542004",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.524430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Base model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6770e457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:17.582915Z",
     "iopub.status.busy": "2024-07-09T19:16:17.581957Z",
     "iopub.status.idle": "2024-07-09T19:16:17.588851Z",
     "shell.execute_reply": "2024-07-09T19:16:17.587589Z"
    },
    "papermill": {
     "duration": 0.029356,
     "end_time": "2024-07-09T19:16:17.591071",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.561715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def model_inference(model, dataloader):\n",
    "    mlp.eval()\n",
    "    X, y = next(iter(dataloader))\n",
    "    logits = model(X)\n",
    "    percents = torch.softmax(logits, dim=1) # dim=1 since the input was batched\n",
    "    preds = torch.argmax(percents, dim=1) # dim=1 since the input was batched\n",
    "    print(f\"for {X} \\n model predicted {preds}\")\n",
    "    print(f\"expected --> {y[:, -1]}\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9968e7ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:17.629576Z",
     "iopub.status.busy": "2024-07-09T19:16:17.628580Z",
     "iopub.status.idle": "2024-07-09T19:16:17.640571Z",
     "shell.execute_reply": "2024-07-09T19:16:17.639200Z"
    },
    "papermill": {
     "duration": 0.0336,
     "end_time": "2024-07-09T19:16:17.643091",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.609491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for tensor([[ 1, 58, 46, 43, 47, 56,  1, 54],\n",
      "        [ 1, 39, 50, 50,  1, 58, 53,  1],\n",
      "        [63, 53, 59,  1, 46, 43, 52, 41],\n",
      "        [56, 52, 47, 52, 45,  1, 49, 47],\n",
      "        [49,  1, 51, 43,  8,  1, 21,  6],\n",
      "        [ 0, 14, 30, 33, 32, 33, 31, 10],\n",
      "        [39, 57,  1, 53, 44, 58, 43, 52],\n",
      "        [46, 53, 56, 53, 59, 45, 46, 50],\n",
      "        [59, 50, 42,  1, 58, 46, 43, 63],\n",
      "        [54, 50, 59, 41, 49,  1, 53, 59],\n",
      "        [56, 43, 40, 59, 49, 43,  1, 63],\n",
      "        [58,  1, 44, 53, 56, 58, 46,  0],\n",
      "        [ 0, 25, 13, 30, 15, 21, 33, 31],\n",
      "        [ 0, 18, 53, 56,  1, 61, 46, 39],\n",
      "        [59, 57,  6,  1, 58, 53,  1, 39],\n",
      "        [46, 63,  1, 44, 56, 47, 43, 52],\n",
      "        [44,  1, 39, 45, 39, 47, 52,  6],\n",
      "        [43, 51,  0, 32, 47, 51, 43,  7],\n",
      "        [47, 59, 57,  1, 15, 53, 56, 47],\n",
      "        [39, 47, 52,  1, 59, 57,  1, 51],\n",
      "        [47, 56, 52, 43, 57, 57,  1, 53],\n",
      "        [55, 59, 43, 57, 58,  1, 63, 53],\n",
      "        [50, 50, 63,  1, 57, 51, 47, 50],\n",
      "        [43,  1, 46, 53, 51, 43,  6,  0],\n",
      "        [12,  0, 20, 53, 61,  1, 57, 46],\n",
      "        [46, 47, 51,  1, 39, 61, 39, 63],\n",
      "        [60, 43, 42,  1, 51, 63,  1, 50],\n",
      "        [58, 50, 43, 56,  6,  1, 58, 46],\n",
      "        [52, 42,  1, 15, 47, 58, 47, 64],\n",
      "        [ 1, 14, 59, 58,  0, 58, 46, 39],\n",
      "        [ 5, 58,  1, 39, 45, 39, 47, 52],\n",
      "        [53, 51, 43,  0, 20, 43, 56,  1]]) \n",
      " model predicted tensor([53, 58, 43, 58,  1,  0,  1,  1,  1, 57, 53, 31, 10, 58, 56,  1,  1, 10,\n",
      "        58, 43, 56, 59, 43,  0, 43,  1, 53, 43, 43, 58,  1, 58])\n",
      "expected --> tensor([53, 56, 43, 57,  1,  0,  1, 63,  1, 58, 53, 13, 10, 58, 50, 42,  0, 54,\n",
      "        53, 59, 44, 59, 43, 27, 39, 10, 47, 39, 43, 58,  7, 43])\n",
      "tensor([[58, 46, 43, 47, 56,  1, 54, 53],\n",
      "        [39, 50, 50,  1, 58, 53,  1, 56],\n",
      "        [53, 59,  1, 46, 43, 52, 41, 43],\n",
      "        [52, 47, 52, 45,  1, 49, 47, 57],\n",
      "        [ 1, 51, 43,  8,  1, 21,  6,  1],\n",
      "        [14, 30, 33, 32, 33, 31, 10,  0],\n",
      "        [57,  1, 53, 44, 58, 43, 52,  1],\n",
      "        [53, 56, 53, 59, 45, 46, 50, 63],\n",
      "        [50, 42,  1, 58, 46, 43, 63,  1],\n",
      "        [50, 59, 41, 49,  1, 53, 59, 58],\n",
      "        [43, 40, 59, 49, 43,  1, 63, 53],\n",
      "        [ 1, 44, 53, 56, 58, 46,  0, 13],\n",
      "        [25, 13, 30, 15, 21, 33, 31, 10],\n",
      "        [18, 53, 56,  1, 61, 46, 39, 58],\n",
      "        [57,  6,  1, 58, 53,  1, 39, 50],\n",
      "        [63,  1, 44, 56, 47, 43, 52, 42],\n",
      "        [ 1, 39, 45, 39, 47, 52,  6,  0],\n",
      "        [51,  0, 32, 47, 51, 43,  7, 54],\n",
      "        [59, 57,  1, 15, 53, 56, 47, 53],\n",
      "        [47, 52,  1, 59, 57,  1, 51, 59],\n",
      "        [56, 52, 43, 57, 57,  1, 53, 44],\n",
      "        [59, 43, 57, 58,  1, 63, 53, 59],\n",
      "        [50, 63,  1, 57, 51, 47, 50, 43],\n",
      "        [ 1, 46, 53, 51, 43,  6,  0, 27],\n",
      "        [ 0, 20, 53, 61,  1, 57, 46, 39],\n",
      "        [47, 51,  1, 39, 61, 39, 63, 10],\n",
      "        [43, 42,  1, 51, 63,  1, 50, 47],\n",
      "        [50, 43, 56,  6,  1, 58, 46, 39],\n",
      "        [42,  1, 15, 47, 58, 47, 64, 43],\n",
      "        [14, 59, 58,  0, 58, 46, 39, 58],\n",
      "        [58,  1, 39, 45, 39, 47, 52,  7],\n",
      "        [51, 43,  0, 20, 43, 56,  1, 43]])\n"
     ]
    }
   ],
   "source": [
    "model_inference(model=mlp, dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecf9fa89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:17.681429Z",
     "iopub.status.busy": "2024-07-09T19:16:17.680544Z",
     "iopub.status.idle": "2024-07-09T19:16:17.859510Z",
     "shell.execute_reply": "2024-07-09T19:16:17.858215Z"
    },
    "papermill": {
     "duration": 0.201799,
     "end_time": "2024-07-09T19:16:17.863019",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.661220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trd, int on thald co s, cut you m'd ink ioL\n",
      "\n",
      "VOalys ant matr th: youck it the mrle.\n",
      "\n",
      "ThabIL\n",
      "\n",
      "hithe t wheil theit meinld, pthas te of thplols: vill sil\n",
      " ingd t se hi to enr ursns, pilla,s thel oulbog\n",
      "\n",
      "Sld ou himCse Micou, ruoos thout pin te re'cut inq to cer ounirro: th m;\n",
      "Aaditn, brav.\n",
      "\n",
      "CORINIA:\n",
      "Lhaintt frowt iseger, uf r, yucimec:\n",
      "\n",
      "Fid tarv, boty then ous dese t oll yo vosila meat, bale ie'tarnevened,ere: sheod me as anlt tar heroms ined, rhak. I ce siverl:\n",
      "Nofa Ted. ehelpt aar of tr itus. toou \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_sampler(model=mlp, context=\"How are \", randomize=True, max_length=500, num_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9002e631",
   "metadata": {
    "papermill": {
     "duration": 0.018193,
     "end_time": "2024-07-09T19:16:17.899489",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.881296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db5ddf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:17.940027Z",
     "iopub.status.busy": "2024-07-09T19:16:17.939657Z",
     "iopub.status.idle": "2024-07-09T19:16:17.948383Z",
     "shell.execute_reply": "2024-07-09T19:16:17.947197Z"
    },
    "papermill": {
     "duration": 0.031799,
     "end_time": "2024-07-09T19:16:17.950746",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.918947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 8\n",
      "torch.Size([32, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "print(B, T)\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "print(embedded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec2f57ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:17.989431Z",
     "iopub.status.busy": "2024-07-09T19:16:17.989019Z",
     "iopub.status.idle": "2024-07-09T19:16:18.021989Z",
     "shell.execute_reply": "2024-07-09T19:16:18.020457Z"
    },
    "papermill": {
     "duration": 0.055105,
     "end_time": "2024-07-09T19:16:18.024400",
     "exception": false,
     "start_time": "2024-07-09T19:16:17.969295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.7578e-01, -2.7511e-01,  3.8973e-01, -3.1879e-02],\n",
      "         [-3.7397e-01,  4.2724e-01,  1.3090e-01, -1.0879e-01],\n",
      "         [-2.7785e-01,  5.9413e-01, -3.4005e-01,  5.0945e-01],\n",
      "         ...,\n",
      "         [-3.5089e-01,  4.3939e-01, -5.0236e-01,  2.2753e-01],\n",
      "         [-4.8447e-01,  2.7865e-01, -4.5576e-01,  2.7088e-01],\n",
      "         [-4.4588e-01,  2.0943e-01, -3.5007e-01,  2.3303e-01]],\n",
      "\n",
      "        [[-5.7216e-01,  1.1296e+00, -1.2793e-01, -1.8570e-01],\n",
      "         [-2.5776e-01,  6.2494e-01, -5.0406e-01, -1.9584e-01],\n",
      "         [-4.6103e-01,  6.3299e-01, -2.6764e-01, -1.3422e-01],\n",
      "         ...,\n",
      "         [-3.3368e-01,  3.5445e-01, -6.2654e-02,  9.3825e-03],\n",
      "         [-3.6775e-01,  4.6519e-01, -7.1979e-02, -1.8486e-02],\n",
      "         [-4.0152e-01,  3.7491e-01, -3.1470e-01, -1.2347e-01]],\n",
      "\n",
      "        [[ 2.4236e+00,  1.7779e+00, -6.6982e-01,  1.9079e+00],\n",
      "         [ 7.4922e-01,  3.9269e-01, -9.7558e-02,  1.6171e+00],\n",
      "         [ 3.0909e-01,  1.0370e-01, -2.3918e-01,  1.2321e+00],\n",
      "         ...,\n",
      "         [-1.0595e-01, -9.2811e-02, -7.3392e-01,  1.0374e+00],\n",
      "         [-1.7255e-01,  8.1820e-02, -6.4735e-01,  8.6266e-01],\n",
      "         [ 5.0698e-02,  5.1387e-02, -4.0356e-01,  9.3949e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.7241e-01, -5.2406e-01,  8.7006e-01, -8.4764e-01],\n",
      "         [-1.9163e+00,  4.7209e-01,  4.2615e-01, -4.3866e-01],\n",
      "         [-1.3349e+00, -3.3419e-01,  1.7287e-02, -1.9720e-03],\n",
      "         ...,\n",
      "         [-3.1450e-01, -3.6386e-01, -5.7270e-02,  1.2003e-01],\n",
      "         [-3.6069e-01, -3.4860e-01, -3.3676e-01, -1.9731e-02],\n",
      "         [-3.8713e-01, -1.6383e-01, -3.1066e-01, -4.0477e-02]],\n",
      "\n",
      "        [[-1.2323e+00,  4.3628e-01, -1.7533e+00, -1.8253e+00],\n",
      "         [-9.0224e-01,  7.8294e-01, -9.4059e-01, -1.0055e+00],\n",
      "         [-7.9189e-01,  3.6386e-01, -8.0120e-01, -5.1627e-01],\n",
      "         ...,\n",
      "         [-1.7962e-01,  1.1456e-01, -9.1030e-01, -6.1727e-01],\n",
      "         [-3.3000e-01,  1.6052e-01, -1.0307e+00, -7.8984e-01],\n",
      "         [-3.6027e-01,  2.8166e-01, -9.1787e-01, -7.1432e-01]],\n",
      "\n",
      "        [[-1.7578e-01, -2.7511e-01,  3.8973e-01, -3.1879e-02],\n",
      "         [-1.5213e-01, -3.8238e-02, -4.7698e-01, -2.3576e-01],\n",
      "         [-2.9214e-01,  3.5104e-01, -3.6063e-01, -2.1907e-01],\n",
      "         ...,\n",
      "         [ 6.0659e-03,  3.6996e-01, -2.0842e-01,  3.2457e-02],\n",
      "         [-1.7513e-01,  4.4284e-01, -3.9891e-01,  3.2729e-01],\n",
      "         [ 4.8449e-02,  3.6728e-01, -1.8617e-01,  4.7104e-01]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = torch.zeros(size=(B, T, C)) # each of the values has a unique value\n",
    "\n",
    "for batch_idx in range(B):\n",
    "    for context_idx in range(T):\n",
    "        xprev = embedded[batch_idx, :context_idx+1]\n",
    "        bag_of_words[batch_idx, context_idx] = torch.mean(xprev, dim=0)\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06e0fc93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.065066Z",
     "iopub.status.busy": "2024-07-09T19:16:18.064636Z",
     "iopub.status.idle": "2024-07-09T19:16:18.078046Z",
     "shell.execute_reply": "2024-07-09T19:16:18.077138Z"
    },
    "papermill": {
     "duration": 0.036968,
     "end_time": "2024-07-09T19:16:18.080815",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.043847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [16., 12., 30.],\n",
      "        [64., 34., 99.]])\n",
      "tensor([[ 0.,  0.,  0.],\n",
      "        [16., 12., 30.],\n",
      "        [64., 34., 99.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(size=(3, 3))\n",
    "tril = torch.tril(ones) # lower triangular part of a matrix\n",
    "print(tril)\n",
    "a = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (2, 3), dtype=torch.float32)\n",
    "matmul_output = a @ b\n",
    "matmul_tril_output = torch.tril(a) @ b\n",
    "print(matmul_output)\n",
    "print(matmul_tril_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4979517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.119717Z",
     "iopub.status.busy": "2024-07-09T19:16:18.119342Z",
     "iopub.status.idle": "2024-07-09T19:16:18.130782Z",
     "shell.execute_reply": "2024-07-09T19:16:18.129610Z"
    },
    "papermill": {
     "duration": 0.033279,
     "end_time": "2024-07-09T19:16:18.132920",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.099641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[1.0000, 4.0000],\n",
      "        [4.0000, 3.0000],\n",
      "        [2.6667, 4.6667]])\n"
     ]
    }
   ],
   "source": [
    "# do the same as bag of words but with matrix multiplication (dot product)\n",
    "a = torch.ones(size=(3, 3), dtype=torch.float32)\n",
    "b = torch.randint(0, 10, (3, 2), dtype=torch.float32)\n",
    "\n",
    "a = torch.tril(a)\n",
    "\"\"\"\n",
    "b = torch.tensor(\n",
    "    [\n",
    "        [2, 7],\n",
    "        [6, 4],\n",
    "        [6, 5]\n",
    "    ], dtype=torch.float32\n",
    ")\n",
    "\"\"\"\n",
    "print(a)\n",
    "a = a/a.sum(dim=1, keepdim=True)\n",
    "print(a)\n",
    "\n",
    "output = a @ b\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c3011b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.172835Z",
     "iopub.status.busy": "2024-07-09T19:16:18.172443Z",
     "iopub.status.idle": "2024-07-09T19:16:18.188625Z",
     "shell.execute_reply": "2024-07-09T19:16:18.186641Z"
    },
    "papermill": {
     "duration": 0.039507,
     "end_time": "2024-07-09T19:16:18.191226",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.151719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 4])\n",
      "torch.Size([8, 8])\n",
      "tensor([[[ 1.9280,  0.6144,  0.5746,  0.1969],\n",
      "         [ 1.2407,  0.8683,  0.2741, -0.2585],\n",
      "         [ 1.0031,  0.7238, -0.0335,  0.1450],\n",
      "         ...,\n",
      "         [ 0.5927,  0.6425,  0.1193, -0.2535],\n",
      "         [ 0.6924,  0.7620,  0.2443, -0.4628],\n",
      "         [ 0.8469,  0.7436,  0.2855, -0.3804]],\n",
      "\n",
      "        [[ 0.5534,  1.1223, -0.0263, -0.7139],\n",
      "         [ 0.6984, -0.4539,  0.1814,  0.0345],\n",
      "         [ 0.6050, -0.2214, -0.3025,  0.6756],\n",
      "         ...,\n",
      "         [ 0.4217,  0.3487,  0.1173, -0.1781],\n",
      "         [ 0.4406,  0.4592,  0.0967, -0.2546],\n",
      "         [ 0.3808,  0.5652,  0.2071, -0.4068]],\n",
      "\n",
      "        [[-0.7959,  2.3944, -0.3589,  0.4237],\n",
      "         [-0.9841,  0.6067,  0.9223,  1.2838],\n",
      "         [-0.3471,  0.1231,  0.4180,  0.9470],\n",
      "         ...,\n",
      "         [-0.2035,  0.3260,  0.3895,  0.4830],\n",
      "         [-0.0953,  0.4397,  0.3301,  0.3120],\n",
      "         [ 0.0384,  0.4003,  0.4160,  0.2190]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5730,  1.6455,  1.7858, -0.4104],\n",
      "         [ 0.8682,  1.1174,  1.9599, -0.2865],\n",
      "         [ 0.7649,  0.7247,  1.1732, -0.3674],\n",
      "         ...,\n",
      "         [ 0.5445,  0.6928,  1.0614, -0.4281],\n",
      "         [ 0.4614,  0.7805,  1.0498, -0.5773],\n",
      "         [ 0.4729,  0.8232,  0.9152, -0.5944]],\n",
      "\n",
      "        [[ 1.7727, -0.3689, -0.7139,  1.2000],\n",
      "         [ 1.1631,  0.3767, -0.3701,  0.2431],\n",
      "         [ 1.0843, -0.0303, -0.4436,  0.2532],\n",
      "         ...,\n",
      "         [ 0.7268,  0.4168,  0.1365,  0.0571],\n",
      "         [ 0.8762,  0.3046,  0.0150,  0.2204],\n",
      "         [ 0.8358,  0.4068,  0.0099,  0.1036]],\n",
      "\n",
      "        [[ 1.9280,  0.6144,  0.5746,  0.1969],\n",
      "         [ 0.4974,  1.0100,  1.0038, -0.6594],\n",
      "         [ 0.5161,  1.0474,  0.6604, -0.6775],\n",
      "         ...,\n",
      "         [ 0.3572,  0.9658,  0.7342, -0.7824],\n",
      "         [ 0.3340,  0.8623,  0.6365, -0.3704],\n",
      "         [ 0.4141,  0.7701,  0.6841, -0.3781]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(test_dataloader))[0]\n",
    "B, T = sample_batch.shape # batch of B by T\n",
    "example_emb = nn.Embedding(vocab_size, 4)\n",
    "embedded = example_emb(sample_batch)\n",
    "B, T, C = embedded.shape # embedded is Batches by Time (context_sie) by Channels (num of values per token)\n",
    "#print(embedded.shape)\n",
    "\n",
    "wei = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei / wei.sum(dim=1, keepdim=True)\n",
    "print(embedded.shape) # B x T x C\n",
    "print(wei.shape) # T x T\n",
    "#  1xTxT @ BxTxC\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b842d",
   "metadata": {
    "papermill": {
     "duration": 0.018952,
     "end_time": "2024-07-09T19:16:18.229337",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.210385",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bag of words type aggregation with a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1ff04d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.269960Z",
     "iopub.status.busy": "2024-07-09T19:16:18.269156Z",
     "iopub.status.idle": "2024-07-09T19:16:18.282763Z",
     "shell.execute_reply": "2024-07-09T19:16:18.281562Z"
    },
    "papermill": {
     "duration": 0.037317,
     "end_time": "2024-07-09T19:16:18.285498",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.248181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "tensor([[[ 1.9280,  0.6144,  0.5746,  0.1969],\n",
      "         [ 1.2407,  0.8683,  0.2741, -0.2585],\n",
      "         [ 1.0031,  0.7238, -0.0335,  0.1450],\n",
      "         ...,\n",
      "         [ 0.5927,  0.6425,  0.1193, -0.2535],\n",
      "         [ 0.6924,  0.7620,  0.2443, -0.4628],\n",
      "         [ 0.8469,  0.7436,  0.2855, -0.3804]],\n",
      "\n",
      "        [[ 0.5534,  1.1223, -0.0263, -0.7139],\n",
      "         [ 0.6984, -0.4539,  0.1814,  0.0345],\n",
      "         [ 0.6050, -0.2214, -0.3025,  0.6756],\n",
      "         ...,\n",
      "         [ 0.4217,  0.3487,  0.1173, -0.1781],\n",
      "         [ 0.4406,  0.4592,  0.0967, -0.2546],\n",
      "         [ 0.3808,  0.5652,  0.2071, -0.4068]],\n",
      "\n",
      "        [[-0.7959,  2.3944, -0.3589,  0.4237],\n",
      "         [-0.9841,  0.6067,  0.9223,  1.2838],\n",
      "         [-0.3471,  0.1231,  0.4180,  0.9470],\n",
      "         ...,\n",
      "         [-0.2035,  0.3260,  0.3895,  0.4830],\n",
      "         [-0.0953,  0.4397,  0.3301,  0.3120],\n",
      "         [ 0.0384,  0.4003,  0.4160,  0.2190]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.5730,  1.6455,  1.7858, -0.4104],\n",
      "         [ 0.8682,  1.1174,  1.9599, -0.2865],\n",
      "         [ 0.7649,  0.7247,  1.1732, -0.3674],\n",
      "         ...,\n",
      "         [ 0.5445,  0.6928,  1.0614, -0.4281],\n",
      "         [ 0.4614,  0.7805,  1.0498, -0.5773],\n",
      "         [ 0.4729,  0.8232,  0.9152, -0.5944]],\n",
      "\n",
      "        [[ 1.7727, -0.3689, -0.7139,  1.2000],\n",
      "         [ 1.1631,  0.3767, -0.3701,  0.2431],\n",
      "         [ 1.0843, -0.0303, -0.4436,  0.2532],\n",
      "         ...,\n",
      "         [ 0.7268,  0.4168,  0.1365,  0.0571],\n",
      "         [ 0.8762,  0.3046,  0.0150,  0.2204],\n",
      "         [ 0.8358,  0.4068,  0.0099,  0.1036]],\n",
      "\n",
      "        [[ 1.9280,  0.6144,  0.5746,  0.1969],\n",
      "         [ 0.4974,  1.0100,  1.0038, -0.6594],\n",
      "         [ 0.5161,  1.0474,  0.6604, -0.6775],\n",
      "         ...,\n",
      "         [ 0.3572,  0.9658,  0.7342, -0.7824],\n",
      "         [ 0.3340,  0.8623,  0.6365, -0.3704],\n",
      "         [ 0.4141,  0.7701,  0.6841, -0.3781]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = torch.zeros(size=(T, T)) # zeros just so there's a plaaceholder for masked_fill\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\")) # whenever the value in tril is 0, it will get replaced with -inf; this allows softmax to come into place, since -inf will get a percent of 0\n",
    "wei = torch.softmax(wei, dim=1)\n",
    "print(wei)\n",
    "bag_of_words = wei @ embedded\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984c54a",
   "metadata": {
    "papermill": {
     "duration": 0.019331,
     "end_time": "2024-07-09T19:16:18.324929",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.305598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MLP model with agreggation\n",
    "- a problem that needs to be addressed with the previous model is that it needs to always receive a input of B x T (batch_size by context_size), whereas it would be best if the model could adapt to inputs of different context_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04b34d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.365149Z",
     "iopub.status.busy": "2024-07-09T19:16:18.364301Z",
     "iopub.status.idle": "2024-07-09T19:16:18.375933Z",
     "shell.execute_reply": "2024-07-09T19:16:18.374471Z"
    },
    "papermill": {
     "duration": 0.034304,
     "end_time": "2024-07-09T19:16:18.378290",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.343986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 6.0203e-01,  7.7065e-01,  5.7534e-01, -4.4121e-01,  9.4248e-01],\n",
      "         [ 5.0862e-02,  2.8102e-01, -5.0223e-01,  9.0502e-01,  3.9423e-01],\n",
      "         [ 5.9646e-01, -3.6989e-01, -4.1166e-01,  6.3679e-01,  1.3495e-02],\n",
      "         ...,\n",
      "         [ 3.3532e-01, -4.9190e-01, -4.1953e-01,  2.7829e-01, -3.8374e-02],\n",
      "         [ 2.0919e-01, -2.6207e-01, -4.4235e-02,  2.3070e-01,  3.0028e-02],\n",
      "         [ 2.9527e-01, -1.9783e-01, -1.1896e-01,  2.9992e-01,  9.6746e-02]],\n",
      "\n",
      "        [[-6.8395e-01,  4.1657e-02,  7.7012e-01,  5.0897e-01,  1.1499e-02],\n",
      "         [-7.3110e-01,  5.9835e-01,  5.5834e-01, -1.5275e-01, -2.6736e-01],\n",
      "         [-9.1908e-01,  6.3536e-01,  4.8470e-01, -3.6135e-01,  4.0921e-02],\n",
      "         ...,\n",
      "         [-3.0068e-01,  8.3545e-01,  3.7348e-01, -7.0396e-01, -1.3963e-01],\n",
      "         [-2.7897e-01,  7.4900e-01,  4.8425e-01, -6.7691e-01, -7.3942e-02],\n",
      "         [-1.1215e-01,  5.6384e-01,  4.4792e-01, -7.1354e-01, -6.7875e-02]],\n",
      "\n",
      "        [[ 1.9688e+00, -1.3080e-01, -1.7727e-01,  4.9248e-01,  7.8015e-01],\n",
      "         [ 1.2786e+00,  3.6809e-01, -8.9357e-02,  1.1674e-01,  2.0547e-01],\n",
      "         [ 1.0332e+00,  6.0684e-01, -1.9541e-01, -3.6372e-01,  2.3257e-01],\n",
      "         ...,\n",
      "         [ 2.9119e-01,  1.1377e-01, -7.2837e-02, -4.9457e-01,  6.4128e-01],\n",
      "         [ 1.4554e-02,  9.1034e-02, -1.2123e-01, -3.7795e-01,  7.1130e-01],\n",
      "         [-2.1300e-01,  1.5311e-01,  5.0532e-02, -3.6513e-01,  5.8765e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.7221e-01, -1.2302e+00,  4.0054e-01, -2.1671e-01,  7.2150e-01],\n",
      "         [-4.4341e-01, -3.0941e-01,  5.9050e-01, -5.0622e-01,  5.8453e-01],\n",
      "         [-3.5632e-02, -1.0468e-01,  6.7642e-01, -4.5840e-01,  3.1185e-01],\n",
      "         ...,\n",
      "         [-1.8127e-01,  3.2260e-01,  8.9614e-01,  3.1022e-02, -2.0496e-01],\n",
      "         [ 6.2915e-02,  3.7604e-01,  8.4558e-01, -2.9598e-01, -2.5423e-01],\n",
      "         [-6.3313e-02,  4.3370e-01,  7.3290e-01, -2.5866e-01, -2.6832e-01]],\n",
      "\n",
      "        [[ 1.3843e-02, -2.6362e-01, -5.3331e-01, -9.5579e-01,  2.7998e-01],\n",
      "         [ 1.0235e+00,  5.9882e-01, -1.7339e-01, -5.8084e-01,  8.8937e-02],\n",
      "         [ 1.9313e-01,  5.9523e-01, -2.0313e-01, -7.6818e-02,  2.1985e-01],\n",
      "         ...,\n",
      "         [-4.4142e-01,  3.9607e-01, -1.8018e-01, -5.5639e-01,  5.6035e-01],\n",
      "         [-4.9813e-01,  4.0482e-01, -6.9579e-02, -5.2860e-01,  5.7830e-01],\n",
      "         [-5.4761e-01,  1.1010e-01, -9.3516e-05, -3.8055e-01,  4.4838e-01]],\n",
      "\n",
      "        [[ 1.1176e+00, -7.0396e-01,  2.6278e+00,  1.7167e+00, -9.6403e-01],\n",
      "         [ 1.1532e+00, -2.2219e-01,  1.6836e+00,  5.3168e-01, -7.3968e-01],\n",
      "         [ 9.4734e-01, -2.4567e-01,  7.7030e-01, -1.3279e-01, -2.4006e-01],\n",
      "         ...,\n",
      "         [ 6.8613e-01,  1.8681e-01,  4.4258e-01,  9.5459e-02, -4.3635e-01],\n",
      "         [ 4.7300e-01,  4.6784e-01,  6.8171e-01,  1.1202e-01, -4.6999e-01],\n",
      "         [ 3.1713e-01,  5.2912e-01,  5.6529e-01,  8.4527e-02, -5.3992e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "C = n_embd\n",
    "T = context_size\n",
    "B = batch_size\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "print(xbow @ test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "635da7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.419677Z",
     "iopub.status.busy": "2024-07-09T19:16:18.419276Z",
     "iopub.status.idle": "2024-07-09T19:16:18.426595Z",
     "shell.execute_reply": "2024-07-09T19:16:18.425339Z"
    },
    "papermill": {
     "duration": 0.030468,
     "end_time": "2024-07-09T19:16:18.428838",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.398370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n",
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "# a problem that needs to be addressed with the previous model is that it needs to always receive a \n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "print(batch_sample_inputs.shape)\n",
    "print(batch_sample_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6dc9446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.469236Z",
     "iopub.status.busy": "2024-07-09T19:16:18.468774Z",
     "iopub.status.idle": "2024-07-09T19:16:18.481351Z",
     "shell.execute_reply": "2024-07-09T19:16:18.480347Z"
    },
    "papermill": {
     "duration": 0.035669,
     "end_time": "2024-07-09T19:16:18.483694",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.448025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        #logits = self.lm_head(token_emb.view(B*T, C)) # output of shape B*T x hidden_units1; this might be a problem for the labels since they are of shape B x T, thus they need to be reshaped aswell\n",
    "        x = self.act_fn(self.linear1(token_emb.view(B*T, C))) # hidden_units1 x hidden_units2\n",
    "        x = self.act_fn(self.linear2(x)) # hidden_units2 x hidden_units3\n",
    "        x = self.linear3(x) # hidden_units3 x vocab_size\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf98db50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.525225Z",
     "iopub.status.busy": "2024-07-09T19:16:18.524796Z",
     "iopub.status.idle": "2024-07-09T19:16:18.532871Z",
     "shell.execute_reply": "2024-07-09T19:16:18.531886Z"
    },
    "papermill": {
     "duration": 0.031254,
     "end_time": "2024-07-09T19:16:18.535247",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.503993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2 = MLPv2(vocab_size=vocab_size, n_embd=32, context_size=context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1209cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.577544Z",
     "iopub.status.busy": "2024-07-09T19:16:18.577068Z",
     "iopub.status.idle": "2024-07-09T19:16:18.585252Z",
     "shell.execute_reply": "2024-07-09T19:16:18.584173Z"
    },
    "papermill": {
     "duration": 0.031553,
     "end_time": "2024-07-09T19:16:18.587691",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.556138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpv2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51724f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.628791Z",
     "iopub.status.busy": "2024-07-09T19:16:18.628409Z",
     "iopub.status.idle": "2024-07-09T19:16:18.640321Z",
     "shell.execute_reply": "2024-07-09T19:16:18.638960Z"
    },
    "papermill": {
     "duration": 0.035195,
     "end_time": "2024-07-09T19:16:18.642517",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.607322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 58, 46, 43, 47, 56,  1, 54])\n",
      "tensor([[58, 46, 43, 47, 56,  1, 54, 53]])\n",
      "torch.Size([8, 65])\n",
      "torch.Size([8])\n",
      "tensor(4.1342)\n"
     ]
    }
   ],
   "source": [
    "mlpv2_loss_fn = nn.CrossEntropyLoss()\n",
    "batch_sample_inputs, batch_sample_labels = next(iter(train_dataloader))\n",
    "sample_input = batch_sample_inputs[0]\n",
    "sample_label = batch_sample_labels[0]\n",
    "print(sample_input) # 1 x T (B x T)\n",
    "print(sample_label.view(1, -1)) # 1 x T (B x T)\n",
    "mlpv2.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = mlpv2(sample_input.view(1, -1))\n",
    "    labels = sample_label.view(-1) # from B x T to B*T to match the shape of the logits\n",
    "    print(logits.shape) # B*T x vocab_size\n",
    "    print(labels.shape)\n",
    "\n",
    "    loss = mlpv2_loss_fn(logits, labels)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07b5be7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.684489Z",
     "iopub.status.busy": "2024-07-09T19:16:18.684067Z",
     "iopub.status.idle": "2024-07-09T19:16:18.690255Z",
     "shell.execute_reply": "2024-07-09T19:16:18.689205Z"
    },
    "papermill": {
     "duration": 0.029905,
     "end_time": "2024-07-09T19:16:18.692470",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.662565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def generate_from_model(model, num_outputs, starting_char, max_length):\n",
    "    mlpv2.eval()\n",
    "    outputs = []\n",
    "    starting_idx = torch.tensor([stoi[starting_char]], dtype=torch.long).view(1, -1)\n",
    "    for i in range(num_outputs):\n",
    "        output = mlpv2.generate(starting_idx=starting_idx, max_length=max_length) # must be batched\n",
    "        outputs.append(output)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66066775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.735101Z",
     "iopub.status.busy": "2024-07-09T19:16:18.733906Z",
     "iopub.status.idle": "2024-07-09T19:16:18.743474Z",
     "shell.execute_reply": "2024-07-09T19:16:18.742167Z"
    },
    "papermill": {
     "duration": 0.0333,
     "end_time": "2024-07-09T19:16:18.745870",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.712570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aO-,yF\n"
     ]
    }
   ],
   "source": [
    "test_output = generate_from_model(model=mlpv2, num_outputs=1, starting_char=\"a\", max_length=5)\n",
    "print(test_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0ddbf97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.787932Z",
     "iopub.status.busy": "2024-07-09T19:16:18.786976Z",
     "iopub.status.idle": "2024-07-09T19:16:18.794074Z",
     "shell.execute_reply": "2024-07-09T19:16:18.792961Z"
    },
    "papermill": {
     "duration": 0.030375,
     "end_time": "2024-07-09T19:16:18.796249",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.765874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, loss_fn, optimizer, epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            if batch % 1200 == 0:\n",
    "                print(f\"loss for batch {batch} --> {loss} at epoch {epoch}\")\n",
    "\n",
    "    print(f\"loss for the very last batch --> {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0116cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.838215Z",
     "iopub.status.busy": "2024-07-09T19:16:18.837818Z",
     "iopub.status.idle": "2024-07-09T19:16:18.843554Z",
     "shell.execute_reply": "2024-07-09T19:16:18.842513Z"
    },
    "papermill": {
     "duration": 0.02929,
     "end_time": "2024-07-09T19:16:18.845810",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.816520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlpv2_optimizer = torch.optim.Adam(params=mlpv2.parameters(), lr=1e-3)\n",
    "mlpv2_loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6db253c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:16:18.887966Z",
     "iopub.status.busy": "2024-07-09T19:16:18.886975Z",
     "iopub.status.idle": "2024-07-09T19:17:01.413473Z",
     "shell.execute_reply": "2024-07-09T19:17:01.411584Z"
    },
    "papermill": {
     "duration": 42.551755,
     "end_time": "2024-07-09T19:17:01.417475",
     "exception": false,
     "start_time": "2024-07-09T19:16:18.865720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for batch 0 --> 4.193885326385498 at epoch 0\n",
      "loss for batch 1200 --> 2.415966033935547 at epoch 0\n",
      "loss for batch 2400 --> 2.2945008277893066 at epoch 0\n",
      "loss for batch 0 --> 2.498746633529663 at epoch 1\n",
      "loss for batch 1200 --> 2.4111926555633545 at epoch 1\n",
      "loss for batch 2400 --> 2.2905168533325195 at epoch 1\n",
      "loss for batch 0 --> 2.4965763092041016 at epoch 2\n",
      "loss for batch 1200 --> 2.410950183868408 at epoch 2\n",
      "loss for batch 2400 --> 2.2882120609283447 at epoch 2\n",
      "loss for batch 0 --> 2.495180130004883 at epoch 3\n",
      "loss for batch 1200 --> 2.4093832969665527 at epoch 3\n",
      "loss for batch 2400 --> 2.2853567600250244 at epoch 3\n",
      "loss for the very last batch --> 2.2023563385009766\n"
     ]
    }
   ],
   "source": [
    "train_model(model=mlpv2, dataloader=train_dataloader, loss_fn=mlpv2_loss_fn, optimizer=mlpv2_optimizer, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d8aff44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.465373Z",
     "iopub.status.busy": "2024-07-09T19:17:01.464832Z",
     "iopub.status.idle": "2024-07-09T19:17:01.544280Z",
     "shell.execute_reply": "2024-07-09T19:17:01.543422Z"
    },
    "papermill": {
     "duration": 0.105994,
     "end_time": "2024-07-09T19:17:01.547767",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.441773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bes o yo pesthe cave grth o veat yosean ce ad towome nant und cteoth inavenkexthone ous sshesthes tlo\n",
      "\n",
      "\n",
      "bret m se d qul ter\n",
      "CO ulu OLAse whe mon y.\n",
      "IUS:\n",
      "COLA:\n",
      "\n",
      "\n",
      "TIUS:\n",
      "Wheranin d cbe th iak' be.\n",
      "Tom orise a\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_outputs = generate_from_model(model=mlpv2, max_length=100, num_outputs=2, starting_char=\"b\")\n",
    "for output in test_outputs:\n",
    "    print(f\"{output}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aad76071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.596752Z",
     "iopub.status.busy": "2024-07-09T19:17:01.595664Z",
     "iopub.status.idle": "2024-07-09T19:17:01.604512Z",
     "shell.execute_reply": "2024-07-09T19:17:01.603452Z"
    },
    "papermill": {
     "duration": 0.033465,
     "end_time": "2024-07-09T19:17:01.606706",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.573241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=T, step=1) # from 0 to T-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3847d27",
   "metadata": {
    "papermill": {
     "duration": 0.021014,
     "end_time": "2024-07-09T19:17:01.649175",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.628161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self attention\n",
    "- with xbow you can add information about the tokens, but the model itself does not attribute any weight to them. This is what self attention solves by using Keys, Queries and Values\n",
    "- every token will have a specific Query (Q) and Key (K) attatched to it\n",
    "    - Query --> what the model is looking for\n",
    "    - Key --> the weight the model is giving to this certain token\n",
    "    - Value --> Q @ K to get the affinities between themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6124d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.693256Z",
     "iopub.status.busy": "2024-07-09T19:17:01.692754Z",
     "iopub.status.idle": "2024-07-09T19:17:01.703463Z",
     "shell.execute_reply": "2024-07-09T19:17:01.701899Z"
    },
    "papermill": {
     "duration": 0.035981,
     "end_time": "2024-07-09T19:17:01.706313",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.670332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# Code to allow comunication between past tokens\n",
    "\n",
    "B, T, C = 2, 4, 8\n",
    "wei = torch.zeros(size=(T, T))\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "xbow = wei.softmax(dim=1)\n",
    "\n",
    "test_tensor = torch.randn(size=(B, T, C))\n",
    "output = xbow @ test_tensor\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca20e8dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.759804Z",
     "iopub.status.busy": "2024-07-09T19:17:01.759416Z",
     "iopub.status.idle": "2024-07-09T19:17:01.767994Z",
     "shell.execute_reply": "2024-07-09T19:17:01.766510Z"
    },
    "papermill": {
     "duration": 0.034173,
     "end_time": "2024-07-09T19:17:01.770740",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.736567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 32])\n",
      "torch.Size([2, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "head_size = 32\n",
    "key = nn.Linear(in_features=C, out_features=head_size, bias=False) # bias = False so that it's just a multiplication\n",
    "query = nn.Linear(in_features=C, out_features=head_size, bias=False) \n",
    "\n",
    "#print(test_tensor.shape)\n",
    "k = key(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a key value\n",
    "q = query(test_tensor) # BxTxC @ BxTxhead_size --> BxTxhead_size; each batch has a context and each context character has a query value\n",
    "print(k.shape)\n",
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b9f9bba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.823409Z",
     "iopub.status.busy": "2024-07-09T19:17:01.822378Z",
     "iopub.status.idle": "2024-07-09T19:17:01.833505Z",
     "shell.execute_reply": "2024-07-09T19:17:01.832259Z"
    },
    "papermill": {
     "duration": 0.038446,
     "end_time": "2024-07-09T19:17:01.836412",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.797966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 32, 4])\n",
      "torch.Size([2, 4, 4])\n",
      "torch.Size([2, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(k.transpose(-2, -1).shape) # same as k.permute(0, 2, 1)\n",
    "print(k.permute(0, 2, 1).shape)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1) # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "print(wei.shape) #  B x T x T\n",
    "\n",
    "tril = torch.tril(torch.ones(size=(T, T)))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = torch.softmax(wei, dim=-1) # dim=-1 in this case, since wei is of shape\n",
    "\n",
    "output = wei @ test_tensor\n",
    "\n",
    "print(output.shape) # B x T x C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bda928",
   "metadata": {
    "papermill": {
     "duration": 0.021942,
     "end_time": "2024-07-09T19:17:01.880713",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.858771",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Update the model with a self attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9302e322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.925792Z",
     "iopub.status.busy": "2024-07-09T19:17:01.925415Z",
     "iopub.status.idle": "2024-07-09T19:17:01.934302Z",
     "shell.execute_reply": "2024-07-09T19:17:01.932951Z"
    },
    "papermill": {
     "duration": 0.034539,
     "end_time": "2024-07-09T19:17:01.936992",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.902453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd):\n",
    "        super(Head, self).__init__()\n",
    "\n",
    "        self.Q = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.K = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "        self.V = nn.Linear(in_features=n_embd, out_features=head_size)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "        #mask = torch.tril(torch.ones(size=(T, T)))\n",
    "\n",
    "        q = self.Q(x) # B x T x head_size\n",
    "        k = self.K(x) # B x T x head_size\n",
    "        v = self.V(x) # B x T x head_size\n",
    "\n",
    "        k = k.transpose(-2, -1) # B x head_size x T\n",
    "\n",
    "        wei = q @ k # BxTxhead_size @ Bxhead_sizexT --> BxTxT\n",
    "\n",
    "        wei = wei.masked_fill(mask==0, float('-inf'))\n",
    "        wei = torch.softmax(wei, dim=-1)\n",
    "\n",
    "        #x = wei @ v # BxTxT @ BxTxhead_size --> BxTxhead_size\n",
    "        x = wei @ x\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e6ebbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:01.989564Z",
     "iopub.status.busy": "2024-07-09T19:17:01.989021Z",
     "iopub.status.idle": "2024-07-09T19:17:02.006714Z",
     "shell.execute_reply": "2024-07-09T19:17:02.005514Z"
    },
    "papermill": {
     "duration": 0.043766,
     "end_time": "2024-07-09T19:17:02.009005",
     "exception": false,
     "start_time": "2024-07-09T19:17:01.965239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPv3(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, context_size):\n",
    "        super(MLPv3, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_embd = n_embd\n",
    "        self.context_size = context_size\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size, n_embd) # the position of each token has a separate table of values; this helps the model keep track of the order of characters\n",
    "\n",
    "        self.head = Head(head_size=32, n_embd=n_embd)\n",
    "\n",
    "        #self.lm_head = nn.Linear(in_features=n_embd, out_features=vocab_size) # this time in_features=n_embd so it's not context_size dependant\n",
    "        self.linear1 = nn.Linear(in_features=n_embd, out_features=8*8)\n",
    "        self.linear2 = nn.Linear(in_features=8*8, out_features=8*8*8)\n",
    "        self.linear3 = nn.Linear(in_features=8*8*8, out_features=vocab_size)\n",
    "\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "        self.mask = torch.tril(torch.ones(size=(context_size, context_size)))\n",
    "\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            \"vocab_size\": self.vocab_size,\n",
    "            \"n_embd\": self.n_embd,\n",
    "            \"context_size\": self.context_size\n",
    "        }\n",
    "\n",
    "        return info_dict\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T = x.shape\n",
    "        C = self.n_embd\n",
    "\n",
    "        #print(B, T, C)\n",
    "\n",
    "        positions = torch.arange(start=0, end=T, step=1)\n",
    "        token_emb = self.token_embedding_table(x) # batch_size x context_size x n_embd --> BxTxC\n",
    "        pos_emb = self.positional_embedding_table(positions) # T x C (each context has a position)\n",
    "\n",
    "\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.head(x, self.mask)\n",
    "        x = x.view(B*T, C)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, starting_idx: torch.Tensor, max_length) -> torch.Tensor:\n",
    "\n",
    "        full_text = itos[starting_idx.item()]\n",
    "        for i in range(max_length):\n",
    "            logits = self(starting_idx)\n",
    "            percents = torch.softmax(logits, dim=1)\n",
    "            pred = torch.multinomial(percents, num_samples=1)\n",
    "            starting_idx = pred\n",
    "            full_text += decode([pred.item()])\n",
    "        return full_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "708fcfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:02.054327Z",
     "iopub.status.busy": "2024-07-09T19:17:02.053811Z",
     "iopub.status.idle": "2024-07-09T19:17:02.067430Z",
     "shell.execute_reply": "2024-07-09T19:17:02.066350Z"
    },
    "papermill": {
     "duration": 0.039855,
     "end_time": "2024-07-09T19:17:02.070727",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.030872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 65, 'n_embd': 32, 'context_size': 8}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 32\n",
    "mlpv3 = MLPv3(vocab_size=vocab_size, n_embd=n_embd, context_size=context_size)\n",
    "mlpv3.optimizer = torch.optim.Adam(params=mlpv3.parameters(), lr=1e-2)\n",
    "mlpv3_loss_fn = nn.CrossEntropyLoss()\n",
    "mlpv3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae763e90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:02.117168Z",
     "iopub.status.busy": "2024-07-09T19:17:02.116206Z",
     "iopub.status.idle": "2024-07-09T19:17:02.273532Z",
     "shell.execute_reply": "2024-07-09T19:17:02.272456Z"
    },
    "papermill": {
     "duration": 0.183258,
     "end_time": "2024-07-09T19:17:02.276203",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.092945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anstil?\n",
      "\n",
      "Fofg band d cowithor,\n",
      "ENIUTore: t\n",
      "Whityo thuchy me, the tin, tl' hesoobl pre gon ioeshald, y?\n",
      "Ashe\n",
      "\n",
      "MENENININUS:\n",
      "\n",
      "Mar t te datre ce ik, bulbe h!\n",
      "Fr wira\n",
      "Thees! e isolo vel t goue ty, atitiumy  \n",
      "\n",
      "\n",
      "anerdy ngrck, y Vode nowig st,\n",
      "Tort glopimionire cith ous t tlle u' he ple.\n",
      "OLA s wntwotonom f prsserd andengin io she tthe.\n",
      "Mar ou f d tt mshindot r f pe sher:\n",
      "\n",
      "Th tn beetre y kne and, pppe d tris twn \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fc4d5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:02.321864Z",
     "iopub.status.busy": "2024-07-09T19:17:02.321481Z",
     "iopub.status.idle": "2024-07-09T19:17:02.326215Z",
     "shell.execute_reply": "2024-07-09T19:17:02.325094Z"
    },
    "papermill": {
     "duration": 0.030505,
     "end_time": "2024-07-09T19:17:02.328658",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.298153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_model(model=mlpv3, dataloader=train_dataloader, loss_fn=mlpv3_loss_fn, optimizer=mlpv2_optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09738d96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T19:17:02.376070Z",
     "iopub.status.busy": "2024-07-09T19:17:02.375638Z",
     "iopub.status.idle": "2024-07-09T19:17:02.506736Z",
     "shell.execute_reply": "2024-07-09T19:17:02.505214Z"
    },
    "papermill": {
     "duration": 0.157482,
     "end_time": "2024-07-09T19:17:02.509025",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.351543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at s m of n waneye m, t uththot y poish hen\n",
      "ENICOLAwhe t Lof t yosisethee at ere t, elst fru pethioto weshe.\n",
      "An oofacoomim thej d, ere wily mefer? mathe,\n",
      "rs as be s s shie s wido't harto Cin ce t, tll  \n",
      "\n",
      "\n",
      "atwhive--alaasark yo ns n m o y f f nst m Pu streart thevaveptyo an s, cot ho ay coulun, merowethananowire rilowe m, ho bl wazech.\n",
      "Whe we ich stod t tod dr wowe vie tod po yovether priple umy wou ac'\n",
      "T \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = generate_from_model(model=mlpv3, max_length=200, num_outputs=2, starting_char=\"a\")\n",
    "for output in outputs:\n",
    "    print(f\"{output} \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cda635",
   "metadata": {
    "papermill": {
     "duration": 0.021511,
     "end_time": "2024-07-09T19:17:02.552678",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.531167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Self-attetion x cross-attention\n",
    "- in self-attention the values for queries (Q), keys (K) and values (V) all come from x itself, thus self-attention\n",
    "- in cross-attention those values can come from somewhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecb574",
   "metadata": {
    "papermill": {
     "duration": 0.021724,
     "end_time": "2024-07-09T19:17:02.596331",
     "exception": false,
     "start_time": "2024-07-09T19:17:02.574607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5339176,
     "sourceId": 8871363,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 69.593367,
   "end_time": "2024-07-09T19:17:03.641662",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-09T19:15:54.048295",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
